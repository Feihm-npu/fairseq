srun: Job 55677 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Step created for job 55677
2024-07-12 03:57:00 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://t006-001:9997
2024-07-12 03:57:00 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://t006-001:9997
2024-07-12 03:57:00 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://t006-001:9997
2024-07-12 03:57:00 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://t006-001:9997
2024-07-12 03:57:01 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://t006-001:9997
2024-07-12 03:57:01 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://t006-001:9997
2024-07-12 03:57:01 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://t006-001:9997
2024-07-12 03:57:01 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://t006-001:9997
2024-07-12 03:57:01 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 1
2024-07-12 03:57:01 | INFO | fairseq.distributed.utils | initialized host t006-002.hpcfund as rank 6
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-12 03:57:02 | INFO | fairseq.distributed.utils | initialized host t006-002.hpcfund as rank 7
2024-07-12 03:57:02 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 3
2024-07-12 03:57:02 | INFO | fairseq.distributed.utils | initialized host t006-002.hpcfund as rank 4
2024-07-12 03:57:02 | INFO | fairseq.distributed.utils | initialized host t006-002.hpcfund as rank 5
2024-07-12 03:57:02 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 2
2024-07-12 03:57:02 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 8, 'moe_eval_capacity_token_fraction': 0.05}", 'results_path': None, 'is_moe': True}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://t006-001:9997', 'distributed_port': 9997, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 10, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': 10, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 10}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | model	None
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 10, 'batch_size_valid': 10, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-12 03:57:03 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-12 03:57:03 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-12 03:57:03 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-12 03:57:03 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 8, Stitching experts to able to load on current world size.
2024-07-12 03:57:04 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-12 03:57:04 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-12 03:57:04 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-12 03:57:04 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-12 03:57:04 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-12 03:57:04 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-12 03:57:04 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-12 03:57:04 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-12 03:57:05 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:57:07 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:57:08 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:57:10 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:57:11 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:57:12 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:57:14 | INFO | fairseq_cli.eval_lm | num. model params: 1,911,816,192
2024-07-12 03:57:21 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-12 03:57:30 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-12 03:57:35 | INFO | fairseq_cli.eval_lm | load time: 32.24 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
now round: 1
New cuda time without quantization: 8817.365234375
torch.Size([524288, 768]) torch.qint8
New cuda time: 8837.822265625
New cuda time without quantization: 55.721370697021484
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.95965576171875
now round: 1
New cuda time without quantization: 135.52093505859375
torch.Size([524288, 768]) torch.qint8
New cuda time: 145.72689819335938
New cuda time without quantization: 60.72331237792969
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.91311645507812
now round: 1
New cuda time without quantization: 48.293495178222656
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.436744689941406
New cuda time without quantization: 54.4596061706543
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.61085510253906
now round: 1
New cuda time without quantization: 50.55398941040039
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.70123291015625
New cuda time without quantization: 54.666969299316406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.88509368896484
now round: 1
New cuda time without quantization: 50.13462448120117
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.313873291015625
New cuda time without quantization: 55.950172424316406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.10637664794922
now round: 1
New cuda time without quantization: 52.13495635986328
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.4841194152832
New cuda time without quantization: 63.69420623779297
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 73.95329284667969
now round: 2
New cuda time without quantization: 51.79399108886719
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.29164123535156
New cuda time without quantization: 63.137725830078125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 73.34112548828125
now round: 2
New cuda time without quantization: 54.769046783447266
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.89645385742188
New cuda time without quantization: 57.044097900390625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.31118774414062
now round: 2
New cuda time without quantization: 50.163265228271484
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.41579055786133
New cuda time without quantization: 54.66120910644531
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.86109161376953
now round: 2
New cuda time without quantization: 51.07111358642578
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.36283493041992
New cuda time without quantization: 67.09310150146484
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 77.31043243408203
now round: 2
New cuda time without quantization: 50.154624938964844
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.33099365234375
New cuda time without quantization: 55.217369079589844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.62429809570312
now round: 2
New cuda time without quantization: 52.149837493896484
now round: 1
New cuda time without quantization: 13541.109375
torch.Size([524288, 768]) torch.qint8
New cuda time: 13553.6435546875
New cuda time without quantization: 64.4972152709961
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 74.64300537109375
now round: 1
New cuda time without quantization: 177.14598083496094
torch.Size([524288, 768]) torch.qint8
New cuda time: 187.38905334472656
New cuda time without quantization: 52.84836959838867
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.0836067199707
now round: 1
New cuda time without quantization: 51.86932373046875
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.92520523071289
New cuda time without quantization: 46.12786102294922
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 56.23830032348633
now round: 1
New cuda time without quantization: 42.29024887084961
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.3320426940918
New cuda time without quantization: 57.69638442993164
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.27724075317383
New cuda time without quantization: 56.625057220458984
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.80110168457031
now round: 3
New cuda time without quantization: 51.684391021728516
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.809078216552734
New cuda time without quantization: 46.071407318115234
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 56.26521301269531
now round: 3
New cuda time without quantization: 50.232547760009766
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.38091278076172
New cuda time without quantization: 60.52859115600586
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.78336334228516
now round: 3
New cuda time without quantization: 42.50099182128906
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.639434814453125
New cuda time without quantization: 54.89048767089844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.10781860351562
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.83098602294922
now round: 1
New cuda time without quantization: 49.88387680053711
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.987274169921875
New cuda time without quantization: 56.663902282714844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.89706420898438
now round: 1
New cuda time without quantization: 47.28450393676758
torch.Size([524288, 768]) torch.qint8
New cuda time: 57.35558319091797
New cuda time without quantization: 64.49417114257812
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 74.63997650146484
now round: 2
New cuda time without quantization: 47.63426971435547
torch.Size([524288, 768]) torch.qint8
New cuda time: 57.685665130615234
New cuda time without quantization: 64.02489471435547
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 74.27164459228516
now round: 2
New cuda time without quantization: 41.665924072265625
torch.Size([524288, 768]) torch.qint8
New cuda time: 51.773162841796875
now round: 3
New cuda time without quantization: 65.33753967285156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 75.49517822265625
now round: 2
New cuda time without quantization: 54.29429244995117
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.36328887939453
New cuda time without quantization: 55.4472541809082
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.52409362792969
now round: 2
New cuda time without quantization: 49.359710693359375
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.437992095947266
New cuda time without quantization: 59.590633392333984
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.68539428710938
now round: 2
New cuda time without quantization: 50.130435943603516
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.204715728759766
New cuda time without quantization: 55.680381774902344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.75929260253906
now round: 2
New cuda time without quantization: 52.59316635131836
New cuda time without quantization: 130.50587463378906
torch.Size([524288, 768]) torch.qint8
New cuda time: 140.7875213623047
New cuda time without quantization: 53.037681579589844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.237083435058594
now round: 3
New cuda time without quantization: 50.181983947753906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.31003189086914
New cuda time without quantization: 55.80617141723633
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.9903793334961
now round: 3
New cuda time without quantization: 85.11366271972656
torch.Size([524288, 768]) torch.qint8
New cuda time: 95.25723266601562
New cuda time without quantization: 61.23291778564453
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.49584197998047
now round: 4
New cuda time without quantization: 55.35160827636719
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.50013732910156
New cuda time without quantization: 54.75448989868164
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.68424987792969
New cuda time without quantization: 57.622467041015625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.73082733154297
now round: 3
New cuda time without quantization: 49.74211502075195
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.9415168762207
New cuda time without quantization: 55.7882194519043
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.87097930908203
now round: 3
New cuda time without quantization: 49.75603485107422
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.81559753417969
New cuda time without quantization: 52.441009521484375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 62.6176872253418
now round: 3
New cuda time without quantization: 51.72804260253906
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.77096176147461
New cuda time without quantization: 55.0245361328125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.16425323486328
now round: 3
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.9217300415039
now round: 4
New cuda time without quantization: 56.64265441894531
torch.Size([524288, 768]) torch.qint8
New cuda time: 66.80462646484375
New cuda time without quantization: 49.44278335571289
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.97710418701172
now round: 4
New cuda time without quantization: 153.9568634033203
torch.Size([524288, 768]) torch.qint8
New cuda time: 164.08265686035156
New cuda time without quantization: 57.25722122192383
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.4527816772461
now round: 4
New cuda time without quantization: 256.7008361816406
torch.Size([524288, 768]) torch.qint8
New cuda time: 266.8672790527344
New cuda time without quantization: 45.94452667236328
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 56.32505416870117
now round: 4
New cuda time without quantization: 149.0542755126953
torch.Size([524288, 768]) torch.qint8
New cuda time: 159.2029571533203
New cuda time without quantization: 132.92083740234375
New cuda time without quantization: 47.84581756591797
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 58.080745697021484
now round: 4
New cuda time without quantization: 49.66902542114258
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.7911491394043
New cuda time without quantization: 267.67608642578125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 278.0342102050781
now round: 5
New cuda time without quantization: 48.91670227050781
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.03194808959961
New cuda time without quantization: 162.859619140625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 173.17758178710938
now round: 5
New cuda time without quantization: 50.196067810058594
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.33339309692383
New cuda time without quantization: 57.02249526977539
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.21166229248047
now round: 5
New cuda time without quantization: 42.13443374633789
now round: 1
New cuda time without quantization: 338.89202880859375
torch.Size([524288, 768]) torch.qint8
New cuda time: 352.25579833984375
New cuda time without quantization: 63.960304260253906
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 74.10298919677734
now round: 1
New cuda time without quantization: 31.297672271728516
torch.Size([524288, 768]) torch.qint8
New cuda time: 45.153472900390625
New cuda time without quantization: 52.69841384887695
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 62.970703125
now round: 1
New cuda time without quantization: 56.10448455810547
torch.Size([524288, 768]) torch.qint8
New cuda time: 66.1577377319336
New cuda time without quantization: 54.89680862426758
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.97869873046875
now round: 1
New cuda time without quantization: 53.24833297729492
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.311344146728516
New cuda time without quantization: 54.792327880859375
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.85979461669922
New cuda time without quantization: 56.88569641113281
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.01918029785156
now round: 5
New cuda time without quantization: 166.1949920654297
torch.Size([524288, 768]) torch.qint8
New cuda time: 176.40640258789062
New cuda time without quantization: 54.50792694091797
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.70573425292969
now round: 5
New cuda time without quantization: 54.78024673461914
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.91693115234375
New cuda time without quantization: 57.821224212646484
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.02510070800781
now round: 5
New cuda time without quantization: 50.5111083984375
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.66331100463867
New cuda time without quantization: 58.53050231933594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.83247375488281
now round: 6
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.92494201660156
now round: 1
New cuda time without quantization: 50.19425964355469
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.27007293701172
New cuda time without quantization: 53.086891174316406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.16622543334961
now round: 1
New cuda time without quantization: 54.96432876586914
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.13501739501953
New cuda time without quantization: 39.521488189697266
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 49.78546142578125
now round: 2
New cuda time without quantization: 50.33393859863281
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.37471389770508
New cuda time without quantization: 55.26288986206055
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.37629699707031
now round: 2
New cuda time without quantization: 65.92045593261719
torch.Size([524288, 768]) torch.qint8
New cuda time: 75.97211456298828
New cuda time without quantization: 151.72532653808594
New cuda time without quantization: 50.03873825073242
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 60.18079376220703
now round: 2
New cuda time without quantization: 54.31376647949219
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.34286499023438
New cuda time without quantization: 55.177127838134766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.26814270019531
now round: 2
New cuda time without quantization: 58.4969596862793
torch.Size([524288, 768]) torch.qint8
New cuda time: 68.64988708496094
New cuda time without quantization: 33.794944763183594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 43.96516036987305
now round: 2
New cuda time without quantization: 49.95538330078125
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.99247360229492
New cuda time without quantization: 55.4036865234375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.5047836303711
now round: 2
New cuda time without quantization: 48.293304443359375
torch.Size([524288, 768]) torch.qint8
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.33423614501953
New cuda time without quantization: 35.631099700927734
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 45.8155517578125
now round: 3
New cuda time without quantization: 50.266258239746094
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.40751266479492
New cuda time without quantization: 55.37936782836914
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.44029998779297
now round: 3
New cuda time without quantization: 49.8150634765625
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.858070373535156
New cuda time without quantization: 35.74005889892578
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 45.8974723815918
now round: 3
New cuda time without quantization: 51.64913558959961
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.69854736328125
New cuda time without quantization: 54.67728805541992
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.76686096191406
now round: 3
New cuda time without quantization: 124.85501861572266
now round: 1
New cuda time without quantization: 14765.1298828125
torch.Size([524288, 768]) torch.qint8
New cuda time: 14776.423828125
New cuda time without quantization: 56.10714340209961
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.26908111572266
now round: 1
New cuda time without quantization: 189.22434997558594
torch.Size([524288, 768]) torch.qint8
New cuda time: 199.48118591308594
New cuda time without quantization: 53.26681900024414
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.46651840209961
now round: 1
New cuda time without quantization: 56.12458419799805
torch.Size([524288, 768]) torch.qint8
New cuda time: 66.21580505371094
New cuda time without quantization: 55.082664489746094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.1711654663086
now round: 1
New cuda time without quantization: 46.56728744506836
torch.Size([524288, 768]) torch.qint8
New cuda time: 56.59562301635742
New cuda time without quantization: 61.702674865722656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.8462142944336
now round: 1
New cuda time without quantization: 50.35881423950195
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.41979217529297
New cuda time without quantization: 52.982818603515625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.06380081176758
now round: 1
New cuda time without quantization: 55.213863372802734
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.38204193115234
New cuda time without quantization: 64.64700317382812
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 74.80254364013672
now round: 2
New cuda time without quantization: 53.18122100830078
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.20795822143555
New cuda time without quantization: 55.38954544067383
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.59452056884766
now round: 2
New cuda time without quantization: 49.96585464477539
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.98235321044922
New cuda time without quantization: 70.64237976074219
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 80.73663330078125
now round: 2
New cuda time without quantization: 50.01017761230469
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.045711517333984
New cuda time without quantization: 55.47178268432617
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.54476165771484
now round: 2
New cuda time without quantization: 58.87403106689453
torch.Size([524288, 768]) torch.qint8
New cuda time: 69.01165008544922
New cuda time without quantization: 59.871952056884766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.97245025634766
now round: 2
New cuda time without quantization: 50.24457550048828
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.35115051269531
New cuda time without quantization: 55.582183837890625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.64220428466797
now round: 2
New cuda time without quantization: 48.27353286743164
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.32427215576172
New cuda time without quantization: 61.7277946472168
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.8487777709961
now round: 3
New cuda time without quantization: 42.246158599853516
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.29865646362305
New cuda time without quantization: 55.60346221923828
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.68252563476562
now round: 3
New cuda time without quantization: 49.89129638671875
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.945072174072266
New cuda time without quantization: 60.771636962890625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.9222183227539
now round: 3
New cuda time without quantization: 51.712894439697266
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.77611541748047
New cuda time without quantization: 54.72826385498047
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.81243896484375
now round: 3
New cuda time without quantization: 125.08952331542969
torch.Size([524288, 768]) torch.qint8
New cuda time: 142.99671936035156
New cuda time without quantization: 51.421958923339844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 61.53144073486328
now round: 3
New cuda time without quantization: 50.3592414855957
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.38135528564453
New cuda time without quantization: 55.85606002807617
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.91114044189453
now round: 3
New cuda time without quantization: 91.27780151367188
torch.Size([524288, 768]) torch.qint8
New cuda time: 101.31752014160156
New cuda time without quantization: 46.02770233154297
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 56.13029861450195
now round: 4
New cuda time without quantization: 55.16341781616211
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.20793914794922
New cuda time without quantization: 54.58677673339844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.65369415283203
now round: 4
New cuda time without quantization: 57.110145568847656
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.27946472167969
New cuda time without quantization: 49.23379135131836
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 59.459110260009766
now round: 4
New cuda time without quantization: 153.76524353027344
torch.Size([524288, 768]) torch.qint8
New cuda time: 163.8135986328125
New cuda time without quantization: 57.88694763183594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.98506164550781
now round: 4
New cuda time without quantization: 257.5355529785156
torch.Size([524288, 768]) torch.qint8
New cuda time: 267.6031494140625
New cuda time without quantization: 55.33766174316406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.41881561279297
now round: 4
New cuda time without quantization: 56.654945373535156
torch.Size([524288, 768]) torch.qint8
New cuda time: 66.69418334960938
New cuda time without quantization: 131.73971557617188
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 141.87208557128906
now round: 4
New cuda time without quantization: 49.83667755126953
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.869834899902344
New cuda time without quantization: 268.3234558105469
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 278.5715026855469
now round: 5
New cuda time without quantization: 50.417640686035156
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.446800231933594
New cuda time without quantization: 161.4936065673828
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 171.58291625976562
now round: 5
New cuda time without quantization: 49.948997497558594
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.97975540161133
New cuda time without quantization: 49.04467010498047
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 59.15399169921875
now round: 5
New cuda time without quantization: 50.66292190551758
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.699920654296875
New cuda time without quantization: 57.41910934448242
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.51466369628906
now round: 5
New cuda time without quantization: 50.36708068847656
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.41096115112305
New cuda time without quantization: 162.30096435546875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 172.42579650878906
now round: 5
New cuda time without quantization: 42.441768646240234
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.472049713134766
New cuda time without quantization: 70.9229965209961
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 81.03424072265625
now round: 5
New cuda time without quantization: 50.67987823486328
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.867759704589844
New cuda time without quantization: 51.43604278564453
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 61.6676025390625
now round: 6
New cuda time without quantization: 149.52171325683594
torch.Size([524288, 768]) torch.qint8
torch.Size([524288, 768]) torch.qint8
New cuda time: 134.9261932373047
New cuda time without quantization: 59.17071533203125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.22541046142578
now round: 3
New cuda time without quantization: 50.463539123535156
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.49759292602539
New cuda time without quantization: 55.553768157958984
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.62861633300781
now round: 3
New cuda time without quantization: 91.01990509033203
torch.Size([524288, 768]) torch.qint8
New cuda time: 101.06771850585938
New cuda time without quantization: 55.26288986206055
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.33550262451172
now round: 4
New cuda time without quantization: 55.52960968017578
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.57293701171875
New cuda time without quantization: 54.64400863647461
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.70622253417969
now round: 4
New cuda time without quantization: 33.094947814941406
torch.Size([524288, 768]) torch.qint8
New cuda time: 43.20051956176758
New cuda time without quantization: 56.93104553222656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.03053283691406
now round: 4
New cuda time without quantization: 154.06564331054688
torch.Size([524288, 768]) torch.qint8
New cuda time: 164.10818481445312
New cuda time without quantization: 34.310302734375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 44.434757232666016
now round: 4
New cuda time without quantization: 257.05450439453125
torch.Size([524288, 768]) torch.qint8
New cuda time: 267.1187744140625
New cuda time without quantization: 55.804805755615234
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.90381622314453
now round: 4
New cuda time without quantization: 122.67838287353516
torch.Size([524288, 768]) torch.qint8
New cuda time: 132.93019104003906
New cuda time without quantization: 47.24099349975586
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.382240295410156
now round: 4
New cuda time without quantization: 49.74594497680664
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.78255081176758
New cuda time without quantization: 242.662841796875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 278.3275451660156
now round: 5
New cuda time without quantization: 50.5617790222168
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.58175277709961
New cuda time without quantization: 161.92947387695312
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 172.02975463867188
now round: 5
New cuda time without quantization: 50.01298522949219
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.035030364990234
New cuda time without quantization: 56.335205078125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.42237854003906
now round: 5
New cuda time without quantization: 50.95233917236328
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.9876708984375
New cuda time without quantization: 36.736698150634766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 46.88370895385742
now round: 5
New cuda time without quantization: 46.02579116821289
torch.Size([524288, 768]) torch.qint8
New cuda time: 56.07728576660156
New cuda time without quantization: 170.03233337402344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 180.11534118652344
now round: 5
New cuda time without quantization: 55.48032760620117
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.57549285888672
New cuda time without quantization: 57.85776138305664
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.92572784423828
now round: 5
New cuda time without quantization: 50.55202102661133
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.75855255126953
New cuda time without quantization: 59.03647994995117
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.16476440429688
now round: 6
New cuda time without quantization: 123.31246185302734
torch.Size([524288, 768]) torch.qint8
torch.Size([524288, 768]) torch.qint8
New cuda time: 135.12313842773438
New cuda time without quantization: 59.730831146240234
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.83229064941406
now round: 3
New cuda time without quantization: 42.245521545410156
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.29753494262695
New cuda time without quantization: 55.673065185546875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.75052642822266
now round: 3
New cuda time without quantization: 91.31153869628906
torch.Size([524288, 768]) torch.qint8
New cuda time: 101.3453140258789
New cuda time without quantization: 55.21226501464844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.3622055053711
now round: 4
New cuda time without quantization: 55.46842575073242
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.48524475097656
New cuda time without quantization: 54.717864990234375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.77259826660156
now round: 4
New cuda time without quantization: 57.1793098449707
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.34780883789062
New cuda time without quantization: 57.715309143066406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.80332946777344
now round: 4
New cuda time without quantization: 145.25323486328125
torch.Size([524288, 768]) torch.qint8
New cuda time: 155.3260498046875
New cuda time without quantization: 57.7596321105957
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.86860656738281
now round: 4
New cuda time without quantization: 257.7248229980469
torch.Size([524288, 768]) torch.qint8
New cuda time: 267.7953796386719
New cuda time without quantization: 54.89482498168945
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.95260620117188
now round: 4
New cuda time without quantization: 56.98074722290039
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.05836486816406
New cuda time without quantization: 139.92538452148438
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 150.04605102539062
now round: 4
New cuda time without quantization: 49.882015228271484
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.95115280151367
New cuda time without quantization: 268.24884033203125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 278.4827575683594
now round: 5
New cuda time without quantization: 51.19673538208008
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.242515563964844
New cuda time without quantization: 161.64190673828125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 171.74464416503906
now round: 5
New cuda time without quantization: 50.09321594238281
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.09339141845703
New cuda time without quantization: 47.9188117980957
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 58.01386642456055
now round: 5
New cuda time without quantization: 50.75417709350586
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.77451705932617
New cuda time without quantization: 57.15994644165039
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.26732635498047
now round: 5
New cuda time without quantization: 50.5316162109375
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.60091018676758
New cuda time without quantization: 170.52224731445312
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 180.62274169921875
now round: 5
New cuda time without quantization: 42.71895980834961
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.74953842163086
New cuda time without quantization: 70.99885559082031
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 81.0758285522461
now round: 5
New cuda time without quantization: 41.699440002441406
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.82587432861328
New cuda time without quantization: 59.390830993652344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.49468994140625
now round: 6
New cuda time without quantization: 150.52716064453125
torch.Size([524288, 768]) torch.qint8
now round: 1
New cuda time without quantization: 13767.259765625
torch.Size([524288, 768]) torch.qint8
New cuda time: 13778.71484375
New cuda time without quantization: 64.69654083251953
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 74.81161499023438
now round: 1
New cuda time without quantization: 124.0233154296875
torch.Size([524288, 768]) torch.qint8
New cuda time: 134.09629821777344
New cuda time without quantization: 61.930137634277344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 72.02584838867188
now round: 1
New cuda time without quantization: 48.25408935546875
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.30772018432617
New cuda time without quantization: 55.524192810058594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.6157455444336
now round: 1
New cuda time without quantization: 46.842559814453125
torch.Size([524288, 768]) torch.qint8
New cuda time: 56.893314361572266
New cuda time without quantization: 57.7861213684082
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.924072265625
now round: 1
New cuda time without quantization: 54.5966682434082
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.67462158203125
New cuda time without quantization: 53.56978225708008
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.644859313964844
now round: 1
New cuda time without quantization: 45.22175598144531
torch.Size([524288, 768]) torch.qint8
New cuda time: 55.283233642578125
New cuda time without quantization: 64.70262145996094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 74.83849334716797
now round: 2
New cuda time without quantization: 48.74032974243164
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.77444076538086
New cuda time without quantization: 55.397953033447266
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.62646484375
now round: 2
New cuda time without quantization: 50.595855712890625
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.63108825683594
now round: 1
New cuda time without quantization: 8378.8544921875
torch.Size([524288, 768]) torch.qint8
New cuda time: 8399.408203125
New cuda time without quantization: 55.32600402832031
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.52716827392578
now round: 1
New cuda time without quantization: 111.1811294555664
torch.Size([524288, 768]) torch.qint8
New cuda time: 121.375732421875
New cuda time without quantization: 57.68681716918945
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.04894256591797
now round: 1
New cuda time without quantization: 50.665184020996094
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.8004264831543
New cuda time without quantization: 54.41704177856445
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.57276153564453
now round: 1
New cuda time without quantization: 53.31831741333008
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.578041076660156
New cuda time without quantization: 54.217201232910156
New cuda time without quantization: 66.00918579101562
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 76.0826644897461
now round: 2
New cuda time without quantization: 45.30047607421875
torch.Size([524288, 768]) torch.qint8
New cuda time: 55.42435073852539
New cuda time without quantization: 55.653953552246094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.85382843017578
now round: 2
New cuda time without quantization: 58.71540451049805
torch.Size([524288, 768]) torch.qint8
New cuda time: 68.848876953125
New cuda time without quantization: 59.83252716064453
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.91464233398438
now round: 2
New cuda time without quantization: 50.370094299316406
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.38932800292969
New cuda time without quantization: 55.23299026489258
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.27734375
now round: 2
New cuda time without quantization: 39.346534729003906
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.42732238769531
now round: 1
New cuda time without quantization: 50.0867805480957
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.24474334716797
New cuda time without quantization: 55.68760681152344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.82621002197266
now round: 1
New cuda time without quantization: 52.09687042236328
torch.Size([524288, 768]) torch.qint8
New cuda time: 73.5315170288086
New cuda time without quantization: 52.89815139770508
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.1242790222168
now round: 2
New cuda time without quantization: 51.33606719970703
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.462032318115234
New cuda time without quantization: 54.86264419555664
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.05484771728516
now round: 2
New cuda time without quantization: 65.39453125
torch.Size([524288, 768]) torch.qint8
New cuda time: 75.55569458007812
torch.Size([524288, 768]) torch.qint8
New cuda time: 49.422088623046875
New cuda time without quantization: 62.178775787353516
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 72.23464965820312
now round: 3
New cuda time without quantization: 50.86225509643555
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.0091667175293
New cuda time without quantization: 55.97987365722656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.02694702148438
now round: 3
New cuda time without quantization: 49.850250244140625
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.886287689208984
New cuda time without quantization: 61.216373443603516
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.35784912109375
now round: 3
New cuda time without quantization: 51.9958610534668
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.02789306640625
New cuda time without quantization: 55.03923034667969
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.13382720947266
now round: 3
New cuda time without quantization: 53.25479507446289
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.45100021362305
now round: 2
New cuda time without quantization: 51.23350524902344
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.45947265625
New cuda time without quantization: 54.59960174560547
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.76636505126953
now round: 2
New cuda time without quantization: 58.818660736083984
torch.Size([524288, 768]) torch.qint8
New cuda time: 68.96798706054688
New cuda time without quantization: 59.43770217895508
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.61214447021484
now round: 2
New cuda time without quantization: 50.17686080932617
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.341705322265625
New cuda time without quantization: 53.02631759643555
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.19179916381836
now round: 2
New cuda time without quantization: 50.18102264404297
New cuda time without quantization: 123.48970031738281
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.30730438232422
New cuda time without quantization: 51.03126525878906
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 61.31003189086914
now round: 3
New cuda time without quantization: 51.31510925292969
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.433231353759766
New cuda time without quantization: 54.56087875366211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.73117065429688
now round: 3
New cuda time without quantization: 50.37014389038086
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.47130584716797
New cuda time without quantization: 48.7840576171875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 59.02857971191406
now round: 3
New cuda time without quantization: 50.73574447631836
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.83578872680664
New cuda time without quantization: 54.56919860839844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.74540710449219
now round: 3
torch.Size([524288, 768]) torch.qint8
New cuda time: 133.6500701904297
New cuda time without quantization: 61.53413009643555
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.62825012207031
now round: 3
New cuda time without quantization: 50.704017639160156
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.74612808227539
New cuda time without quantization: 54.417789459228516
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.4658203125
now round: 3
New cuda time without quantization: 33.40667724609375
torch.Size([524288, 768]) torch.qint8
New cuda time: 43.59135055541992
New cuda time without quantization: 55.449310302734375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.58246612548828
now round: 4
New cuda time without quantization: 55.5838737487793
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.59846496582031
New cuda time without quantization: 55.212032318115234
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.28102111816406
now round: 4
New cuda time without quantization: 132.24554443359375
New cuda time without quantization: 57.43492126464844
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.57655334472656
New cuda time without quantization: 57.835880279541016
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.92279052734375
now round: 4
New cuda time without quantization: 31.28154754638672
torch.Size([524288, 768]) torch.qint8
New cuda time: 41.35502243041992
New cuda time without quantization: 58.03715896606445
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.14551544189453
now round: 4
New cuda time without quantization: 257.0533752441406
torch.Size([524288, 768]) torch.qint8
New cuda time: 267.0993347167969
New cuda time without quantization: 56.039554595947266
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.121826171875
now round: 4
New cuda time without quantization: 150.12098693847656
torch.Size([524288, 768]) torch.qint8
New cuda time: 160.30471801757812
New cuda time without quantization: 46.46160125732422
torch.Size([524288, 768]) torch.qint8
New cuda time: 142.3998260498047
New cuda time without quantization: 51.51062774658203
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 61.68155288696289
now round: 3
New cuda time without quantization: 50.1671028137207
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.26426315307617
New cuda time without quantization: 54.21879959106445
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.39932250976562
now round: 3
New cuda time without quantization: 86.4626235961914
torch.Size([524288, 768]) torch.qint8
New cuda time: 96.60794067382812
New cuda time without quantization: 60.968910217285156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.20863342285156
now round: 4
New cuda time without quantization: 53.9039192199707
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.03580474853516
New cuda time without quantization: 55.78232955932617
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.93069458007812
now round: 4
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 56.61219787597656
now round: 4
New cuda time without quantization: 50.6724967956543
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.68532943725586
New cuda time without quantization: 268.5252380371094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 278.7264099121094
now round: 5
New cuda time without quantization: 171.50730895996094
torch.Size([524288, 768]) torch.qint8
New cuda time: 181.57998657226562
New cuda time without quantization: 41.79822540283203
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 51.850738525390625
now round: 5
New cuda time without quantization: 50.33073425292969
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.35396957397461
New cuda time without quantization: 56.83859634399414
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.9075927734375
now round: 5
New cuda time without quantization: 51.39265441894531
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.41621017456055
New cuda time without quantization: 56.67049026489258
torch.Size([524288, 768]) torch.qint8
New cuda time: 66.81645965576172
New cuda time without quantization: 57.47897720336914
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.73534393310547
now round: 4
New cuda time without quantization: 153.9485321044922
torch.Size([524288, 768]) torch.qint8
New cuda time: 164.08616638183594
New cuda time without quantization: 57.00169372558594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.2097396850586
now round: 4
New cuda time without quantization: 257.6246643066406
torch.Size([524288, 768]) torch.qint8
New cuda time: 267.75189208984375
New cuda time without quantization: 54.73784255981445
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.89628601074219
now round: 4
New cuda time without quantization: 141.7412567138672
torch.Size([524288, 768]) torch.qint8
New cuda time: 151.8976287841797
New cuda time without quantization: 53.0640754699707
New cuda time without quantization: 57.38483810424805
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.45447540283203
now round: 5
New cuda time without quantization: 167.07833862304688
torch.Size([524288, 768]) torch.qint8
New cuda time: 177.1161346435547
New cuda time without quantization: 54.47091293334961
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.5709457397461
now round: 5
New cuda time without quantization: 42.77054977416992
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.80770492553711
New cuda time without quantization: 71.4164047241211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 81.502197265625
now round: 5
New cuda time without quantization: 50.7398567199707
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.89588928222656
New cuda time without quantization: 59.66708755493164
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.76439666748047
now round: 6
New cuda time without quantization: 31.402027130126953
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.22587966918945
now round: 4
New cuda time without quantization: 51.73542785644531
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.854671478271484
New cuda time without quantization: 267.791259765625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 277.9873352050781
now round: 5
New cuda time without quantization: 49.24661636352539
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.379302978515625
New cuda time without quantization: 162.95399475097656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 173.14236450195312
now round: 5
New cuda time without quantization: 49.7387809753418
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.862022399902344
New cuda time without quantization: 56.849693298339844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.04541778564453
now round: 5
New cuda time without quantization: 50.488704681396484
torch.Size([524288, 768]) torch.qint8
torch.Size([524288, 768]) torch.qint8
New cuda time: 41.464942932128906
New cuda time: 60.771949768066406
New cuda time without quantization: 61.360111236572266
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.52960205078125
now round: 5
New cuda time without quantization: 161.77032470703125
torch.Size([524288, 768]) torch.qint8
New cuda time: 171.92413330078125
New cuda time without quantization: 54.38471984863281
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.56204986572266
now round: 5
New cuda time without quantization: 54.63911819458008
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.74188995361328
New cuda time without quantization: 47.70853042602539
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.92105484008789
now round: 5
New cuda time without quantization: 50.55382537841797
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.68266677856445
New cuda time without quantization: 58.39385986328125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.67550659179688
now round: 6
New cuda time without quantization: 151.00035095214844
torch.Size([524288, 768]) torch.qint8
now round: 1
New cuda time without quantization: 9930.5908203125
torch.Size([524288, 768]) torch.qint8
New cuda time: 9954.2802734375
New cuda time without quantization: 55.14240646362305
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.37286376953125
now round: 1
New cuda time without quantization: 54.99936294555664
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.18118286132812
New cuda time without quantization: 57.79825973510742
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.07991790771484
now round: 1
New cuda time without quantization: 50.78221893310547
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.94804000854492
New cuda time without quantization: 54.15840148925781
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.3210220336914
now round: 1
New cuda time without quantization: 53.400474548339844
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.537174224853516
New cuda time without quantization: 54.23455810546875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.4658203125
now round: 1
New cuda time without quantization: 50.02861785888672
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.17715072631836
New cuda time without quantization: 54.532798767089844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.6898193359375
now round: 1
New cuda time without quantization: 53.10639190673828
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.46501541137695
New cuda time without quantization: 53.53007507324219
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.7963752746582
now round: 2
New cuda time without quantization: 50.90317916870117
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.03507995605469
New cuda time without quantization: 54.74736404418945
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.94950103759766
now round: 2
New cuda time without quantization: 63.1038932800293
torch.Size([524288, 768]) torch.qint8
New cuda time: 73.23963165283203
New cuda time without quantization: 56.344810485839844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.55062866210938
now round: 2
New cuda time without quantization: 50.42397689819336
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.66211700439453
New cuda time without quantization: 54.50912094116211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.70390319824219
now round: 2
New cuda time without quantization: 47.39179992675781
torch.Size([524288, 768]) torch.qint8
New cuda time: 57.52690124511719
New cuda time without quantization: 70.52457427978516
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 80.68080139160156
now round: 2
New cuda time without quantization: 50.22141647338867
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.381317138671875
New cuda time without quantization: 52.943511962890625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.10469055175781
now round: 2
New cuda time without quantization: 50.20237731933594
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.32051467895508
New cuda time without quantization: 60.59796142578125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.77625274658203
now round: 3
New cuda time without quantization: 51.37646484375
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.508365631103516
New cuda time without quantization: 54.20256042480469
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.3750991821289
now round: 3
New cuda time without quantization: 50.365577697753906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.48019790649414
New cuda time without quantization: 60.425636291503906
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.64665222167969
now round: 3
New cuda time without quantization: 50.630218505859375
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.75508117675781
New cuda time without quantization: 54.346561431884766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.52117919921875
now round: 3
New cuda time without quantization: 39.98823547363281
now round: 1
New cuda time without quantization: 4386.02734375
torch.Size([524288, 768]) torch.qint8
New cuda time: 4410.8369140625
New cuda time without quantization: 55.09495162963867
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.3100357055664
now round: 1
New cuda time without quantization: 130.32421875
torch.Size([524288, 768]) torch.qint8
New cuda time: 140.5271453857422
New cuda time without quantization: 57.640403747558594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.00396728515625
now round: 1
New cuda time without quantization: 50.558292388916016
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.73273468017578
New cuda time without quantization: 53.772708892822266
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.93514633178711
now round: 1
New cuda time without quantization: 50.85237121582031
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.971134185791016
New cuda time without quantization: 56.74359893798828
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.98011779785156
now round: 1
New cuda time without quantization: 50.13844680786133
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.311771392822266
New cuda time without quantization: 55.383113861083984
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.55835723876953
now round: 1
New cuda time without quantization: 52.17926025390625
torch.Size([524288, 768]) torch.qint8
New cuda time: 72.19758605957031
New cuda time without quantization: 53.545982360839844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.832908630371094
now round: 2
New cuda time without quantization: 52.71718215942383
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.83242416381836
New cuda time without quantization: 54.67991256713867
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.865234375
now round: 2
New cuda time without quantization: 62.77386474609375
torch.Size([524288, 768]) torch.qint8
New cuda time: 72.8857421875
New cuda time without quantization: 56.648719787597656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.88860321044922
now round: 2
New cuda time without quantization: 50.23237228393555
torch.Size([524288, 768]) torch.qint8
New cuda time: 66.61788177490234
New cuda time without quantization: 48.26372528076172
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 58.43400573730469
now round: 2
New cuda time without quantization: 47.052520751953125
torch.Size([524288, 768]) torch.qint8
New cuda time: 57.18008041381836
New cuda time without quantization: 70.5892562866211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 80.7593765258789
now round: 2
New cuda time without quantization: 50.10724639892578
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.220733642578125
New cuda time without quantization: 52.82022476196289
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 62.964744567871094
now round: 2
New cuda time without quantization: 54.3885498046875
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.48619079589844
New cuda time without quantization: 49.42148971557617
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 59.60664749145508
now round: 3
New cuda time without quantization: 51.80021667480469
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.90393829345703
New cuda time without quantization: 54.03894805908203
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.20394897460938
now round: 3
New cuda time without quantization: 50.14229202270508
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.25353240966797
New cuda time without quantization: 60.09977340698242
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.26189422607422
now round: 3
New cuda time without quantization: 50.65781021118164
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.773536682128906
New cuda time without quantization: 47.773319244384766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 58.05176544189453
now round: 3
New cuda time without quantization: 114.51952362060547
New cuda time: 161.14599609375
torch.Size([524288, 768]) torch.qint8
New cuda time: 50.23597717285156
New cuda time without quantization: 51.39886474609375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 61.57540512084961
now round: 3
New cuda time without quantization: 50.18461608886719
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.30483627319336
New cuda time without quantization: 54.07855987548828
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.26006317138672
now round: 3
New cuda time without quantization: 86.55155181884766
torch.Size([524288, 768]) torch.qint8
New cuda time: 96.73736572265625
New cuda time without quantization: 60.82691955566406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.03753662109375
now round: 4
New cuda time without quantization: 31.80914878845215
torch.Size([524288, 768]) torch.qint8
New cuda time: 42.07720947265625
New cuda time without quantization: 54.45792007446289
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.61494445800781
now round: 4
New cuda time without quantization: 56.669776916503906
torch.Size([524288, 768]) torch.qint8
New cuda time: 66.80135345458984
New cuda time without quantization: 57.6291389465332
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.89320373535156
now round: 4
New cuda time without quantization: 153.79867553710938
torch.Size([524288, 768]) torch.qint8
New cuda time: 163.94801330566406
New cuda time without quantization: 49.37837219238281
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 59.542911529541016
now round: 4
New cuda time without quantization: 265.43389892578125
torch.Size([524288, 768]) torch.qint8
New cuda time: 275.73858642578125
New cuda time without quantization: 54.06079864501953
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.21749877929688
now round: 4
New cuda time without quantization: 138.2371368408203
torch.Size([524288, 768]) torch.qint8
New cuda time: 148.38856506347656
New cuda time without quantization: 56.603214263916016
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.85191345214844
now round: 4
New cuda time without quantization: 51.70414352416992
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.8525276184082
New cuda time without quantization: 34.080841064453125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 44.42554473876953
now round: 5
New cuda time without quantization: 48.27004623413086
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.389625549316406
New cuda time without quantization: 162.18112182617188
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 172.36294555664062
now round: 5
New cuda time without quantization: 50.609901428222656
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.7264404296875
New cuda time without quantization: 37.224700927734375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 47.379638671875
now round: 5
New cuda time without quantization: 50.524139404296875
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.78499984741211
New cuda time without quantization: 56.4803352355957
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.63543701171875
now round: 5
New cuda time without quantization: 166.17059326171875
torch.Size([524288, 768]) torch.qint8
New cuda time: 176.31640625
New cuda time without quantization: 54.6353645324707
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.80614471435547
now round: 5
New cuda time without quantization: 54.803524017333984
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.914306640625
New cuda time without quantization: 57.48978042602539
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.68952178955078
now round: 5
New cuda time without quantization: 50.765098571777344
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.91971969604492
New cuda time without quantization: 38.951271057128906
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 49.104286193847656
now round: 6
New cuda time without quantization: 151.0084228515625
torch.Size([524288, 768]) torch.qint8
torch.Size([524288, 768]) torch.qint8
New cuda time: 124.63829040527344
New cuda time without quantization: 68.70396423339844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 78.87248992919922
now round: 3
New cuda time without quantization: 50.18821334838867
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.2829704284668
New cuda time without quantization: 54.00758743286133
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.17179107666016
now round: 3
New cuda time without quantization: 92.49911499023438
torch.Size([524288, 768]) torch.qint8
New cuda time: 102.850830078125
New cuda time without quantization: 54.14742660522461
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.34107208251953
now round: 4
New cuda time without quantization: 52.952064514160156
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.05818557739258
New cuda time without quantization: 56.19943618774414
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.37371826171875
now round: 4
New cuda time without quantization: 56.570960998535156
torch.Size([524288, 768]) torch.qint8
New cuda time: 66.700439453125
New cuda time without quantization: 57.2423210144043
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.52204895019531
now round: 4
New cuda time without quantization: 153.80113220214844
torch.Size([524288, 768]) torch.qint8
New cuda time: 163.9552459716797
New cuda time without quantization: 50.26405334472656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 60.4343376159668
now round: 4
New cuda time without quantization: 44.01474380493164
torch.Size([524288, 768]) torch.qint8
New cuda time: 54.135108947753906
New cuda time without quantization: 274.7595520019531
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 284.973388671875
now round: 4
New cuda time without quantization: 149.77392578125
torch.Size([524288, 768]) torch.qint8
New cuda time: 160.068359375
New cuda time without quantization: 44.66594696044922
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 54.916072845458984
now round: 4
New cuda time without quantization: 51.60629653930664
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.73514175415039
New cuda time without quantization: 267.1692810058594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 277.3304748535156
now round: 5
New cuda time without quantization: 170.72935485839844
torch.Size([524288, 768]) torch.qint8
New cuda time: 180.99436950683594
New cuda time without quantization: 40.34401321411133
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 50.50693130493164
now round: 5
New cuda time without quantization: 49.77525329589844
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.921051025390625
New cuda time without quantization: 56.641841888427734
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.80908203125
now round: 5
New cuda time without quantization: 50.54117202758789
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.78985595703125
New cuda time without quantization: 56.393680572509766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.55835723876953
now round: 5
New cuda time without quantization: 160.19747924804688
torch.Size([524288, 768]) torch.qint8
New cuda time: 170.3919219970703
New cuda time without quantization: 54.36103057861328
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.51322937011719
now round: 5
New cuda time without quantization: 54.443111419677734
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.54843139648438
New cuda time without quantization: 57.62008285522461
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.78765106201172
now round: 5
New cuda time without quantization: 50.698455810546875
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.84457778930664
New cuda time without quantization: 50.51941680908203
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.45148468017578
now round: 6
New cuda time without quantization: 151.63839721679688
torch.Size([524288, 768]) torch.qint8
New cuda time: 161.7462921142578
New cuda time: 161.14224243164062
New cuda time without quantization: 55.7677116394043
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.95111083984375
now round: 6
New cuda time without quantization: 51.294898986816406
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.71957778930664
New cuda time without quantization: 47.14464569091797
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.219398498535156
now round: 6
New cuda time without quantization: 65.40454864501953
torch.Size([524288, 768]) torch.qint8
New cuda time: 75.43866729736328
New cuda time without quantization: 164.0697021484375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 174.15565490722656
now round: 6
New cuda time without quantization: 53.16530227661133
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.22214126586914
New cuda time without quantization: 58.86628341674805
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.96135711669922
now round: 6
New cuda time without quantization: 54.9859504699707
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.04998779296875
New cuda time without quantization: 55.10403060913086
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.22822570800781
now round: 6
New cuda time without quantization: 53.07778549194336
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.12070083618164
New cuda time without quantization: 59.14292526245117
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.23544311523438
now round: 7
New cuda time without quantization: 50.83393478393555
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.91861343383789
New cuda time without quantization: 149.8064422607422
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 159.915283203125
now round: 7
New cuda time without quantization: 264.2066955566406
torch.Size([524288, 768]) torch.qint8
New cuda time: 274.27728271484375
New cuda time without quantization: 58.54756546020508
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.62120056152344
now round: 7
New cuda time without quantization: 48.776329040527344
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.973323822021484
New cuda time without quantization: 61.41301727294922
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.51705169677734
now round: 7
New cuda time without quantization: 50.06305694580078
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.08820724487305
New cuda time without quantization: 284.12994384765625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 294.2339782714844
now round: 7
New cuda time without quantization: 42.34446716308594
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.37682342529297
New cuda time without quantization: 55.59811782836914
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.67015075683594
now round: 7
New cuda time without quantization: 51.143856048583984
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.173973083496094
New cuda time without quantization: 58.14036560058594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.22535705566406
now round: 8
New cuda time without quantization: 51.92802047729492
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.979896545410156
New cuda time without quantization: 184.01776123046875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 194.1169891357422
now round: 8
New cuda time without quantization: 50.3187370300293
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.483253479003906
New cuda time without quantization: 56.012996673583984
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.09895324707031
now round: 8
New cuda time without quantization: 50.64913558959961
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.835411071777344
New cuda time without quantization: 55.17059326171875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.23574829101562
now round: 8
New cuda time without quantization: 42.19166946411133
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.3417854309082
New cuda time without quantization: 268.6947021484375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 278.8428649902344
now round: 8
New cuda time without quantization: 50.189937591552734
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.22100830078125
New cuda time without quantization: 60.786293029785156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.89736938476562
now round: 8
New cuda time without quantization: 50.742897033691406
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.77397155761719
New cuda time without quantization: 55.32931137084961
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.40119171142578
now round: 9
New cuda time without quantization: 175.71820068359375
torch.Size([524288, 768]) torch.qint8
New cuda time: 185.82017517089844
New cuda time without quantization: 54.813472747802734
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.88983154296875
now round: 9
New cuda time without quantization: 67.71144104003906
torch.Size([524288, 768]) torch.qint8
New cuda time: 77.73883056640625
New cuda time without quantization: 55.44163513183594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.51174926757812
now round: 9
New cuda time without quantization: 58.92852783203125
torch.Size([524288, 768]) torch.qint8
New cuda time: 68.96311950683594
New cuda time without quantization: 55.02627182006836
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.13063049316406
now round: 9
New cuda time without quantization: 171.55772399902344
torch.Size([524288, 768]) torch.qint8
New cuda time: 181.63856506347656
New cuda time without quantization: 46.40544509887695
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 56.48548126220703
now round: 9
New cuda time without quantization: 50.939701080322266
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.94837188720703
New cuda time without quantization: 150.46533203125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 160.5639190673828
now round: 9
New cuda time without quantization: 50.203697204589844
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.26277160644531
New cuda time without quantization: 232.44561767578125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 242.5546112060547
now round: 10
New cuda time without quantization: 42.278228759765625
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.28626251220703
New cuda time without quantization: 55.118431091308594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.17350769042969
now round: 10
New cuda time without quantization: 50.72465515136719
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.74629211425781
New cuda time without quantization: 141.00193786621094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 151.07205200195312
now round: 10
New cuda time without quantization: 31.41050910949707
torch.Size([524288, 768]) torch.qint8
New cuda time: 159.86935424804688
New cuda time without quantization: 55.37107467651367
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.45927429199219
now round: 10
New cuda time without quantization: 50.822261810302734
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.046295166015625
New cuda time without quantization: 55.731075286865234
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.79351043701172
now round: 10
New cuda time without quantization: 50.46401596069336
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.48341369628906
New cuda time without quantization: 55.78227615356445
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.839111328125
now round: 10
New cuda time without quantization: 162.16249084472656
torch.Size([524288, 768]) torch.qint8
New cuda time: 172.40220642089844
New cuda time without quantization: 54.921630859375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.01046752929688
now round: 11
New cuda time without quantization: 50.95602035522461
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.96821594238281
New cuda time without quantization: 54.69955062866211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time without quantization: 55.35032653808594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.56317138671875
now round: 6
New cuda time without quantization: 50.94502258300781
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.06475067138672
New cuda time without quantization: 60.56026840209961
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.73599243164062
now round: 6
New cuda time without quantization: 51.9045524597168
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.02619171142578
New cuda time without quantization: 162.00296020507812
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 172.17709350585938
now round: 6
New cuda time without quantization: 44.849159240722656
torch.Size([524288, 768]) torch.qint8
New cuda time: 54.99000549316406
New cuda time without quantization: 73.29664611816406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 83.62356567382812
now round: 6
New cuda time without quantization: 47.649173736572266
New cuda time: 159.57357788085938
New cuda time without quantization: 55.55830001831055
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.64441680908203
now round: 6
New cuda time without quantization: 49.10755157470703
torch.Size([524288, 768]) torch.qint8
New cuda time: 68.04058837890625
New cuda time without quantization: 40.79328155517578
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 50.895721435546875
now round: 6
New cuda time without quantization: 64.8936996459961
torch.Size([524288, 768]) torch.qint8
New cuda time: 74.93085479736328
New cuda time without quantization: 46.579063415527344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 56.761505126953125
now round: 6
New cuda time without quantization: 169.6582794189453
torch.Size([524288, 768]) torch.qint8
New cuda time: 179.73269653320312
New cuda time without quantization: 58.38951110839844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.501708984375
now round: 6
torch.Size([524288, 768]) torch.qint8
New cuda time: 57.780574798583984
New cuda time without quantization: 54.651123046875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.83500671386719
now round: 6
New cuda time without quantization: 52.64519119262695
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.88235855102539
New cuda time without quantization: 57.668575286865234
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.83070373535156
now round: 7
New cuda time without quantization: 46.91556930541992
torch.Size([524288, 768]) torch.qint8
New cuda time: 57.051612854003906
New cuda time without quantization: 148.78065490722656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 158.93093872070312
now round: 7
New cuda time without quantization: 264.3279113769531
torch.Size([524288, 768]) torch.qint8
New cuda time: 274.4893798828125
New cuda time without quantization: 57.86329650878906
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.02670288085938
now round: 7
New cuda time without quantization: 54.62869644165039
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.66585540771484
New cuda time without quantization: 54.985496520996094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.04217529296875
now round: 6
New cuda time without quantization: 45.09105682373047
torch.Size([524288, 768]) torch.qint8
New cuda time: 55.193016052246094
New cuda time without quantization: 58.67591094970703
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.76891326904297
now round: 7
New cuda time without quantization: 49.66179656982422
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.71639633178711
New cuda time without quantization: 47.42226791381836
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.53622817993164
now round: 7
New cuda time without quantization: 370.3321838378906
torch.Size([524288, 768]) torch.qint8
New cuda time: 380.4154357910156
New cuda time without quantization: 53.9035758972168
New cuda time without quantization: 51.157989501953125
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.291473388671875
New cuda time without quantization: 53.73720169067383
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.89676284790039
now round: 7
New cuda time without quantization: 53.42599868774414
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.54331970214844
New cuda time without quantization: 173.77069091796875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 183.9376220703125
now round: 7
New cuda time without quantization: 152.06851196289062
torch.Size([524288, 768]) torch.qint8
New cuda time: 162.1997528076172
New cuda time without quantization: 54.953529357910156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.12108612060547
now round: 7
New cuda time without quantization: 50.517024993896484
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.66347122192383
New cuda time without quantization: 58.20682144165039
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.01289367675781
now round: 7
New cuda time without quantization: 51.91700744628906
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.191287994384766
New cuda time without quantization: 57.754947662353516
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.86779022216797
now round: 7
New cuda time without quantization: 49.692996978759766
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.75175476074219
New cuda time without quantization: 55.288700103759766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.4032974243164
now round: 7
New cuda time without quantization: 270.63885498046875
torch.Size([524288, 768]) torch.qint8
New cuda time: 280.7894287109375
New cuda time without quantization: 54.91301727294922
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.07241821289062
now round: 7
New cuda time without quantization: 50.69060134887695
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.72071838378906
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.37518310546875
now round: 8
New cuda time without quantization: 48.40485763549805
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.51689910888672
New cuda time without quantization: 182.1020965576172
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 192.29318237304688
now round: 8
New cuda time without quantization: 50.17318344116211
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.30634689331055
New cuda time without quantization: 56.337852478027344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.54509735107422
now round: 8
New cuda time without quantization: 50.24150466918945
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.37098693847656
New cuda time without quantization: 54.7525634765625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.8934097290039
now round: 8
New cuda time without quantization: 57.6732177734375
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.78254699707031
New cuda time without quantization: 59.353515625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.45243072509766
now round: 8
New cuda time without quantization: 49.79092025756836
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.86167526245117
New cuda time without quantization: 146.2244110107422
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 156.31935119628906
now round: 8
New cuda time without quantization: 81.1297607421875
torch.Size([524288, 768]) torch.qint8
New cuda time: 91.1805191040039
New cuda time without quantization: 53.129173278808594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.33369064331055
now round: 8
New cuda time without quantization: 50.259559631347656
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.321678161621094
New cuda time without quantization: 55.31222152709961
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.40409851074219
now round: 8
New cuda time without quantization: 41.615684509277344
New cuda time without quantization: 161.24871826171875
torch.Size([524288, 768]) torch.qint8
New cuda time: 51.757484436035156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 171.40797424316406
now round: 8
New cuda time without quantization: 140.17950439453125
torch.Size([524288, 768]) torch.qint8
New cuda time: 150.308837890625
New cuda time without quantization: 58.47002029418945
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.88896179199219
now round: 8
New cuda time without quantization: 50.46134567260742
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.56043243408203
New cuda time without quantization: 54.383445739746094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.55804443359375
now round: 9
New cuda time without quantization: 174.67807006835938
torch.Size([524288, 768]) torch.qint8
New cuda time: 184.822265625
New cuda time without quantization: 54.65800476074219
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.80620574951172
now round: 9
New cuda time without quantization: 66.28925323486328
torch.Size([524288, 768]) torch.qint8
New cuda time: 76.39602661132812
New cuda time: 133.36619567871094
New cuda time without quantization: 55.15968704223633
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.2426986694336
now round: 6
New cuda time without quantization: 51.2646598815918
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.42287063598633
New cuda time without quantization: 61.6473503112793
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.81611633300781
now round: 6
New cuda time without quantization: 51.147701263427734
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.18095016479492
New cuda time without quantization: 47.5457878112793
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.74816131591797
now round: 6
New cuda time without quantization: 168.3809814453125
torch.Size([524288, 768]) torch.qint8
New cuda time: 178.43663024902344
New cuda time without quantization: 39.239410400390625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 49.342262268066406
now round: 6
New cuda time without quantization: 55.3565673828125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.51469421386719
now round: 9
New cuda time without quantization: 55.65224838256836
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.7745361328125
New cuda time without quantization: 55.01432800292969
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.16812896728516
now round: 9
New cuda time without quantization: 149.3513946533203
torch.Size([524288, 768]) torch.qint8
New cuda time: 159.49960327148438
New cuda time without quantization: 67.5969467163086
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 77.76387023925781
now round: 9
New cuda time without quantization: 49.7341423034668
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.873069763183594
New cuda time without quantization: 149.7069091796875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 159.89559936523438
now round: 9
New cuda time without quantization: 50.423583984375
New cuda time without quantization: 48.166587829589844
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.202239990234375
New cuda time without quantization: 54.68480682373047
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.79566192626953
now round: 6
New cuda time without quantization: 52.84193420410156
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.89662551879883
New cuda time without quantization: 34.192543029785156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 44.4520378112793
now round: 7
New cuda time without quantization: 50.17378234863281
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.23887252807617
New cuda time without quantization: 47.23267364501953
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.354400634765625
now round: 7
New cuda time without quantization: 365.9747009277344
torch.Size([524288, 768]) torch.qint8
New cuda time: 376.1476135253906
New cuda time without quantization: 57.809600830078125
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.558990478515625
New cuda time without quantization: 146.43585205078125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 156.6075897216797
now round: 10
New cuda time without quantization: 127.4197769165039
torch.Size([524288, 768]) torch.qint8
New cuda time: 137.66845703125
New cuda time without quantization: 54.738487243652344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.88925170898438
now round: 10
New cuda time without quantization: 50.288543701171875
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.408592224121094
New cuda time without quantization: 47.02933120727539
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.17881774902344
now round: 10
New cuda time without quantization: 242.03485107421875
torch.Size([524288, 768]) torch.qint8
New cuda time: 252.19650268554688
New cuda time without quantization: 55.08680725097656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.24797058105469
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.91981506347656
now round: 7
New cuda time without quantization: 48.350746154785156
torch.Size([524288, 768]) torch.qint8
New cuda time: 84.2892074584961
New cuda time without quantization: 34.097347259521484
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 44.17475891113281
now round: 7
New cuda time without quantization: 50.806739807128906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.822872161865234
New cuda time without quantization: 54.979209899902344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.07950592041016
now round: 7
New cuda time without quantization: 270.6995849609375
torch.Size([524288, 768]) torch.qint8
New cuda time: 280.7765197753906
New cuda time without quantization: 54.93952941894531
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.05582427978516
now round: 7
New cuda time without quantization: 50.89377975463867
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.932151794433594
now round: 10
New cuda time without quantization: 50.07350540161133
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.17451095581055
New cuda time without quantization: 55.141849517822266
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.42093658447266
now round: 10
New cuda time without quantization: 50.294464111328125
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.43931198120117
New cuda time without quantization: 54.94296646118164
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.21517181396484
now round: 10
New cuda time without quantization: 137.14862060546875
torch.Size([524288, 768]) torch.qint8
New cuda time: 147.26370239257812
New cuda time without quantization: 78.55570983886719
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 88.80216217041016
now round: 11
New cuda time without quantization: 50.16582489013672
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.269073486328125
New cuda time without quantization: 54.4420051574707
New cuda time without quantization: 34.41414260864258
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 44.59603500366211
now round: 8
New cuda time without quantization: 50.1595458984375
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.239837646484375
New cuda time without quantization: 146.3631134033203
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 156.46356201171875
now round: 8
New cuda time without quantization: 89.3560791015625
torch.Size([524288, 768]) torch.qint8
New cuda time: 99.48804473876953
New cuda time without quantization: 53.324337005615234
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.440948486328125
now round: 8
New cuda time without quantization: 50.26946258544922
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.30255126953125
New cuda time without quantization: 54.91617202758789
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.98990631103516
now round: 8
New cuda time without quantization: 58.822078704833984
torch.Size([8, 64, 1024, 768]) torch.qint8
torch.Size([524288, 768]) torch.qint8
New cuda time: 68.88909149169922
New cuda time: 64.616455078125
New cuda time: 160.58990478515625
New cuda time without quantization: 55.53898239135742
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.672607421875
now round: 6
New cuda time without quantization: 51.30089569091797
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.81403732299805
New cuda time without quantization: 46.966007232666016
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.04890823364258
now round: 6
New cuda time without quantization: 65.10508728027344
torch.Size([524288, 768]) torch.qint8
New cuda time: 75.13550567626953
New cuda time without quantization: 54.13914489746094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.22428131103516
now round: 6
New cuda time without quantization: 162.5019073486328
torch.Size([524288, 768]) torch.qint8
New cuda time: 172.55679321289062
New cuda time without quantization: 58.4281120300293
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.52349090576172
now round: 6
New cuda time: 161.86778259277344
New cuda time without quantization: 55.297691345214844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.4404525756836
now round: 6
New cuda time without quantization: 57.78634262084961
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.94414520263672
New cuda time without quantization: 53.96280288696289
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.15805053710938
now round: 6
New cuda time without quantization: 47.901336669921875
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.03642272949219
New cuda time without quantization: 166.29083251953125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 176.49696350097656
now round: 6
New cuda time without quantization: 44.59891891479492
torch.Size([524288, 768]) torch.qint8
New cuda time: 54.749366760253906
New cuda time without quantization: 66.72142028808594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 77.02275085449219
now round: 6
New cuda time without quantization: 55.0321044921875
torch.Size([524288, 768]) torch.qint8
New cuda time: 65.05756378173828
New cuda time without quantization: 55.12090301513672
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.24012756347656
now round: 6
New cuda time without quantization: 52.857540130615234
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.89500045776367
New cuda time without quantization: 58.80763244628906
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.91324615478516
now round: 7
New cuda time without quantization: 50.82585525512695
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.90571594238281
New cuda time without quantization: 44.25496292114258
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 54.362342834472656
now round: 7
New cuda time without quantization: 363.36102294921875
torch.Size([524288, 768]) torch.qint8
New cuda time: 373.4623107910156
New cuda time without quantization: 53.76890563964844
New cuda time without quantization: 44.46900177001953
torch.Size([524288, 768]) torch.qint8
New cuda time: 54.6743278503418
New cuda time without quantization: 54.70056915283203
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.94013977050781
now round: 6
New cuda time without quantization: 52.59751892089844
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.84220504760742
New cuda time without quantization: 50.48470687866211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 60.68635559082031
now round: 7
New cuda time without quantization: 51.07575225830078
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.20283508300781
New cuda time without quantization: 143.78176879882812
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 154.1077423095703
now round: 7
New cuda time without quantization: 273.7261962890625
torch.Size([524288, 768]) torch.qint8
New cuda time: 284.0564880371094
New cuda time without quantization: 53.43448257446289
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.87147903442383
now round: 7
New cuda time without quantization: 48.415611267089844
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.63579177856445
New cuda time without quantization: 61.074676513671875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.16093444824219
now round: 7
New cuda time without quantization: 49.82441711425781
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.99099349975586
New cuda time without quantization: 50.660736083984375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 60.79179763793945
now round: 7
New cuda time without quantization: 270.87249755859375
torch.Size([524288, 768]) torch.qint8
New cuda time: 280.9296569824219
New cuda time without quantization: 55.22314453125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.46092224121094
now round: 7
New cuda time without quantization: 50.65513610839844
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.69963455200195
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.6071662902832
now round: 7
New cuda time without quantization: 51.14535140991211
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.339481353759766
New cuda time without quantization: 57.661224365234375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.85406494140625
now round: 7
New cuda time without quantization: 49.42406463623047
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.562191009521484
New cuda time without quantization: 55.852577209472656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.99726104736328
now round: 7
New cuda time without quantization: 270.4161071777344
torch.Size([524288, 768]) torch.qint8
New cuda time: 280.5910339355469
New cuda time without quantization: 55.22665023803711
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.47037506103516
now round: 7
New cuda time without quantization: 50.565673828125
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.90939712524414
New cuda time without quantization: 56.932586669921875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.03900909423828
now round: 8
New cuda time without quantization: 52.31658172607422
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.40684127807617
New cuda time without quantization: 146.360595703125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 156.47422790527344
now round: 8
New cuda time without quantization: 81.05342864990234
torch.Size([524288, 768]) torch.qint8
New cuda time: 91.11969757080078
New cuda time without quantization: 62.07931900024414
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 72.18397521972656
now round: 8
New cuda time without quantization: 50.39161682128906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.452274322509766
New cuda time without quantization: 55.003143310546875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.07164764404297
now round: 8
New cuda time without quantization: 41.89543914794922
New cuda time without quantization: 58.04634475708008
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.21599578857422
now round: 8
New cuda time without quantization: 50.73271179199219
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.892757415771484
New cuda time without quantization: 60.87323760986328
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.11376190185547
now round: 8
New cuda time without quantization: 52.49480056762695
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.6494026184082
New cuda time without quantization: 54.322967529296875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.47100830078125
now round: 8
New cuda time without quantization: 50.31446838378906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.41291046142578
New cuda time without quantization: 55.06025314331055
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.22797393798828
now round: 8
New cuda time without quantization: 57.5439453125
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.08409881591797
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.66814422607422
New cuda time without quantization: 260.3431091308594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 270.4662170410156
now round: 8
New cuda time without quantization: 50.057960510253906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.08536148071289
New cuda time without quantization: 60.47256088256836
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.56876373291016
now round: 8
New cuda time without quantization: 45.126258850097656
torch.Size([524288, 768]) torch.qint8
New cuda time: 55.20486068725586
New cuda time without quantization: 55.1491813659668
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.21114349365234
now round: 9
New cuda time without quantization: 48.886436462402344
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.9271125793457
New cuda time without quantization: 180.19464111328125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 190.34315490722656
now round: 9
New cuda time without quantization: 67.35419464111328
New cuda time without quantization: 251.7190704345703
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 261.925048828125
now round: 8
New cuda time without quantization: 49.813026428222656
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.965232849121094
New cuda time without quantization: 60.919639587402344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 71.3017578125
now round: 8
New cuda time without quantization: 50.41255187988281
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.516754150390625
New cuda time without quantization: 54.634647369384766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.8276596069336
now round: 9
New cuda time without quantization: 174.5017547607422
torch.Size([524288, 768]) torch.qint8
New cuda time: 184.6648406982422
New cuda time without quantization: 55.70905685424805
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.89630126953125
now round: 9
New cuda time without quantization: 31.35086441040039
torch.Size([524288, 768]) torch.qint8
New cuda time: 77.40430450439453
New cuda time without quantization: 55.47654342651367
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.55834197998047
now round: 9
New cuda time without quantization: 58.49447250366211
torch.Size([524288, 768]) torch.qint8
New cuda time: 68.55355072021484
New cuda time without quantization: 54.88518142700195
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.96138000488281
now round: 9
New cuda time without quantization: 149.59259033203125
torch.Size([524288, 768]) torch.qint8
New cuda time: 159.63600158691406
New cuda time without quantization: 68.077392578125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 78.27567291259766
now round: 9
New cuda time without quantization: 50.58292007446289
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.62200164794922
New cuda time without quantization: 150.2103729248047
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 160.3089599609375
now round: 9
torch.Size([524288, 768]) torch.qint8
New cuda time: 41.546749114990234
New cuda time without quantization: 55.498817443847656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.66813659667969
now round: 9
New cuda time without quantization: 57.64330291748047
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.78350830078125
New cuda time without quantization: 55.15017318725586
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.30525970458984
now round: 9
New cuda time without quantization: 149.27557373046875
torch.Size([524288, 768]) torch.qint8
New cuda time: 159.4327392578125
New cuda time without quantization: 67.58623504638672
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 77.75619506835938
now round: 9
New cuda time without quantization: 49.882789611816406
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.008750915527344
New cuda time without quantization: 150.0946044921875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 160.4226531982422
now round: 9
New cuda time without quantization: 49.9323616027832
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.968719482421875
New cuda time without quantization: 49.37779998779297
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 59.471275329589844
now round: 10
New cuda time without quantization: 224.60057067871094
torch.Size([524288, 768]) torch.qint8
New cuda time: 234.71102905273438
New cuda time without quantization: 54.49525451660156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.59273529052734
now round: 10
New cuda time without quantization: 50.34307861328125
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.39336013793945
New cuda time without quantization: 141.4576873779297
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 151.5905303955078
now round: 10
New cuda time without quantization: 148.7397918701172
torch.Size([524288, 768]) torch.qint8
New cuda time: 158.9102325439453
New cuda time without quantization: 55.095420837402344
New cuda time without quantization: 50.2109489440918
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.357234954833984
New cuda time without quantization: 148.27731323242188
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 158.45176696777344
now round: 10
New cuda time without quantization: 125.29049682617188
torch.Size([524288, 768]) torch.qint8
New cuda time: 135.57102966308594
New cuda time without quantization: 55.010013580322266
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.18045806884766
now round: 10
New cuda time without quantization: 50.25975036621094
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.3919563293457
New cuda time without quantization: 47.16325759887695
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.32602310180664
now round: 10
New cuda time without quantization: 242.12062072753906
torch.Size([524288, 768]) torch.qint8
New cuda time: 252.37747192382812
New cuda time without quantization: 55.22185134887695
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.18921661376953
now round: 10
New cuda time without quantization: 50.54964065551758
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.79352569580078
New cuda time without quantization: 55.58822250366211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.69450378417969
now round: 10
New cuda time without quantization: 50.26932144165039
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.342960357666016
New cuda time without quantization: 55.43094253540039
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.49498748779297
now round: 10
New cuda time without quantization: 161.7787322998047
torch.Size([524288, 768]) torch.qint8
New cuda time: 171.82228088378906
New cuda time without quantization: 54.89318084716797
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.991943359375
now round: 11
New cuda time without quantization: 48.30227279663086
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.32695388793945
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.37757873535156
now round: 10
New cuda time without quantization: 49.906307220458984
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.006832122802734
New cuda time without quantization: 50.1239128112793
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 60.30763626098633
now round: 10
New cuda time without quantization: 50.274471282958984
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.392757415771484
New cuda time without quantization: 55.17929458618164
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.33998107910156
now round: 10
New cuda time without quantization: 137.32318115234375
torch.Size([524288, 768]) torch.qint8
New cuda time: 147.47779846191406
New cuda time without quantization: 79.08212280273438
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 89.32728576660156
now round: 11
New cuda time without quantization: 50.35143280029297
torch.Size([524288, 768]) torch.qint8
New cuda time without quantization: 55.37014389038086
New cuda time: 60.46107482910156
New cuda time without quantization: 55.28073501586914
New cuda time without quantization: 251.47531127929688
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 261.5987854003906
now round: 8
New cuda time without quantization: 49.955543518066406
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.99935531616211
New cuda time without quantization: 33.87190628051758
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 44.091880798339844
now round: 8
New cuda time without quantization: 50.44162368774414
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.48687744140625
New cuda time without quantization: 54.80769348144531
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.86766052246094
now round: 9
New cuda time without quantization: 49.65666580200195
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.70207595825195
New cuda time without quantization: 155.33509826660156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 165.61331176757812
now round: 9
New cuda time without quantization: 67.2476577758789
torch.Size([8, 64, 1024, 768]) torch.qint8
torch.Size([524288, 768]) torch.qint8
New cuda time: 77.25994873046875
New cuda time without quantization: 54.8985710144043
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.98750305175781
now round: 9
New cuda time without quantization: 31.439916610717773
torch.Size([524288, 768]) torch.qint8
New cuda time: 41.49620819091797
New cuda time without quantization: 54.5910530090332
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.65326690673828
now round: 9
New cuda time without quantization: 149.67848205566406
torch.Size([524288, 768]) torch.qint8
New cuda time: 159.73716735839844
New cuda time without quantization: 57.509925842285156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.60125732421875
now round: 9
New cuda time without quantization: 50.79778289794922
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.81119155883789
New cuda time without quantization: 150.22328186035156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 160.3101348876953
now round: 9
New cuda time without quantization: 49.85874557495117
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.87791442871094
New cuda time without quantization: 44.53971862792969
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 54.6462516784668
now round: 10
New cuda time without quantization: 224.2923583984375
torch.Size([524288, 768]) torch.qint8
New cuda time: 234.3465576171875
New cuda time without quantization: 54.70641326904297
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.89342498779297
now round: 10
New cuda time without quantization: 50.21570587158203
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.248634338378906
New cuda time without quantization: 141.0978546142578
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 151.15989685058594
now round: 10
New cuda time without quantization: 148.7264862060547
torch.Size([524288, 768]) torch.qint8
New cuda time: 158.88404846191406
New cuda time without quantization: 54.75633239746094
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.83038330078125
now round: 10
New cuda time without quantization: 50.440345764160156
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.85390853881836
New cuda time without quantization: 52.07442092895508
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 62.15247344970703
now round: 10
New cuda time without quantization: 50.3285026550293
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.363834381103516
New cuda time without quantization: 55.210411071777344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.28094482421875
now round: 10
New cuda time without quantization: 161.941650390625
torch.Size([524288, 768]) torch.qint8
New cuda time: 171.98464965820312
New cuda time without quantization: 54.670894622802734
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.85758972167969
now round: 11
New cuda time without quantization: 50.36498260498047
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.38127899169922
New cuda time without quantization: 55.05329132080078
New cuda time without quantization: 268.2515563964844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 278.4242248535156
now round: 8
New cuda time without quantization: 50.36521530151367
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.395477294921875
New cuda time without quantization: 60.32763671875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.44925689697266
now round: 8
New cuda time without quantization: 50.654335021972656
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.71531677246094
New cuda time without quantization: 54.73274230957031
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.79228210449219
now round: 9
New cuda time without quantization: 49.451454162597656
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.510353088378906
New cuda time without quantization: 179.99795532226562
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 190.1368408203125
now round: 9
New cuda time without quantization: 67.2278060913086
torch.Size([524288, 768]) torch.qint8
New cuda time: 77.26990509033203
New cuda time without quantization: 55.15514373779297
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.35052490234375
now round: 9
New cuda time without quantization: 58.364112854003906
torch.Size([524288, 768]) torch.qint8
New cuda time: 68.46492767333984
New cuda time without quantization: 54.88954544067383
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.95708465576172
now round: 9
New cuda time without quantization: 149.57901000976562
torch.Size([524288, 768]) torch.qint8
New cuda time: 159.6151885986328
New cuda time without quantization: 68.04061126708984
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 78.28047180175781
now round: 9
New cuda time without quantization: 50.73401641845703
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.78123474121094
New cuda time without quantization: 150.26092529296875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 160.3980712890625
now round: 9
New cuda time without quantization: 49.761375427246094
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.863792419433594
New cuda time without quantization: 49.109375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 59.19131088256836
now round: 10
New cuda time without quantization: 224.53675842285156
torch.Size([524288, 768]) torch.qint8
New cuda time: 234.61708068847656
New cuda time without quantization: 54.7097053527832
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.7926025390625
now round: 10
New cuda time without quantization: 50.39433670043945
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.454994201660156
New cuda time without quantization: 141.27883911132812
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 151.3543701171875
now round: 10
New cuda time without quantization: 148.76156616210938
torch.Size([524288, 768]) torch.qint8
New cuda time: 158.9490966796875
New cuda time without quantization: 55.31242752075195
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.38285064697266
now round: 10
New cuda time without quantization: 50.7988166809082
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.047794342041016
New cuda time without quantization: 55.29050827026367
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.39164733886719
now round: 10
New cuda time without quantization: 50.447776794433594
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.50507736206055
New cuda time without quantization: 55.39354705810547
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.455810546875
now round: 10
New cuda time without quantization: 162.18576049804688
torch.Size([524288, 768]) torch.qint8
New cuda time: 172.24481201171875
New cuda time without quantization: 54.397544860839844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.58252716064453
now round: 11
New cuda time without quantization: 51.070499420166016
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.0794792175293
New cuda time without quantization: 55.04298782348633
torch.Size([8, 64, 1024, 768]) torch.qint8
torch.Size([8, 64, 1024, 768]) torch.qint8
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time without quantization: 54.978790283203125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.25051879882812
now round: 6
New cuda time without quantization: 50.72149658203125
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.859134674072266
New cuda time without quantization: 60.23001480102539
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.38157653808594
now round: 6
New cuda time without quantization: 47.79924011230469
torch.Size([524288, 768]) torch.qint8
New cuda time: 57.92664337158203
New cuda time without quantization: 157.74819946289062
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 168.0613555908203
now round: 6
New cuda time without quantization: 44.58306884765625
torch.Size([524288, 768]) torch.qint8
New cuda time: 54.72279357910156
New cuda time without quantization: 66.31596374511719
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 76.61087799072266
now round: 6
New cuda time without quantization: 54.29991149902344
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.4490737915039
New cuda time without quantization: 54.35927200317383
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.59899139404297
now round: 6
New cuda time without quantization: 44.71459197998047
torch.Size([524288, 768]) torch.qint8
New cuda time: 54.9642333984375
New cuda time without quantization: 57.356082916259766
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.5066909790039
now round: 7
New cuda time without quantization: 50.44405746459961
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.558494567871094
New cuda time without quantization: 142.61708068847656
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 152.79457092285156
now round: 7
New cuda time without quantization: 270.214599609375
torch.Size([524288, 768]) torch.qint8
New cuda time: 280.37750244140625
New cuda time without quantization: 57.593685150146484
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.766845703125
now round: 7
New cuda time without quantization: 50.98981475830078
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.129859924316406
New cuda time without quantization: 53.48550796508789
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.65163040161133
now round: 7
New cuda time without quantization: 53.20934295654297
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.31242752075195
New cuda time without quantization: 55.246315002441406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.42668151855469
now round: 7
New cuda time without quantization: 270.54803466796875
torch.Size([524288, 768]) torch.qint8
New cuda time: 280.6968688964844
New cuda time without quantization: 54.542633056640625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.7111587524414
now round: 7
New cuda time without quantization: 50.43269729614258
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.559295654296875
New cuda time without quantization: 57.7906494140625
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.94236755371094
now round: 8
New cuda time without quantization: 50.98933410644531
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.09722137451172
New cuda time without quantization: 175.1764373779297
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 185.54127502441406
now round: 8
New cuda time without quantization: 51.84870147705078
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.968265533447266
New cuda time without quantization: 54.31527328491211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.45083618164062
now round: 8
New cuda time without quantization: 50.19477462768555
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.360416412353516
New cuda time without quantization: 54.42583084106445
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.57211303710938
now round: 8
New cuda time without quantization: 50.77781677246094
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.950660705566406
New cuda time without quantization: 159.07972717285156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 169.25015258789062
now round: 8
New cuda time without quantization: 141.9962921142578
torch.Size([524288, 768]) torch.qint8
New cuda time: 152.11810302734375
New cuda time without quantization: 60.33753967285156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.7267074584961
now round: 8
New cuda time without quantization: 50.23829650878906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.349056243896484
New cuda time without quantization: 48.35140609741211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 58.67577362060547
now round: 9
New cuda time without quantization: 174.46282958984375
torch.Size([524288, 768]) torch.qint8
New cuda time: 184.6527862548828
New cuda time without quantization: 54.68119430541992
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.84716033935547
now round: 9
New cuda time without quantization: 66.27596282958984
torch.Size([524288, 768]) torch.qint8
New cuda time: 76.4123306274414
New cuda time without quantization: 55.04375457763672
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.19580078125
now round: 9
New cuda time without quantization: 50.093017578125
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.37305450439453
New cuda time without quantization: 54.43143081665039
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.66411590576172
now round: 9
New cuda time without quantization: 149.2644805908203
torch.Size([524288, 768]) torch.qint8
New cuda time: 159.40277099609375
New cuda time without quantization: 67.22796630859375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 77.40017700195312
now round: 9
New cuda time without quantization: 49.71797561645508
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.82249450683594
New cuda time without quantization: 33.46142578125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 43.6502685546875
now round: 9
New cuda time without quantization: 50.161495208740234
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.25049591064453
New cuda time without quantization: 148.5404815673828
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 158.69412231445312
now round: 10
New cuda time without quantization: 125.6461410522461
torch.Size([524288, 768]) torch.qint8
New cuda time: 135.92698669433594
New cuda time without quantization: 54.49543762207031
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.64219665527344
now round: 10
New cuda time without quantization: 50.18309783935547
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.30009841918945
New cuda time without quantization: 140.12332153320312
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 150.30064392089844
now round: 10
New cuda time without quantization: 148.39695739746094
torch.Size([524288, 768]) torch.qint8
New cuda time: 158.64004516601562
New cuda time without quantization: 54.89079666137695
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.0602798461914
now round: 10
New cuda time without quantization: 49.883094787597656
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.00249481201172
New cuda time without quantization: 55.29288101196289
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.57020568847656
now round: 10
New cuda time without quantization: 50.19509506225586
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.32265853881836
New cuda time without quantization: 54.65031433105469
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.80316162109375
now round: 10
New cuda time without quantization: 161.8175048828125
torch.Size([524288, 768]) torch.qint8
New cuda time: 171.95050048828125
New cuda time without quantization: 53.87431335449219
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.10491943359375
now round: 11
New cuda time without quantization: 50.714778900146484
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.83642578125
New cuda time without quantization: 54.21511459350586
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time without quantization: 55.15312957763672
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.3541488647461
now round: 6
New cuda time without quantization: 51.066864013671875
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.18339920043945
New cuda time without quantization: 60.291717529296875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.4620132446289
now round: 6
New cuda time without quantization: 47.92316436767578
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.04402542114258
New cuda time without quantization: 165.97891235351562
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 176.1535186767578
now round: 6
New cuda time without quantization: 53.480316162109375
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.603736877441406
New cuda time without quantization: 57.67890548706055
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.96263885498047
now round: 6
New cuda time without quantization: 54.32575988769531
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.4415054321289
New cuda time without quantization: 54.49152374267578
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.68038177490234
now round: 6
New cuda time without quantization: 52.82079315185547
torch.Size([524288, 768]) torch.qint8
New cuda time: 62.94757080078125
New cuda time without quantization: 57.5776252746582
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.74903869628906
now round: 7
New cuda time without quantization: 50.8687858581543
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.03971862792969
New cuda time without quantization: 148.69479370117188
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 158.86334228515625
now round: 7
New cuda time without quantization: 264.28619384765625
torch.Size([524288, 768]) torch.qint8
New cuda time: 274.6595458984375
New cuda time without quantization: 57.37042236328125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.52552032470703
now round: 7
New cuda time without quantization: 50.60797882080078
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.7099609375
New cuda time without quantization: 54.10111999511719
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.28662109375
now round: 7
New cuda time without quantization: 53.28751754760742
torch.Size([524288, 768]) torch.qint8
New cuda time: 63.43093490600586
New cuda time without quantization: 284.2621765136719
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 294.6139221191406
now round: 7
New cuda time without quantization: 41.720088958740234
torch.Size([524288, 768]) torch.qint8
New cuda time: 51.8641471862793
New cuda time without quantization: 54.95248794555664
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.08790588378906
now round: 7
New cuda time without quantization: 50.648460388183594
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.77027893066406
New cuda time without quantization: 57.99314498901367
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 68.14520263671875
now round: 8
New cuda time without quantization: 50.30638122558594
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.41891860961914
New cuda time without quantization: 181.8145294189453
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 192.1776123046875
now round: 8
New cuda time without quantization: 50.15021514892578
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.283878326416016
New cuda time without quantization: 56.39057540893555
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.56599426269531
now round: 8
New cuda time without quantization: 50.295021057128906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.41204071044922
New cuda time without quantization: 54.61264419555664
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.77046203613281
now round: 8
New cuda time without quantization: 57.626102447509766
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.7320785522461
New cuda time without quantization: 131.1047821044922
New cuda time: 64.36155700683594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 141.4933319091797
now round: 8
New cuda time without quantization: 49.424617767333984
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.546913146972656
New cuda time without quantization: 60.43347930908203
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.7943344116211
now round: 8
New cuda time without quantization: 50.50014114379883
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.598758697509766
New cuda time without quantization: 54.3470458984375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.51718139648438
now round: 9
New cuda time without quantization: 174.6832733154297
torch.Size([524288, 768]) torch.qint8
New cuda time: 184.98622131347656
New cuda time without quantization: 54.44096374511719
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.58230590820312
now round: 9
New cuda time without quantization: 66.30887603759766
torch.Size([524288, 768]) torch.qint8
New cuda time: 76.44717407226562
New cuda time without quantization: 55.366729736328125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.52167510986328
now round: 9
New cuda time without quantization: 57.59330368041992
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.71943664550781
New cuda time without quantization: 55.04016876220703
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.27862548828125
now round: 9
New cuda time without quantization: 170.7938232421875
torch.Size([524288, 768]) torch.qint8
New cuda time: 181.04522705078125
New cuda time without quantization: 45.93083190917969
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 56.08401107788086
now round: 9
New cuda time without quantization: 49.77021789550781
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.874916076660156
New cuda time without quantization: 149.69065856933594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 159.85472106933594
now round: 9
New cuda time without quantization: 50.4114990234375
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.60036087036133
New cuda time without quantization: 231.189208984375
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 241.48687744140625
now round: 10
New cuda time without quantization: 41.94968795776367
torch.Size([524288, 768]) torch.qint8
New cuda time: 52.05375289916992
New cuda time without quantization: 54.63296890258789
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.77830505371094
now round: 10
New cuda time without quantization: 50.404300689697266
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.52116012573242
New cuda time without quantization: 46.88251876831055
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 57.06050109863281
now round: 10
New cuda time without quantization: 241.9739227294922
torch.Size([524288, 768]) torch.qint8
New cuda time: 252.10598754882812
New cuda time without quantization: 55.19888687133789
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.36550903320312
now round: 10
New cuda time without quantization: 49.95725631713867
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.0771598815918
New cuda time without quantization: 55.33761215209961
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.6183090209961
now round: 10
New cuda time without quantization: 50.232460021972656
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.36676025390625
New cuda time without quantization: 54.822086334228516
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.97590637207031
now round: 10
New cuda time without quantization: 137.37217712402344
torch.Size([524288, 768]) torch.qint8
New cuda time: 147.51080322265625
New cuda time without quantization: 78.82575225830078
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 89.10660552978516
now round: 11
New cuda time without quantization: 39.3859977722168
torch.Size([524288, 768]) torch.qint8
New cuda time: 49.50029754638672
New cuda time without quantization: 54.31840515136719
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.48326110839844
New cuda time: 65.13246154785156
now round: 11
New cuda time without quantization: 50.04610824584961
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.087520599365234
New cuda time without quantization: 54.82817077636719
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.12446594238281
now round: 11
New cuda time without quantization: 50.662742614746094
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.69599533081055
New cuda time without quantization: 55.27313232421875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.34782409667969
now round: 11
New cuda time without quantization: 50.58738327026367
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.66703414916992
New cuda time without quantization: 55.0225715637207
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.16382598876953
now round: 11
New cuda time without quantization: 54.15185546875
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.20782470703125
New cuda time without quantization: 55.625450134277344
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.70398712158203
now round: 11
New cuda time without quantization: 50.60802459716797
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.62384033203125
New cuda time without quantization: 54.697776794433594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.86126708984375
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 65.13324737548828
now round: 11
New cuda time without quantization: 49.990177154541016
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.0469970703125
New cuda time without quantization: 55.15178680419922
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.44652557373047
now round: 11
New cuda time without quantization: 50.70537567138672
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.7514762878418
New cuda time without quantization: 55.79098892211914
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.8919677734375
now round: 11
New cuda time without quantization: 50.77801513671875
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.832435607910156
New cuda time without quantization: 51.46601867675781
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 61.59196090698242
now round: 11
New cuda time without quantization: 54.05994415283203
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.11548614501953
New cuda time without quantization: 56.029869079589844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.09709167480469
now round: 11
New cuda time without quantization: 50.50617599487305
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.568756103515625
New cuda time without quantization: 54.87946701049805
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.96125030517578
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 64.76934814453125
now round: 11
New cuda time without quantization: 50.897621154785156
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.92981719970703
New cuda time without quantization: 55.487876892089844
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.42089080810547
now round: 11
New cuda time without quantization: 47.354888916015625
torch.Size([524288, 768]) torch.qint8
New cuda time: 57.358280181884766
New cuda time without quantization: 55.91748046875
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.0451889038086
now round: 11
New cuda time without quantization: 49.0179328918457
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.09428787231445
New cuda time without quantization: 53.70867156982422
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.790462493896484
now round: 11
New cuda time without quantization: 57.574283599853516
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.63719940185547
New cuda time without quantization: 53.01826858520508
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 63.08998489379883
now round: 11
New cuda time without quantization: 50.87057876586914
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.88565444946289
New cuda time without quantization: 52.13858413696289
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 62.22053909301758
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 65.41962432861328
now round: 11
New cuda time without quantization: 49.95716094970703
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.98759841918945
New cuda time without quantization: 55.16854476928711
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.4650650024414
now round: 11
New cuda time without quantization: 50.740203857421875
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.770164489746094
New cuda time without quantization: 55.89494323730469
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.98042297363281
now round: 11
New cuda time without quantization: 50.575565338134766
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.63624572753906
New cuda time without quantization: 55.575904846191406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.77562713623047
now round: 11
New cuda time without quantization: 54.041015625
torch.Size([524288, 768]) torch.qint8
New cuda time: 64.11113739013672
New cuda time without quantization: 56.13702392578125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.20410919189453
now round: 11
New cuda time without quantization: 50.51396560668945
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.600563049316406
New cuda time without quantization: 54.85286331176758
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.94170379638672
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
now round: 11
New cuda time without quantization: 50.560699462890625
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.65642547607422
New cuda time without quantization: 54.66167449951172
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.80699920654297
now round: 11
New cuda time without quantization: 50.63349914550781
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.752262115478516
New cuda time without quantization: 54.22103500366211
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 70.80622100830078
now round: 11
New cuda time without quantization: 44.77891159057617
torch.Size([524288, 768]) torch.qint8
New cuda time: 54.93095779418945
New cuda time without quantization: 55.22359848022461
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.36860656738281
now round: 11
New cuda time without quantization: 49.26405715942383
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.52137756347656
New cuda time without quantization: 59.519935607910156
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.76270294189453
now round: 11
New cuda time without quantization: 49.8541374206543
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.97513961791992
New cuda time without quantization: 54.73575973510742
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.87787628173828
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
now round: 11
New cuda time without quantization: 50.537986755371094
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.65787124633789
New cuda time without quantization: 54.703128814697266
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.85980987548828
now round: 11
New cuda time without quantization: 50.70118713378906
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.81611251831055
New cuda time without quantization: 54.5264892578125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.82189178466797
now round: 11
New cuda time without quantization: 51.155113220214844
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.298194885253906
New cuda time without quantization: 55.67897033691406
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.81277465820312
now round: 11
New cuda time without quantization: 49.28054428100586
torch.Size([524288, 768]) torch.qint8
New cuda time: 59.527469635009766
New cuda time without quantization: 59.80651092529297
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 69.99919891357422
now round: 11
New cuda time without quantization: 49.930145263671875
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.06043243408203
New cuda time without quantization: 55.060089111328125
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.21565246582031
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 65.47022247314453
now round: 11
New cuda time without quantization: 49.93430709838867
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.051795959472656
New cuda time without quantization: 54.89529037475586
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.0588607788086
now round: 11
New cuda time without quantization: 50.6912727355957
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.80939865112305
New cuda time without quantization: 54.876731872558594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.15438079833984
now round: 11
New cuda time without quantization: 51.10487747192383
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.2452392578125
New cuda time without quantization: 55.876895904541016
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 66.07246398925781
now round: 11
New cuda time without quantization: 48.61974334716797
torch.Size([524288, 768]) torch.qint8
New cuda time: 58.8909912109375
New cuda time without quantization: 57.79770278930664
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 67.99439239501953
now round: 11
New cuda time without quantization: 49.97319030761719
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.12203598022461
New cuda time without quantization: 55.2149772644043
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.44029998779297
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
now round: 11
New cuda time without quantization: 50.67822265625
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.78020477294922
New cuda time without quantization: 54.60512924194336
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.74903106689453
now round: 11
New cuda time without quantization: 50.734703063964844
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.84596252441406
New cuda time without quantization: 54.56272888183594
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 64.84870910644531
now round: 11
New cuda time without quantization: 51.159664154052734
torch.Size([524288, 768]) torch.qint8
New cuda time: 61.29924774169922
New cuda time without quantization: 55.49345016479492
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.6351089477539
now round: 11
New cuda time without quantization: 57.11154556274414
torch.Size([524288, 768]) torch.qint8
New cuda time: 67.24552154541016
New cuda time without quantization: 52.05535125732422
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 62.30821228027344
now round: 11
New cuda time without quantization: 49.95438003540039
torch.Size([524288, 768]) torch.qint8
New cuda time: 60.12211990356445
New cuda time without quantization: 55.008968353271484
torch.Size([8, 64, 1024, 768]) torch.qint8
New cuda time: 65.16278839111328
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:58:15 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:58:15 | INFO | fairseq_cli.eval_lm | Evaluated 1,800,489 tokens in 39.9s (45129.60 tokens/s)
2024-07-12 03:58:15 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9548, Perplexity: 7.75
