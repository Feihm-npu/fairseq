2024-07-11 02:02:05 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16330
2024-07-11 02:02:05 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16330
2024-07-11 02:02:05 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16330
2024-07-11 02:02:05 | INFO | fairseq.distributed.utils | initialized host t008-001.hpcfund as rank 2
2024-07-11 02:02:05 | INFO | fairseq.distributed.utils | initialized host t008-001.hpcfund as rank 3
2024-07-11 02:02:05 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16330
2024-07-11 02:02:05 | INFO | fairseq.distributed.utils | initialized host t008-001.hpcfund as rank 1
2024-07-11 02:02:05 | INFO | fairseq.distributed.utils | initialized host t008-001.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.05}", 'results_path': None, 'is_moe': True}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16330', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 10, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 10}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | model	None
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-11 02:02:06 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-11 02:02:06 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-11 02:02:06 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-11 02:02:06 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-11 02:02:08 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-11 02:02:11 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-11 02:02:14 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-11 02:02:16 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-11 02:02:19 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-11 02:02:22 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-11 02:02:24 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-11 02:02:27 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-11 02:02:35 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-11 02:02:44 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-11 02:03:04 | INFO | fairseq_cli.eval_lm | load time: 58.11 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
New cuda time without quantization: 8596.0810546875
New cuda time without quantization: 0.8662440180778503
New cuda time: 1.9428880214691162
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 151.43247985839844
New cuda time without quantization: 0.9395239949226379
New cuda time: 2.024967908859253
New cuda time without quantization: 101.3837890625
New cuda time without quantization: 0.9452840089797974
New cuda time: 2.0222489833831787
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 8.209634780883789
New cuda time without quantization: 0.939844012260437
New cuda time: 2.016007900238037
New cuda time without quantization: 64.18154907226562
New cuda time without quantization: 0.9521639943122864
New cuda time: 2.0332889556884766
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 9.103239059448242
New cuda time without quantization: 0.9507240056991577
New cuda time: 2.0264089107513428
New cuda time without quantization: 0.7515230178833008
New cuda time without quantization: 0.8614439964294434
New cuda time: 1.9369679689407349
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 80.23922729492188
New cuda time without quantization: 0.995045006275177
New cuda time: 2.075368881225586
New cuda time without quantization: 0.9009640216827393
New cuda time without quantization: 0.7620829939842224
New cuda time: 1.8385670185089111
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 78.62769317626953
New cuda time without quantization: 1.6862469911575317
New cuda time: 2.780172109603882
New cuda time without quantization: 0.91184401512146
New cuda time without quantization: 0.8249629735946655
New cuda time: 1.9081679582595825
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 76.54896545410156
New cuda time without quantization: 1.0028849840164185
New cuda time: 2.083688974380493
New cuda time without quantization: 82.48162841796875
New cuda time without quantization: 0.9174439907073975
New cuda time: 2.012808084487915
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 10.995407104492188
New cuda time without quantization: 67.93405151367188
New cuda time: 69.02557373046875
New cuda time without quantization: 1.3400059938430786
New cuda time without quantization: 0.8776040077209473
New cuda time: 1.9643280506134033
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.41616821289062
New cuda time without quantization: 1.208804965019226
New cuda time: 2.2844901084899902
New cuda time without quantization: 1.4504070281982422
New cuda time without quantization: 0.7444829940795898
New cuda time: 1.8182480335235596
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.5883350372314453
New cuda time without quantization: 0.8337640166282654
New cuda time: 1.905608057975769
New cuda time without quantization: 94.33016204833984
New cuda time without quantization: 0.6913620233535767
New cuda time: 1.7705680131912231
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 79.54129791259766
New cuda time without quantization: 1.0060850381851196
New cuda time: 2.09040904045105
New cuda time without quantization: 1.278244972229004
New cuda time without quantization: 0.7625629901885986
New cuda time: 1.8302479982376099
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 79.68018341064453
New cuda time without quantization: 1.0244849920272827
New cuda time: 2.1043291091918945
New cuda time without quantization: 1.454725980758667
New cuda time without quantization: 0.8097630143165588
New cuda time: 1.8849680423736572
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.9668970108032227
New cuda time without quantization: 68.98333740234375
New cuda time: 70.07133483886719
New cuda time without quantization: 1.438565969467163
New cuda time without quantization: 0.7628840208053589
New cuda time: 1.8307280540466309
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 8.128034591674805
New cuda time without quantization: 66.24908447265625
New cuda time: 67.44700622558594
New cuda time without quantization: 1.9040080308914185
New cuda time without quantization: 0.755843997001648
New cuda time: 1.830407977104187
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 10.775087356567383
New cuda time without quantization: 0.7156829833984375
New cuda time: 1.8044869899749756
New cuda time without quantization: 71.96862030029297
New cuda time without quantization: 0.930724024772644
New cuda time: 2.010727882385254
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.428819179534912
New cuda time without quantization: 7.978114128112793
New cuda time: 9.058279037475586
New cuda time without quantization: 75.74384307861328
New cuda time without quantization: 0.9694439768791199
New cuda time: 2.040808916091919
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 9.569801330566406
New cuda time without quantization: 72.94670867919922
New cuda time: 74.04528045654297
New cuda time without quantization: 2.4396910667419434
New cuda time without quantization: 0.9433640241622925
New cuda time: 2.0225679874420166
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 8.671876907348633
New cuda time without quantization: 65.46971893310547
New cuda time: 66.56236267089844
New cuda time without quantization: 1.4134459495544434
New cuda time without quantization: 0.7632039785385132
New cuda time: 1.8340879678726196
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 9.242119789123535
New cuda time without quantization: 0.9572839736938477
New cuda time: 2.0332889556884766
New cuda time without quantization: 90.99414825439453
New cuda time without quantization: 1.3603260517120361
New cuda time: 2.4272100925445557
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 81.48722839355469
New cuda time without quantization: 8.142754554748535
New cuda time: 9.31779956817627
New cuda time without quantization: 2.013607978820801
New cuda time without quantization: 0.7556830048561096
New cuda time: 1.8244869709014893
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 73.49391174316406
New cuda time without quantization: 4.0953779220581055
New cuda time: 5.184182167053223
New cuda time without quantization: 1.4380860328674316
New cuda time without quantization: 0.7588840126991272
New cuda time: 1.8286479711532593
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 78.46513366699219
New cuda time without quantization: 5.68642520904541
New cuda time: 6.7664289474487305
New cuda time without quantization: 1.1668850183486938
New cuda time without quantization: 0.7515239715576172
New cuda time: 1.8198479413986206
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 65.96636199951172
New cuda time without quantization: 0.9595239758491516
New cuda time: 2.043848991394043
New cuda time without quantization: 7.032830238342285
New cuda time without quantization: 0.9252840280532837
New cuda time: 2.000009059906006
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 69.51261901855469
New cuda time without quantization: 0.9396839737892151
New cuda time: 2.019529104232788
New cuda time without quantization: 1.5723270177841187
New cuda time without quantization: 0.7478430271148682
New cuda time: 1.9220889806747437
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 10.754446029663086
New cuda time without quantization: 75.23343658447266
New cuda time: 76.33552551269531
New cuda time without quantization: 8.408196449279785
New cuda time without quantization: 0.9220839738845825
New cuda time: 1.9958490133285522
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 73.32255554199219
New cuda time without quantization: New cuda time without quantization: 7414.2392578125
New cuda time without quantization: 0.8865569829940796
New cuda time: 1.9619109630584717
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 145.1739501953125
New cuda time without quantization: 1.0428760051727295
New cuda time: 2.1225509643554688
New cuda time without quantization: 63.912052154541016
New cuda time without quantization: 0.9286360144615173
New cuda time: 2.005592107772827
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 7.726367950439453
New cuda time without quantization: 0.8867160081863403
New cuda time: 1.9571119546890259
New cuda time without quantization: 64.49317169189453
New cuda time without quantization: 0.9476760029792786
New cuda time: 2.0190320014953613
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 8.369725227355957
New cuda time without quantization: 0.9113559722900391
New cuda time: 2.035991907119751
New cuda time without quantization: 1.0023959875106812
New cuda time without quantization: 0.7603170275688171
New cuda time: 1.949591040611267
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 79.5854263305664
New cuda time without quantization: 0.9447960257530212
New cuda time: 2.0318310260772705
New cuda time without quantization: 1.2068740129470825
New cuda time without quantization: 0.7681570053100586
New cuda time: 1.8369519710540771
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 78.02351379394531
New cuda time without quantization: 0.7025570273399353
New cuda time: 1.7951929569244385
New cuda time without quantization: 1.2579139471054077
New cuda time without quantization: 0.8313559889793396
New cuda time: 1.9028719663619995
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 75.7745590209961
New cuda time without quantization: 0.8964759707450867
New cuda time: 1.9791909456253052
New cuda time without quantization: 82.51453399658203
New cuda time without quantization: 0.9270359873771667
New cuda time: 2.01967191696167
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 10.08443832397461
New cuda time without quantization: 67.90451049804688
New cuda time: 68.99699401855469
New cuda time without quantization: 1.330873966217041
New cuda time without quantization: 7.131490230560303
New cuda time: 8.316925048828125
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.01631164550781
New cuda time without quantization: 1.1227149963378906
New cuda time: 2.2004709243774414
New cuda time without quantization: 1.4363139867782593
New cuda time without quantization: 0.7739160060882568
New cuda time: 1.841271996498108
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.177427053451538
New cuda time without quantization: 0.7775970101356506
New cuda time: 1.853592038154602
New cuda time without quantization: 89.3338623046875
New cuda time without quantization: 5.848134994506836
New cuda time: 6.923971176147461
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 79.4767837524414
New cuda time without quantization: 0.9700750112533569
New cuda time: 2.052791118621826
New cuda time without quantization: 1.4103939533233643
New cuda time without quantization: 0.7460770010948181
New cuda time: 1.8190330266952515
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 79.34318542480469
New cuda time without quantization: 0.9715160131454468
New cuda time: 2.053750991821289
New cuda time without quantization: 1.4252740144729614
New cuda time without quantization: 0.801596999168396
New cuda time: 1.8723119497299194
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 8.83420181274414
New cuda time without quantization: 68.93122863769531
New cuda time: 70.02386474609375
New cuda time without quantization: 1.8318320512771606
New cuda time without quantization: 0.7670369744300842
New cuda time: 1.8353519439697266
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 8.173245429992676
New cuda time without quantization: 66.15316009521484
New cuda time: 67.34674835205078
New cuda time without quantization: 1.9219119548797607
New cuda time without quantization: 0.7716770172119141
New cuda time: 1.8452730178833008
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 10.08891773223877
New cuda time without quantization: 1.4719940423965454
New cuda time: 2.549588918685913
New cuda time without quantization: 72.30577850341797
New cuda time without quantization: 0.9103959798812866
New cuda time: 1.9867119789123535
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.363020896911621
New cuda time without quantization: 8.003966331481934
New cuda time: 9.084761619567871
New cuda time without quantization: 75.716796875
New cuda time without quantization: 0.96287602186203
New cuda time: 2.0345520973205566
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 9.479000091552734
New cuda time without quantization: 7.212769985198975
New cuda time: 8.295326232910156
New cuda time without quantization: 74.4686508178711
New cuda time without quantization: 0.9238359928131104
New cuda time: 2.0011119842529297
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 5.506697177886963
New cuda time without quantization: 65.36116027832031
New cuda time: 66.45316314697266
New cuda time without quantization: 0.9284759759902954
New cuda time without quantization: 0.7670369744300842
New cuda time: 1.8319920301437378
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 8.344285011291504
New cuda time without quantization: 0.9385560154914856
New cuda time: 2.0083110332489014
New cuda time without quantization: 7.848766803741455
New cuda time without quantization: 91.4290542602539
New cuda time: 92.62024688720703
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 80.05470275878906
New cuda time without quantization: 8.092605590820312
New cuda time: 9.283480644226074
New cuda time without quantization: 1.7996729612350464
New cuda time without quantization: 0.7535970211029053
New cuda time: 1.8238320350646973
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.58399200439453
New cuda time without quantization: 3.9942240715026855
New cuda time: 5.085577964782715
New cuda time without quantization: 1.3291139602661133
New cuda time without quantization: 0.75279700756073
New cuda time: 1.8169519901275635
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.12975311279297
New cuda time without quantization: 5.67085599899292
New cuda time: 6.757091999053955
New cuda time without quantization: 1.0660749673843384
New cuda time without quantization: 0.7670360207557678
New cuda time: 1.8343919515609741
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 70.40626525878906
New cuda time without quantization: 0.951196014881134
New cuda time: 2.0267109870910645
New cuda time without quantization: 6.971490859985352
New cuda time without quantization: 0.8967959880828857
New cuda time: 1.9731110334396362
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 68.3392333984375
New cuda time without quantization: 0.9407960176467896
New cuda time: 2.015990972518921
New cuda time without quantization: 1.5318340063095093
New cuda time without quantization: 0.7519969940185547
New cuda time: 1.927351951599121
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 10.296916007995605
New cuda time without quantization: 75.14672088623047
New cuda time: 76.23423767089844
New cuda time without quantization: 7.953726768493652
New cuda time without quantization: 0.9164760112762451
New cuda time: 1.985592007637024
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 72.52529907226562
New cuda time without quantization: New cuda time without quantization: 5662.0791015625
New cuda time without quantization: 0.7096019983291626
New cuda time: 1.7883260250091553
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 168.77003479003906
New cuda time without quantization: 0.8104029893875122
New cuda time: 1.8968069553375244
New cuda time without quantization: 34.032440185546875
New cuda time without quantization: 0.9184030294418335
New cuda time: 1.9974470138549805
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.7539329528808594
New cuda time without quantization: 0.9644830226898193
New cuda time: 2.036807060241699
New cuda time without quantization: 64.59286499023438
New cuda time without quantization: 0.8932830095291138
New cuda time: 1.9670469760894775
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.492815971374512
New cuda time without quantization: 0.8201630115509033
New cuda time: 1.8985660076141357
New cuda time without quantization: 1.1203240156173706
New cuda time without quantization: 0.9555230140686035
New cuda time: 2.0323269367218018
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 72.05769348144531
New cuda time without quantization: 0.909762978553772
New cuda time: 1.9969669580459595
New cuda time without quantization: 1.1651240587234497
New cuda time without quantization: 0.7635220289230347
New cuda time: 1.8334460258483887
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.09481048583984
New cuda time without quantization: 1.530405044555664
New cuda time: 2.61712908744812
New cuda time without quantization: 0.8651229739189148
New cuda time without quantization: 0.7627230286598206
New cuda time: 1.8352069854736328
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 68.98391723632812
New cuda time without quantization: 0.9712030291557312
New cuda time: 2.051846981048584
New cuda time without quantization: 71.22584533691406
New cuda time without quantization: 0.9105640053749084
New cuda time: 2.01088809967041
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 67.32615661621094
New cuda time without quantization: 1.2128039598464966
New cuda time: 2.2948880195617676
New cuda time without quantization: 1.4208060503005981
New cuda time without quantization: 7.109304904937744
New cuda time: 8.194748878479004
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 73.56633758544922
New cuda time without quantization: 0.9888030290603638
New cuda time: 2.06624698638916
New cuda time without quantization: 1.3705639839172363
New cuda time without quantization: 0.7480030059814453
New cuda time: 1.8126469850540161
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7008029818534851
New cuda time without quantization: 0.7856029868125916
New cuda time: 1.8654459714889526
New cuda time without quantization: 82.12957000732422
New cuda time without quantization: 5.683859825134277
New cuda time: 6.767543792724609
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.06616973876953
New cuda time without quantization: 0.9412829875946045
New cuda time: 2.026566982269287
New cuda time without quantization: 1.3688039779663086
New cuda time without quantization: 0.7564830183982849
New cuda time: 1.8254469633102417
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 72.05657958984375
New cuda time without quantization: 0.9764829874038696
New cuda time: 2.0572869777679443
New cuda time without quantization: 1.348803997039795
New cuda time without quantization: 0.714402973651886
New cuda time: 1.7768069505691528
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 68.49336242675781
New cuda time without quantization: 1.3572839498519897
New cuda time: 2.4368081092834473
New cuda time without quantization: 0.7004830241203308
New cuda time without quantization: 0.7851229906082153
New cuda time: 1.8518459796905518
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9006440043449402
New cuda time without quantization: 66.1703109741211
New cuda time: 67.37992095947266
New cuda time without quantization: 1.8025660514831543
New cuda time without quantization: 0.7475230097770691
New cuda time: 1.819206953048706
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.518725037574768
New cuda time without quantization: 0.8708829879760742
New cuda time: 1.960966944694519
New cuda time without quantization: 72.25193786621094
New cuda time without quantization: 0.9451239705085754
New cuda time: 2.0132880210876465
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7088029980659485
New cuda time without quantization: 0.9118430018424988
New cuda time: 2.0105669498443604
New cuda time without quantization: 75.57514190673828
New cuda time without quantization: 0.9566439986228943
New cuda time: 2.0364880561828613
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8857629895210266
New cuda time without quantization: 7.184825897216797
New cuda time: 8.271069526672363
New cuda time without quantization: 74.26106262207031
New cuda time without quantization: 0.9068840146064758
New cuda time: 1.9883270263671875
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 64.9512710571289
New cuda time without quantization: 1.2662440538406372
New cuda time: 2.3484880924224854
New cuda time without quantization: 1.5048049688339233
New cuda time without quantization: 0.780003011226654
New cuda time: 1.8401670455932617
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9113640189170837
New cuda time without quantization: 0.8880029916763306
New cuda time: 1.9585670232772827
New cuda time without quantization: 7.525465965270996
New cuda time without quantization: 91.45648193359375
New cuda time: 92.64112854003906
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.5906753540039
New cuda time without quantization: 0.9035239815711975
New cuda time: 9.495392799377441
New cuda time without quantization: 0.700643002986908
New cuda time without quantization: 0.7763220071792603
New cuda time: 1.8464059829711914
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.97291564941406
New cuda time without quantization: 0.8382430076599121
New cuda time: 1.9176069498062134
New cuda time without quantization: 1.376965045928955
New cuda time without quantization: 0.7521629929542542
New cuda time: 1.8244860172271729
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 80.56988525390625
New cuda time without quantization: 0.7065619826316833
New cuda time: 1.7889659404754639
New cuda time without quantization: 1.0788840055465698
New cuda time without quantization: 0.7488030195236206
New cuda time: 1.840965986251831
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 69.92552947998047
New cuda time without quantization: 0.9048029780387878
New cuda time: 1.9856070280075073
New cuda time without quantization: 0.891202986240387
New cuda time without quantization: 0.7832030057907104
New cuda time: 1.8492870330810547
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 65.52167510986328
New cuda time without quantization: 0.8966429829597473
New cuda time: 1.9780869483947754
New cuda time without quantization: 1.4332849979400635
New cuda time without quantization: 0.7574430108070374
New cuda time: 8.835071563720703
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.72698211669922
New cuda time without quantization: 1.1860840320587158
New cuda time: 2.265608072280884
New cuda time without quantization: 0.9209629893302917
New cuda time without quantization: 0.8596829771995544
New cuda time: 1.9259259700775146
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.23433685302734
New cuda time without quantization: 319.0251770019531
New cuda time without quantization: 0.834879994392395
New cuda time: 1.9131189584732056
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8971179723739624
New cuda time without quantization: 1.074079990386963
New cuda time: 2.150239944458008
New cuda time without quantization: 0.880158007144928
New cuda time without quantization: 0.9707199931144714
New cuda time: 2.0451200008392334
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.851518988609314
New cuda time without quantization: 0.7763199806213379
New cuda time: 1.8526400327682495
New cuda time without quantization: 0.88223797082901
New cuda time without quantization: 0.7491199970245361
New cuda time: 1.8235199451446533
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8801599740982056
New cuda time without quantization: 0.7544000148773193
New cuda time: 1.8273589611053467
New cuda time without quantization: 0.9105600118637085
New cuda time without quantization: 0.8531200289726257
New cuda time: 74.28558349609375
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.891040027141571
New cuda time without quantization: 0.9433599710464478
New cuda time: 2.0214390754699707
New cuda time without quantization: 0.8695989847183228
New cuda time without quantization: 0.7540799975395203
New cuda time: 1.818560004234314
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8969579935073853
New cuda time without quantization: 1.623039960861206
New cuda time: 2.6995201110839844
New cuda time without quantization: 0.9361600279808044
New cuda time without quantization: 0.751999020576477
New cuda time: 1.8217589855194092
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8873580098152161
New cuda time without quantization: 0.7411199808120728
New cuda time: 1.8198399543762207
New cuda time without quantization: 0.8793579936027527
New cuda time without quantization: 0.9419199824333191
New cuda time: 2.0452799797058105
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.18718719482422
New cuda time without quantization: 0.8592000007629395
New cuda time: 1.9433599710464478
New cuda time without quantization: 0.7028800249099731
New cuda time without quantization: 7.165438175201416
New cuda time: 8.355358123779297
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.50878143310547
New cuda time without quantization: 0.7153599858283997
New cuda time: 1.7985600233078003
New cuda time without quantization: 0.6857600212097168
New cuda time without quantization: 0.7809600234031677
New cuda time: 1.8507189750671387
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.6337590217590332
New cuda time without quantization: 0.7364799976348877
New cuda time: 1.8124799728393555
New cuda time without quantization: 89.48189544677734
New cuda time without quantization: 5.337919235229492
New cuda time: 6.421119213104248
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8839979767799377
New cuda time without quantization: 0.7334399819374084
New cuda time: 1.8176000118255615
New cuda time without quantization: 0.6895999908447266
New cuda time without quantization: 0.7828789949417114
New cuda time: 1.8483190536499023
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8867179751396179
New cuda time without quantization: 0.7145599722862244
New cuda time: 1.7879999876022339
New cuda time without quantization: 0.7049599885940552
New cuda time without quantization: 0.8387190103530884
New cuda time: 1.9126390218734741
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 75.21502685546875
New cuda time without quantization: 0.8740800023078918
New cuda time: 1.9566400051116943
New cuda time without quantization: 1.2807999849319458
New cuda time without quantization: 0.7447999715805054
New cuda time: 1.8174389600753784
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 6.592799186706543
New cuda time without quantization: 66.45662689208984
New cuda time: 67.76366424560547
New cuda time without quantization: 0.6977599859237671
New cuda time without quantization: 0.7742400169372559
New cuda time: 1.8483200073242188
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 6.971357822418213
New cuda time without quantization: 1.4011189937591553
New cuda time: 2.483999013900757
New cuda time without quantization: 0.8839979767799377
New cuda time without quantization: 0.7726399898529053
New cuda time: 1.8385599851608276
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.140159010887146
New cuda time without quantization: 7.983357906341553
New cuda time: 9.069598197937012
New cuda time without quantization: 0.8851180076599121
New cuda time without quantization: 0.7211199998855591
New cuda time: 1.7982399463653564
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 5.885278224945068
New cuda time without quantization: 79.59278106689453
New cuda time: 81.02157592773438
New cuda time without quantization: 0.8772789835929871
New cuda time without quantization: 0.9795200228691101
New cuda time: 2.0502400398254395
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.40286254882812
New cuda time without quantization: 0.8848000168800354
New cuda time: 1.9710400104522705
New cuda time without quantization: 0.7457600235939026
New cuda time without quantization: 0.7323200106620789
New cuda time: 1.8044790029525757
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 8.289278030395508
New cuda time without quantization: 0.8697599768638611
New cuda time: 1.9529600143432617
New cuda time without quantization: 97.52285766601562
New cuda time without quantization: 0.8529599905014038
New cuda time: 1.9312000274658203
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8868780136108398
New cuda time without quantization: 8.081117630004883
New cuda time: 9.278557777404785
New cuda time without quantization: 1.21343994140625
New cuda time without quantization: 0.7463989853858948
New cuda time: 1.813918948173523
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.031357765197754
New cuda time without quantization: 0.713919997215271
New cuda time: 1.8009599447250366
New cuda time without quantization: 0.7075200080871582
New cuda time without quantization: 0.7796800136566162
New cuda time: 1.8495999574661255
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 5.623836994171143
New cuda time without quantization: 0.9286400079727173
New cuda time: 2.0064001083374023
New cuda time without quantization: 0.7193599939346313
New cuda time without quantization: 0.7723190188407898
New cuda time: 1.8510390520095825
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8908780217170715
New cuda time without quantization: 0.7644799947738647
New cuda time: 1.8492799997329712
New cuda time without quantization: 6.048479080200195
New cuda time without quantization: 0.9478399753570557
New cuda time: 2.0196800231933594
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8956779837608337
New cuda time without quantization: 0.7622399926185608
New cuda time: 1.839359998703003
New cuda time without quantization: 0.6987199783325195
New cuda time without quantization: 0.7831990122795105
New cuda time: 1.9619189500808716
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 82.98030090332031
New cuda time without quantization: 0.8772799968719482
New cuda time: 1.960479974746704
New cuda time without quantization: 6.915358066558838
New cuda time without quantization: 0.818880021572113
New cuda time: 1.8923200368881226
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8956779837608337
New cuda time without quantization: 0.909762978553772
New cuda time: 11.88436222076416
New cuda time without quantization: 2.3755290508270264
New cuda time without quantization: 0.7633619904518127
New cuda time: 1.826725959777832
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.81483459472656
New cuda time without quantization: 0.8844829797744751
New cuda time: 1.9636869430541992
New cuda time without quantization: 1.3112050294876099
New cuda time without quantization: 0.7459220290184021
New cuda time: 1.8081660270690918
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 69.6357650756836
New cuda time without quantization: 0.8796830177307129
New cuda time: 1.9584070444107056
New cuda time without quantization: 0.9248039722442627
New cuda time without quantization: 0.7828829884529114
New cuda time: 1.8499259948730469
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.61722564697266
New cuda time without quantization: 0.8916839957237244
New cuda time: 9.268512725830078
New cuda time without quantization: 1.3321640491485596
New cuda time without quantization: 0.7811229825019836
New cuda time: 1.8448070287704468
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 70.89512634277344
New cuda time without quantization: 0.89376300573349
New cuda time: 1.993927001953125
New cuda time without quantization: 1.3473639488220215
New cuda time without quantization: 0.742563009262085
New cuda time: 1.814566969871521
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.51914978027344
New cuda time without quantization: 0.8300830125808716
New cuda time: 1.905925989151001
New cuda time without quantization: 1.7110459804534912
New cuda time without quantization: 0.7740830183029175
New cuda time: 1.8441660404205322
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 75.22090148925781
New cuda time without quantization: 0.7200019955635071
New cuda time: 1.8073660135269165
New cuda time without quantization: 1.156324028968811
New cuda time without quantization: 0.744642972946167
New cuda time: 1.8172860145568848
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 79.18267822265625
New cuda time without quantization: 0.7435219883918762
New cuda time: 1.8230459690093994
New cuda time without quantization: 1.3140850067138672
New cuda time without quantization: 0.7329620122909546
New cuda time: 1.8027260303497314
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 68.93144226074219
New cuda time without quantization: 0.9387230277061462
New cuda time: 2.019207000732422
New cuda time without quantization: 1.326084017753601
New cuda time without quantization: 0.7667229771614075
New cuda time: 1.833927035331726
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7048019766807556
New cuda time without quantization: 0.7880020141601562
New cuda time: 1.8585660457611084
New cuda time without quantization: 80.10523986816406
New cuda time without quantization: 0.9275239706039429
New cuda time: 1.9971270561218262
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7296019792556763
New cuda time without quantization: 0.7932829856872559
New cuda time: 1.866886019706726
New cuda time without quantization: 74.46826171875
New cuda time without quantization: 0.9265639781951904
New cuda time: 1.997607946395874
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7051219940185547
New cuda time without quantization: 0.8254430294036865
New cuda time: 1.956807017326355
New cuda time without quantization: 76.73467254638672
New cuda time without quantization: 0.9166439771652222
New cuda time: 1.9910470247268677
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7072020173072815
New cuda time without quantization: 0.8156830072402954
New cuda time: 1.8889670372009277
New cuda time without quantization: 1.0184030532836914
New cuda time without quantization: 0.7390429973602295
New cuda time: 1.806406021118164
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 81.4546890258789
New cuda time without quantization: 0.8944029808044434
New cuda time: 1.9732869863510132
New cuda time without quantization: 1.1764839887619019
New cuda time without quantization: 0.7528030276298523
New cuda time: 1.8187259435653687
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 73.40169525146484
New cuda time without quantization: 0.8788830041885376
New cuda time: 1.9628870487213135
New cuda time without quantization: 1.1424039602279663
New cuda time without quantization: 0.7702429890632629
New cuda time: 1.840325951576233
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 66.88679504394531
New cuda time without quantization: 0.9560030102729797
New cuda time: 2.026566982269287
New cuda time without quantization: 1.5012849569320679
New cuda time without quantization: 0.7640029788017273
New cuda time: 1.8288060426712036
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.6964830160140991
New cuda time without quantization: 0.8088030219078064
New cuda time: 1.9987269639968872
New cuda time without quantization: 84.74349975585938
New cuda time without quantization: 0.9411240220069885
New cuda time: 2.0140879154205322
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 75.12010192871094
New cuda time without quantization: 0.9763230085372925
New cuda time: 2.0608069896698
New cuda time without quantization: 2.6387290954589844
New cuda time without quantization: 0.7408030033111572
New cuda time: 1.8076870441436768
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 75.4506607055664
New cuda time without quantization: 0.9699230194091797
New cuda time: 2.052807092666626
New cuda time without quantization: 1.4072049856185913
New cuda time without quantization: 7.625307083129883
New cuda time: 8.702271461486816
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 67.98951721191406
New cuda time without quantization: 4.276655197143555
New cuda time: 5.405939102172852
New cuda time without quantization: 0.703361988067627
New cuda time without quantization: 0.7852830290794373
New cuda time: 1.8512070178985596
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7259219884872437
New cuda time without quantization: 0.7905629873275757
New cuda time: 1.8643269538879395
New cuda time without quantization: 34.51100158691406
New cuda time without quantization: 1.0481640100479126
New cuda time: 2.1220879554748535
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7416020035743713
New cuda time without quantization: 0.7569630146026611
New cuda time: 1.8332860469818115
New cuda time without quantization: 0.9622430205345154
New cuda time without quantization: 0.7640020251274109
New cuda time: 1.8360060453414917
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7025629878044128
New cuda time without quantization: 0.803043007850647
New cuda time: 1.8740869760513306
New cuda time without quantization: 4.630414962768555
New cuda time without quantization: 0.9086430072784424
New cuda time: 1.98272705078125
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.98272705078125
New cuda time without quantization: 0.7569630146026611
New cuda time: 1.83536696434021
New cuda time without quantization: 0.7060829997062683
New cuda time without quantization: 0.7920029759407043
New cuda time: 1.8624060153961182
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.6971219778060913
New cuda time without quantization: 0.7924820184707642
New cuda time: 1.9132859706878662
New cuda time without quantization: 0.9126430153846741
New cuda time without quantization: 0.7464029788970947
New cuda time: 1.8139270544052124
torch.Size([4, 128, 103, 768])New cuda time without quantization: 8.01839828491211
New cuda time: 13.119997024536133
New cuda time without quantization: 0.7059199810028076
New cuda time without quantization: 0.7879999876022339
New cuda time: 1.853119969367981
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 6.592957019805908
New cuda time without quantization: 0.8851190209388733
New cuda time: 1.9695990085601807
New cuda time without quantization: 0.7039989829063416
New cuda time without quantization: 0.792959988117218
New cuda time: 1.8625600337982178
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8956779837608337
New cuda time without quantization: 0.8340799808502197
New cuda time: 1.9028799533843994
New cuda time without quantization: 5.995358943939209
New cuda time without quantization: 0.9435200095176697
New cuda time: 2.019360065460205
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.893917977809906
New cuda time without quantization: 7.926397800445557
New cuda time: 9.12271785736084
New cuda time without quantization: 0.6892799735069275
New cuda time without quantization: 0.7705600261688232
New cuda time: 1.838879942893982
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8889579772949219
New cuda time without quantization: 7.699518203735352
New cuda time: 8.787837982177734
New cuda time without quantization: 0.7036799788475037
New cuda time without quantization: 0.792959988117218
New cuda time: 1.8664000034332275
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.8630380630493164
New cuda time without quantization: 0.7209590077400208
New cuda time: 1.7996790409088135
New cuda time without quantization: 0.6948800086975098
New cuda time without quantization: 0.7739199995994568
New cuda time: 1.8459199666976929
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.0382380485534668
New cuda time without quantization: 0.9385600090026855
New cuda time: 2.019200086593628
New cuda time without quantization: 0.7129600048065186
New cuda time without quantization: 0.7830399870872498
New cuda time: 1.848958969116211
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 5.6927971839904785
New cuda time without quantization: 0.7777600288391113
New cuda time: 1.8609600067138672
New cuda time without quantization: 0.7123200297355652
New cuda time without quantization: 0.7951989769935608
New cuda time: 1.8583990335464478
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8980780243873596
New cuda time without quantization: 0.7206400036811829
New cuda time: 1.7940800189971924
New cuda time without quantization: 0.7003200054168701
New cuda time without quantization: 0.7977589964866638
New cuda time: 1.8684790134429932
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.2535990476608276
New cuda time without quantization: 0.7321599721908569
New cuda time: 1.8056000471115112
New cuda time without quantization: 0.8737580180168152
New cuda time without quantization: 0.7470399737358093
New cuda time: 1.818560004234314
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9491199851036072
New cuda time without quantization: 0.7383999824523926
New cuda time: 1.8169599771499634
New cuda time without quantization: 0.8910380005836487
New cuda time without quantization: 0.7432000041007996
New cuda time: 1.814560055732727
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.17631995677948
New cuda time without quantization: 0.7220799922943115
New cuda time: 1.7968000173568726
New cuda time without quantization: 0.8825579881668091
New cuda time without quantization: 0.7497599720954895
New cuda time: 1.8153599500656128
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.0111989974975586
New cuda time without quantization: 0.7163199782371521
New cuda time: 1.7902400493621826
New cuda time without quantization: 0.7163199782371521
New cuda time without quantization: 0.781279981136322
New cuda time: 1.8507200479507446
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8966379761695862
New cuda time without quantization: 0.8886399865150452
New cuda time: 1.9665600061416626
New cuda time without quantization: 0.6995199918746948
New cuda time without quantization: 0.7817599773406982
New cuda time: 1.8447990417480469
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.910398006439209
New cuda time without quantization: 0.8822399973869324
New cuda time: 1.96288001537323
New cuda time without quantization: 0.7182400226593018
New cuda time without quantization: 0.8022400140762329
New cuda time: 1.875519037246704
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8950380086898804
New cuda time without quantization: 0.7232000231742859
New cuda time: 1.8007999658584595
New cuda time without quantization: 0.6947199702262878
New cuda time without quantization: 0.7873589992523193
New cuda time: 1.8507189750671387
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.1292799711227417
New cuda time without quantization: 0.7239999771118164
New cuda time: 1.7993589639663696
New cuda time without quantization: 0.8766379952430725
New cuda time without quantization: 0.7262399792671204
New cuda time: 1.800320029258728
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8977580070495605
New cuda time without quantization: 0.718720018863678
New cuda time: 1.795199990272522
New cuda time without quantization: 0.6967999935150146
New cuda time without quantization: 0.7879999876022339
New cuda time: 1.858240008354187
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8951979875564575
New cuda time without quantization: 0.718720018863678
New cuda time: 1.8025599718093872
New cuda time without quantization: 0.6900799870491028
New cuda time without quantization: 7.651197910308838
New cuda time: 8.728157997131348
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8897579908370972
New cuda time without quantization: 0.7132800221443176
New cuda time: 1.897279977798462
New cuda time without quantization: 3.6500790119171143
New cuda time without quantization: 0.7505599856376648
New cuda time: 1.8167999982833862
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9742400050163269
New cuda time without quantization: 0.7387189865112305
New cuda time: 1.8126389980316162
New cuda time without quantization: 34.59583282470703
New cuda time without quantization: 0.716159999370575
New cuda time: 1.7947200536727905
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9364799857139587
New cuda time without quantization: 0.7443199753761292
New cuda time: 1.8175990581512451
New cuda time without quantization: 0.7396789789199829
New cuda time without quantization: 0.7750399708747864
New cuda time: 1.8447999954223633
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.0708800554275513
New cuda time without quantization: 0.7286390066146851
New cuda time: 1.7974389791488647
New cuda time without quantization: 7.715356826782227
New cuda time without quantization: 0.9297599792480469
New cuda time: 2.006558895111084
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8664000034332275
New cuda time without quantization: 0.7739199995994568
New cuda time: 1.8472000360488892
New cuda time without quantization: 0.9991999864578247
New cuda time without quantization: 0.7446399927139282
New cuda time: 1.811998963356018
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.55551815032959
New cuda time without quantization: 0.7171199917793274
New cuda time: 1.790719985961914
New cuda time without quantization: 0.9648000001907349
New cuda time without quantization: 0.7468799948692322
New cuda time: 1.825119972229004
8.037954330444336
New cuda time: 10.547884941101074
New cuda time without quantization: 4.0528178215026855
New cuda time without quantization: 0.7440029978752136
New cuda time: 1.8148880004882812
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 75.58303833007812
New cuda time without quantization: 6.968510150909424
New cuda time: 8.050914764404297
New cuda time without quantization: 1.3228850364685059
New cuda time without quantization: 0.7624030113220215
New cuda time: 1.8304070234298706
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 72.5833511352539
New cuda time without quantization: 0.9411240220069885
New cuda time: 2.0209689140319824
New cuda time without quantization: 6.889469146728516
New cuda time without quantization: 0.9243239760398865
New cuda time: 1.9996880292892456
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 78.33281707763672
New cuda time without quantization: 8.168194770812988
New cuda time: 9.35811996459961
New cuda time without quantization: 1.5084869861602783
New cuda time without quantization: 0.7374429702758789
New cuda time: 1.8000080585479736
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.99136352539062
New cuda time without quantization: 7.8678741455078125
New cuda time: 8.948838233947754
New cuda time without quantization: 1.4953659772872925
New cuda time without quantization: 0.7697629928588867
New cuda time: 1.840008020401001
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 78.8747329711914
New cuda time without quantization: 2.960973024368286
New cuda time: 4.044338226318359
New cuda time without quantization: 2.053607940673828
New cuda time without quantization: 0.7289630174636841
New cuda time: 1.800487995147705
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 76.95793151855469
New cuda time without quantization: 1.0132850408554077
New cuda time: 2.0889689922332764
New cuda time without quantization: 1.3126449584960938
New cuda time without quantization: 0.7483230233192444
New cuda time: 1.8179270029067993
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 76.9686508178711
New cuda time without quantization: 5.692503929138184
New cuda time: 6.7797088623046875
New cuda time without quantization: 1.030243992805481
New cuda time without quantization: 0.7598429918289185
New cuda time: 1.8331279754638672
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 69.71853637695312
New cuda time without quantization: 1.0200049877166748
New cuda time: 2.1004889011383057
New cuda time without quantization: 1.474086046218872
New cuda time without quantization: 0.731203019618988
New cuda time: 1.8030469417572021
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.148648977279663
New cuda time without quantization: 0.8252840042114258
New cuda time: 1.8971279859542847
New cuda time without quantization: 80.19794464111328
New cuda time without quantization: 0.9136040210723877
New cuda time: 1.9803279638290405
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.1401689052581787
New cuda time without quantization: 0.8267239928245544
New cuda time: 1.9012880325317383
New cuda time without quantization: 74.57872009277344
New cuda time without quantization: 0.9572839736938477
New cuda time: 2.0328080654144287
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.0110578536987305
New cuda time without quantization: 0.8204839825630188
New cuda time: 1.895367980003357
New cuda time without quantization: 77.17376708984375
New cuda time without quantization: 0.9339240193367004
New cuda time: 2.0081679821014404
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.694580078125
New cuda time without quantization: 0.8171229958534241
New cuda time: 1.8929680585861206
New cuda time without quantization: 1.146723985671997
New cuda time without quantization: 0.7649629712104797
New cuda time: 1.8305679559707642
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 84.02739715576172
New cuda time without quantization: 0.9540839791297913
New cuda time: 2.0302491188049316
New cuda time without quantization: 1.3260860443115234
New cuda time without quantization: 0.7619230151176453
New cuda time: 1.836967945098877
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.39552307128906
New cuda time without quantization: 0.9531239867210388
New cuda time: 2.0355288982391357
New cuda time without quantization: 1.0707249641418457
New cuda time without quantization: 0.7942429780960083
New cuda time: 1.8606480360031128
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 68.62189483642578
New cuda time without quantization: 1.0782450437545776
New cuda time: 2.158889055252075
New cuda time without quantization: 1.619526982307434
New cuda time without quantization: 0.7740839719772339
New cuda time: 1.8483279943466187
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.2864139080047607
New cuda time without quantization: 0.8236839771270752
New cuda time: 2.0104079246520996
New cuda time without quantization: 84.8454818725586
New cuda time without quantization: 0.9456040263175964
New cuda time: 2.0249691009521484
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 78.4192123413086
New cuda time without quantization: 1.055845022201538
New cuda time: 2.1329689025878906
New cuda time without quantization: 2.3203299045562744
New cuda time without quantization: 0.7641630172729492
New cuda time: 1.835368037223816
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.57137298583984
New cuda time without quantization: 1.0633649826049805
New cuda time: 2.1440091133117676
New cuda time without quantization: 1.580327033996582
New cuda time without quantization: 7.604833126068115
New cuda time: 8.69539737701416
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.16542053222656
New cuda time without quantization: 1.16656494140625
New cuda time: 2.24849009513855
New cuda time without quantization: 4.227218151092529
New cuda time without quantization: 0.7627230286598206
New cuda time: 1.8352069854736328
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.268649101257324
New cuda time without quantization: 0.8193640112876892
New cuda time: 1.8969680070877075
New cuda time without quantization: 34.57838821411133
New cuda time without quantization: 1.116165041923523
New cuda time: 2.1915290355682373
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.254737854003906
New cuda time without quantization: 0.8292840123176575
New cuda time: 1.8992079496383667
New cuda time without quantization: 1.0147240161895752
New cuda time without quantization: 0.7603229880332947
New cuda time: 1.8288079500198364
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.5934510231018066
New cuda time without quantization: 0.8339229822158813
New cuda time: 1.9092880487442017
New cuda time without quantization: 0.871042013168335
New cuda time without quantization: 0.8929640054702759
New cuda time: 1.9598480463027954
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 6.448348045349121
New cuda time without quantization: 0.9414439797401428
New cuda time: 2.0137689113616943
New cuda time without quantization: 1.4321659803390503
New cuda time without quantization: 0.7548829913139343
New cuda time: 1.8270469903945923
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 5.608983039855957
New cuda time without quantization: 0.9201639890670776
New cuda time: 2.0313680171966553
New cuda time without quantization: 0.9470440149307251
New cuda time without quantization: 0.7632030248641968
New cuda time: 1.8270479440689087
torch.Size([4, 128, 103, 768]) torch.float16
8.037405967712402
New cuda time: 11.76891040802002
New cuda time without quantization: 2.3566300868988037
New cuda time without quantization: 0.7841569781303406
New cuda time: 1.8583920001983643
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.98432159423828
New cuda time without quantization: 6.951970100402832
New cuda time: 8.030686378479004
New cuda time without quantization: 1.3123149871826172
New cuda time without quantization: 0.7500770092010498
New cuda time: 1.820631980895996
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.98577880859375
New cuda time without quantization: 0.9908760190010071
New cuda time: 2.0713510513305664
New cuda time without quantization: 6.823492050170898
New cuda time without quantization: 0.9303960204124451
New cuda time: 1.999351978302002
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.95535278320312
New cuda time without quantization: 8.164606094360352
New cuda time: 9.360760688781738
New cuda time without quantization: 1.4484740495681763
New cuda time without quantization: 0.7721570134162903
New cuda time: 1.8431930541992188
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.50736999511719
New cuda time without quantization: 7.8410868644714355
New cuda time: 8.921882629394531
New cuda time without quantization: 1.4615939855575562
New cuda time without quantization: 0.7510370016098022
New cuda time: 1.817911982536316
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 78.50254821777344
New cuda time without quantization: 3.004626989364624
New cuda time: 4.084143161773682
New cuda time without quantization: 2.3403100967407227
New cuda time without quantization: 0.787837028503418
New cuda time: 1.856632947921753
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 76.5222396850586
New cuda time without quantization: 1.0015950202941895
New cuda time: 2.0787110328674316
New cuda time without quantization: 1.2075140476226807
New cuda time without quantization: 0.7678369879722595
New cuda time: 1.8383920192718506
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 76.4609603881836
New cuda time without quantization: 5.804934978485107
New cuda time: 6.8849310874938965
New cuda time without quantization: 1.414713978767395
New cuda time without quantization: 0.7620769739151001
New cuda time: 1.8335930109024048
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 69.5827407836914
New cuda time without quantization: 0.9903960227966309
New cuda time: 2.0643110275268555
New cuda time without quantization: 1.4134340286254883
New cuda time without quantization: 0.7979170083999634
New cuda time: 1.864313006401062
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.3180699348449707
New cuda time without quantization: 0.8028770089149475
New cuda time: 1.8772720098495483
New cuda time without quantization: 80.21598052978516
New cuda time without quantization: 0.9543960094451904
New cuda time: 2.026711940765381
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.9097520112991333
New cuda time without quantization: 0.7953569889068604
New cuda time: 1.869271993637085
New cuda time without quantization: 74.57184600830078
New cuda time without quantization: 0.9582359790802002
New cuda time: 2.032792091369629
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.7300639152526855
New cuda time without quantization: 0.820156991481781
New cuda time: 1.8918319940567017
New cuda time without quantization: 77.05280303955078
New cuda time without quantization: 0.9585559964179993
New cuda time: 2.0305519104003906
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.217103004455566
New cuda time without quantization: 0.8171160221099854
New cuda time: 1.899672031402588
New cuda time without quantization: 1.078874945640564
New cuda time without quantization: 0.7591959834098816
New cuda time: 1.8284720182418823
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 83.53324890136719
New cuda time without quantization: 0.9502360224723816
New cuda time: 2.028311014175415
New cuda time without quantization: 1.2787139415740967
New cuda time without quantization: 0.7513570189476013
New cuda time: 1.8161530494689941
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 74.23136901855469
New cuda time without quantization: 0.9374359846115112
New cuda time: 2.01711106300354
New cuda time without quantization: 1.2294349670410156
New cuda time without quantization: 0.7355170249938965
New cuda time: 1.8046330213546753
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 68.3062744140625
New cuda time without quantization: 1.0191949605941772
New cuda time: 2.096311092376709
New cuda time without quantization: 1.5979130268096924
New cuda time without quantization: 0.7475169897079468
New cuda time: 1.8171119689941406
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.26814603805542
New cuda time without quantization: 0.8038370013237
New cuda time: 1.9847919940948486
New cuda time without quantization: 84.83196258544922
New cuda time without quantization: 0.9204760193824768
New cuda time: 1.9884719848632812
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 78.22479248046875
New cuda time without quantization: 1.018875002861023
New cuda time: 2.098391056060791
New cuda time without quantization: 2.4619100093841553
New cuda time without quantization: 0.7537559866905212
New cuda time: 1.8243119716644287
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 77.22639465332031
New cuda time without quantization: 1.025434970855713
New cuda time: 2.104310989379883
New cuda time without quantization: 1.5379129648208618
New cuda time without quantization: 7.624607086181641
New cuda time: 8.693082809448242
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 70.6699447631836
New cuda time without quantization: 1.048954963684082
New cuda time: 2.220310926437378
New cuda time without quantization: 4.283661842346191
New cuda time without quantization: 0.7547169923782349
New cuda time: 1.82511305809021
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.9729520082473755
New cuda time without quantization: 0.8580759763717651
New cuda time: 1.9211119413375854
New cuda time without quantization: 34.53121566772461
New cuda time without quantization: 1.1023950576782227
New cuda time: 2.1811110973358154
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.27390193939209
New cuda time without quantization: 0.8209559917449951
New cuda time: 1.8945519924163818
New cuda time without quantization: 0.9828760027885437
New cuda time without quantization: 0.7476760149002075
New cuda time: 1.81551194190979
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.576788902282715
New cuda time without quantization: 0.8047969937324524
New cuda time: 1.8745520114898682
New cuda time without quantization: 7.844766139984131
New cuda time without quantization: 0.9102360010147095
New cuda time: 1.9785510301589966
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 6.848771095275879
New cuda time without quantization: 0.8835160136222839
New cuda time: 1.9524719715118408
New cuda time without quantization: 1.876312017440796
New cuda time without quantization: 0.7689570188522339
New cuda time: 1.8375920057296753
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 5.644774913787842
New cuda time without quantization: 0.911516010761261
New cuda time: 2.036151885986328
New cuda time without quantization: 0.9239959716796875
New cuda time without quantization: 0.7606369853019714
New cuda time: 1.829272985458374
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 5.217418193817139
New cuda time without quantization: 0.7047970294952393
New cuda time: 1.7769529819488525
New cuda time without quantization: 0.9406359791755676
New cuda time without quantization: 0.832315981388092
New cuda time: 1.901911973953247
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 50.72602462768555
New cuda time without quantization: 0.9379169940948486
New cuda time: 2.015990972518921
New cuda time without quantization: 1.0932749509811401
New cuda time without quantization: 0.755515992641449
New cuda time: 1.8241519927978516
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.851978778839111
New cuda time without quantization: 6.622372150421143
New cuda time: 7.69724702835083
New cuda time without quantization: 79.99838256835938
New cuda time without quantization: 0.9377560019493103
New cuda time: 2.0070319175720215
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.382061004638672
New cuda time without quantization: 0.8118370175361633
New cuda time: 1.890071988105774
New cuda time without quantization: 72.33409881591797
New cuda time without quantization: 0.9499160051345825
New cuda time: 2.0223920345306396
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.500633955001831
New cuda time without quantization: 0.9380760192871094
New cuda time: 2.0159919261932373
New cuda time without quantization: 7.618368148803711
New cuda time without quantization: 72.28577423095703
New cuda time: 73.37408447265625
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.007022857666016
New cuda time without quantization: 0.8348770141601562
New cuda time: 1.9059120416641235
New cuda time without quantization: 1.0551960468292236
New cuda time without quantization: 0.7871969938278198
New cuda time: 1.8511929512023926
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 87.95451354980469
New cuda time without quantization: 0.9471960067749023
New cuda time: 2.0798308849334717
New cuda time without quantization: 1.5326329469680786
New cuda time without quantization: 8.003807067871094
New cuda time: 9.085400581359863
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 76.32943725585938
New cuda time without quantization: 0.9414359927177429
New cuda time: 2.0595109462738037
New cuda time without quantization: 0.9337559938430786
New cuda time without quantization: 0.7705569863319397
New cuda time: 1.8315119743347168
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.99969482421875
New cuda time without quantization: 0.936955988407135
New cuda time: 2.0145509243011475
New cuda time without quantization: 0.9268760085105896
New cuda time without quantization: 0.7684770226478577
New cuda time: 1.8399920463562012
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 67.86946868896484
New cuda time without quantization: 0.9353560209274292
New cuda time: 2.026071071624756
New cuda time without quantization: 1.0921549797058105
New cuda time without quantization: 0.8116769790649414
New cuda time: 1.9105520248413086
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.1217550039291382
New cuda time without quantization: 0.8099160194396973
New cuda time: 1.8820719718933105
New cuda time without quantization: 82.97660827636719
New cuda time without quantization: 0.9340760111808777
New cuda time: 2.003511905670166
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 27.94628143310547
New cuda time without quantization: 0.9243159890174866
New cuda time: 1.996791958808899
New cuda time without quantization: 1.2247949838638306
New cuda time without quantization: 0.7571160197257996
New cuda time: 1.8262319564819336
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9059150218963623
New cuda time without quantization: 0.7844769954681396
New cuda time: 1.8644720315933228
New cuda time without quantization: 0.9238359928131104
New cuda time without quantization: 0.7441570162773132
New cuda time: 1.8143919706344604
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7033569812774658
New cuda time without quantization: 0.8060770034790039
New cuda time: 1.87807297706604
New cuda time without quantization: 0.8108770251274109
New cuda time without quantization: 0.7457559704780579
New cuda time: 1.8059120178222656
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.4537439346313477
New cuda time without quantization: 0.8003159761428833
New cuda time: 1.876471996307373
New cuda time without quantization: 0.9076759815216064
New cuda time without quantization: 0.7443169951438904
New cuda time: 1.818071961402893
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7230370044708252
New cuda time without quantization: 0.8038370013237
New cuda time: 1.8774319887161255
New cuda time without quantization: 0.9412760138511658
New cuda time without quantization: 0.7580770254135132
New cuda time: 1.8243119716644287
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8953549861907959
New cuda time without quantization: 0.7278370261192322
New cuda time: 1.8012720346450806
2024-07-11 02:03:40 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time without quantization: 5.196022987365723
New cuda time without quantization: 1.9227279424667358
New cuda time: 2.99809193611145
New cuda time without quantization: 0.9411240220069885
New cuda time without quantization: 0.8267229795455933
New cuda time: 1.8915289640426636
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 50.60357666015625
New cuda time without quantization: 0.9702439904212952
New cuda time: 2.0518479347229004
New cuda time without quantization: 1.1272050142288208
New cuda time without quantization: 0.7683230042457581
New cuda time: 1.8387279510498047
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 10.449004173278809
New cuda time without quantization: 0.8992040157318115
New cuda time: 1.9740890264511108
New cuda time without quantization: 79.91138458251953
New cuda time without quantization: 0.9401640295982361
New cuda time: 2.0161681175231934
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.556660175323486
New cuda time without quantization: 0.8243240118026733
New cuda time: 1.890887975692749
New cuda time without quantization: 72.39263153076172
New cuda time without quantization: 0.9401640295982361
New cuda time: 2.0132880210876465
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.4307270050048828
New cuda time without quantization: 0.9604840278625488
New cuda time: 2.0308890342712402
New cuda time without quantization: 71.8539047241211
New cuda time without quantization: 1.2864060401916504
New cuda time: 2.3843300342559814
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.6380960941314697
New cuda time without quantization: 0.8035230040550232
New cuda time: 1.8902479410171509
New cuda time without quantization: 0.9260839819908142
New cuda time without quantization: 0.7454429864883423
New cuda time: 1.824807047843933
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 87.86853790283203
New cuda time without quantization: 0.9657649993896484
New cuda time: 2.1065690517425537
New cuda time without quantization: 1.5344059467315674
New cuda time without quantization: 74.8172836303711
New cuda time: 75.95264434814453
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.4089701175689697
New cuda time without quantization: 0.9988840222358704
New cuda time: 2.1132900714874268
New cuda time without quantization: 0.9440039992332458
New cuda time without quantization: 0.7596830129623413
New cuda time: 1.8267279863357544
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.9105453491211
New cuda time without quantization: 0.9692839980125427
New cuda time: 2.046088933944702
New cuda time without quantization: 0.974403977394104
New cuda time without quantization: 0.7496039867401123
New cuda time: 1.8225680589675903
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 62.235145568847656
New cuda time without quantization: 0.9524840116500854
New cuda time: 2.0344090461730957
New cuda time without quantization: 1.1912050247192383
New cuda time without quantization: 0.8256040215492249
New cuda time: 1.8963279724121094
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7067229747772217
New cuda time without quantization: 0.8593639731407166
New cuda time: 1.9321680068969727
New cuda time without quantization: 82.61395263671875
New cuda time without quantization: 0.9552040100097656
New cuda time: 2.0289690494537354
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 27.540437698364258
New cuda time without quantization: 0.930724024772644
New cuda time: 2.0032079219818115
New cuda time without quantization: 0.8934440016746521
New cuda time without quantization: 0.7556830048561096
New cuda time: 1.8187270164489746
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9974430203437805
New cuda time without quantization: 0.8456029891967773
New cuda time: 1.9187289476394653
New cuda time without quantization: 1.0779240131378174
New cuda time without quantization: 0.770563006401062
New cuda time: 1.8532880544662476
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.8448070287704468
New cuda time without quantization: 0.834883987903595
New cuda time: 1.9011280536651611
New cuda time without quantization: 1.1409649848937988
New cuda time without quantization: 0.7470430135726929
New cuda time: 1.8129680156707764
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.8180949687957764
New cuda time without quantization: 0.8550429940223694
New cuda time: 1.9334490299224854
New cuda time without quantization: 1.0564839839935303
New cuda time without quantization: 0.7764829993247986
New cuda time: 1.844167947769165
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9568039774894714
New cuda time without quantization: 0.8347240090370178
New cuda time: 1.9065680503845215
New cuda time without quantization: 1.0193639993667603
New cuda time without quantization: 0.7721629738807678
New cuda time: 1.837448000907898
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9361630082130432
New cuda time without quantization: 0.8185639977455139
New cuda time: 1.8921680450439453
2024-07-11 02:03:40 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.390558958053589
New cuda time without quantization: 3.16287899017334
New cuda time: 4.231998920440674
New cuda time without quantization: 0.9436799883842468
New cuda time without quantization: 0.7515190243721008
New cuda time: 1.814558982849121
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8902379870414734
New cuda time without quantization: 0.8895999789237976
New cuda time: 1.9651199579238892
New cuda time without quantization: 0.7310400009155273
New cuda time without quantization: 0.7775999903678894
New cuda time: 1.8502390384674072
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.084319114685059
New cuda time without quantization: 6.403997898101807
New cuda time: 7.493437767028809
New cuda time without quantization: 0.873278021812439
New cuda time without quantization: 0.7587199807167053
New cuda time: 1.8763200044631958
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 3.423358917236328
New cuda time without quantization: 0.7206400036811829
New cuda time: 1.8065600395202637
New cuda time without quantization: 0.8871979713439941
New cuda time without quantization: 0.8182399868965149
New cuda time: 1.8924800157546997
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.888159990310669
New cuda time without quantization: 0.7440000176429749
New cuda time: 1.819200038909912
New cuda time without quantization: 78.27694702148438
New cuda time without quantization: 0.8796799778938293
New cuda time: 1.9494400024414062
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.6556799411773682
New cuda time without quantization: 0.721439003944397
New cuda time: 1.8599989414215088
New cuda time without quantization: 0.7502390146255493
New cuda time without quantization: 0.7593600153923035
New cuda time: 1.8289599418640137
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8860780000686646
New cuda time without quantization: 0.7368000149726868
New cuda time: 1.8172800540924072
New cuda time without quantization: 0.6969599723815918
New cuda time without quantization: 82.18126678466797
New cuda time: 83.50045776367188
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9004799723625183
New cuda time without quantization: 0.9126399755477905
New cuda time: 1.9833589792251587
New cuda time without quantization: 0.7729589939117432
New cuda time without quantization: 0.7524799704551697
New cuda time: 1.8198399543762207
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8884779810905457
New cuda time without quantization: 0.9287999868392944
New cuda time: 2.0614399909973145
New cuda time without quantization: 0.8113600015640259
New cuda time without quantization: 0.7569599747657776
New cuda time: 1.8310400247573853
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8820779919624329
New cuda time without quantization: 0.9291200041770935
New cuda time: 1.9966399669647217
New cuda time without quantization: 0.7105600237846375
New cuda time without quantization: 0.7871999740600586
New cuda time: 1.8558390140533447
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.6967999935150146
New cuda time without quantization: 0.7305600047111511
New cuda time: 1.7991989850997925
New cuda time without quantization: 0.8654379844665527
New cuda time without quantization: 0.9590399861335754
New cuda time: 2.032320022583008
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.8855999708175659
New cuda time without quantization: 0.9175999760627747
New cuda time: 1.9884790182113647
New cuda time without quantization: 0.9137589931488037
New cuda time without quantization: 0.7619199752807617
New cuda time: 1.8223999738693237
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.3988779783248901
New cuda time without quantization: 0.7671999931335449
New cuda time: 1.84607994556427
New cuda time without quantization: 0.9412800073623657
New cuda time without quantization: 0.7537599802017212
New cuda time: 1.82607901096344
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.756959915161133
New cuda time without quantization: 0.7235199809074402
New cuda time: 1.797760009765625
New cuda time without quantization: 1.0111989974975586
New cuda time without quantization: 0.7470399737358093
New cuda time: 1.8171199560165405
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 4.675999164581299
New cuda time without quantization: 0.7249600291252136
New cuda time: 1.8030400276184082
New cuda time without quantization: 0.9361600279808044
New cuda time without quantization: 0.7531200051307678
New cuda time: 1.8217600584030151
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.2100799083709717
New cuda time without quantization: 0.760798990726471
New cuda time: 1.8334389925003052
New cuda time without quantization: 0.9028800129890442
New cuda time without quantization: 0.7576000094413757
New cuda time: 1.82368004322052
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.172959089279175
New cuda time without quantization: 0.8675199747085571
New cuda time: 1.9457579851150513
2024-07-11 02:03:40 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
 torch.float16
New cuda time without quantization: 0.6992020010948181
New cuda time without quantization: 3.2120110988616943
New cuda time: 4.285295009613037
New cuda time without quantization: 0.8891230225563049
New cuda time without quantization: 0.7576029896736145
New cuda time: 1.8238470554351807
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 46.64704513549805
New cuda time without quantization: 0.8838430047035217
New cuda time: 1.9582469463348389
New cuda time without quantization: 0.9467229843139648
New cuda time without quantization: 0.7548829913139343
New cuda time: 1.8249670267105103
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.6896020174026489
New cuda time without quantization: 6.450901985168457
New cuda time: 7.543866157531738
New cuda time without quantization: 80.0767593383789
New cuda time without quantization: 0.8219220042228699
New cuda time: 1.8905659914016724
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7156829833984375
New cuda time without quantization: 0.8128020167350769
New cuda time: 1.8992060422897339
New cuda time without quantization: 72.18457794189453
New cuda time without quantization: 0.9168040156364441
New cuda time: 1.993927001953125
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.930404007434845
New cuda time without quantization: 0.7753620147705078
New cuda time: 1.8521660566329956
New cuda time without quantization: 5.99730110168457
New cuda time without quantization: 72.28153228759766
New cuda time: 73.39033508300781
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.7075219750404358
New cuda time without quantization: 0.8012819886207581
New cuda time: 1.8764859437942505
New cuda time without quantization: 0.9593639969825745
New cuda time without quantization: 0.7547230124473572
New cuda time: 1.8342469930648804
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 85.57118225097656
New cuda time without quantization: 0.866083025932312
New cuda time: 1.93744695186615
New cuda time without quantization: 1.4929660558700562
New cuda time without quantization: 7.964508056640625
New cuda time: 9.04531192779541
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 72.6412124633789
New cuda time without quantization: 0.877282977104187
New cuda time: 1.951846957206726
New cuda time without quantization: 1.0411239862442017
New cuda time without quantization: 0.7523229718208313
New cuda time: 1.8238459825515747
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 71.5316162109375
New cuda time without quantization: 0.9134430289268494
New cuda time: 2.045607089996338
New cuda time without quantization: 0.9676839709281921
New cuda time without quantization: 0.763683021068573
New cuda time: 1.833287000656128
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 68.32936096191406
New cuda time without quantization: 0.907522976398468
New cuda time: 1.9788869619369507
New cuda time without quantization: 1.0777629613876343
New cuda time without quantization: 0.7272030115127563
New cuda time: 1.7995270490646362
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.3649649620056152
New cuda time without quantization: 0.8035230040550232
New cuda time: 1.8739269971847534
New cuda time without quantization: 82.33596801757812
New cuda time without quantization: 0.8992040157318115
New cuda time: 1.9787269830703735
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 23.529844284057617
New cuda time without quantization: 0.9491239786148071
New cuda time: 2.022407054901123
New cuda time without quantization: 1.147204041481018
New cuda time without quantization: 0.7572829723358154
New cuda time: 1.826727032661438
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.9440019726753235
New cuda time without quantization: 0.7361630201339722
New cuda time: 1.8056069612503052
New cuda time without quantization: 0.9502429962158203
New cuda time without quantization: 0.7689629793167114
New cuda time: 1.8371269702911377
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 2.243367910385132
New cuda time without quantization: 0.8435230255126953
New cuda time: 1.915526032447815
New cuda time without quantization: 0.9369630217552185
New cuda time without quantization: 0.7486429810523987
New cuda time: 1.822566032409668
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 0.70592200756073
New cuda time without quantization: 0.8156819939613342
New cuda time: 1.8889659643173218
New cuda time without quantization: 0.9387230277061462
New cuda time without quantization: 0.7569620013237
New cuda time: 1.8214459419250488
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.782405972480774
New cuda time without quantization: 0.7584030032157898
New cuda time: 1.8366470336914062
New cuda time without quantization: 0.9137629866600037
New cuda time without quantization: 0.744642972946167
New cuda time: 1.812487006187439
torch.Size([4, 128, 103, 768]) torch.float16
New cuda time without quantization: 1.5662460327148438
New cuda time without quantization: 0.8827229738235474
New cuda time: 1.9561660289764404
2024-07-11 02:03:40 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-11 02:03:40 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-11 02:03:40 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-11 02:03:40 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-11 02:03:40 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-11 02:03:40 | INFO | fairseq_cli.eval_lm | Evaluated 88,361 tokens in 35.9s (2463.30 tokens/s)
2024-07-11 02:03:40 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.8963, Perplexity: 7.45
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
