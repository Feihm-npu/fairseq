2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10753
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10753
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15086
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15065
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12457
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12457
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15086
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 3
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 3
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15065
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12457
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 1
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15086
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 2
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15086
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10753
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 1
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 0
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15065
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12457
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15065
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10753
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 2
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 3
2024-07-09 22:16:16 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15086', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:16 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 22:16:17 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12457', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 22:16:17 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 22:16:17 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 22:16:17 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 22:16:17 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 22:16:17 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 1
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 2
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 0
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 3
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 1
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 2
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-001.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12209
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13509
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13509
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17191
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16046
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12209
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17191
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17191
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 2
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 1
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16046
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17191
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 1
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 3
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 0
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13509
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16046
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16046
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12209
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 3
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 2
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13509
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 0
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 2
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12209
2024-07-09 22:16:17 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 2
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10753', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:17 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 22:16:18 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 22:16:18 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 22:16:18 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15065', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 22:16:18 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 22:16:18 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 22:16:18 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16046', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17191', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:18 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 22:16:18 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 22:16:18 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 22:16:18 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 22:16:18 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 22:16:18 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 22:16:18 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 22:16:18 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 3
2024-07-09 22:16:18 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 1
2024-07-09 22:16:18 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 1
2024-07-09 22:16:18 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 3
2024-07-09 22:16:18 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 0
2024-07-09 22:16:18 | INFO | fairseq.distributed.utils | initialized host t007-002.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12209', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13509', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 22:16:19 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 22:16:19 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 22:16:19 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 22:16:19 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 22:16:19 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 22:16:19 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 22:16:19 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 22:16:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 22:16:23 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 22:16:44 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 22:16:45 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 22:16:46 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 22:16:46 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 22:16:47 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 22:16:49 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 22:16:50 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 22:16:50 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 22:16:57 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 22:17:05 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 22:17:07 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 22:17:07 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 22:17:08 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 22:17:08 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 22:17:08 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 22:17:09 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 22:17:12 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 22:17:32 | INFO | fairseq_cli.eval_lm | load time: 75.92 seconds
2024-07-09 22:17:44 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 22:18:15 | INFO | fairseq_cli.eval_lm | load time: 116.74 seconds
2024-07-09 22:18:19 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 22:18:30 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 22:18:31 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 22:18:34 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 22:18:35 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 22:18:42 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 22:18:48 | INFO | fairseq_cli.eval_lm | load time: 148.56 seconds
2024-07-09 22:18:55 | INFO | fairseq_cli.eval_lm | load time: 155.50 seconds
2024-07-09 22:18:55 | INFO | fairseq_cli.eval_lm | load time: 157.53 seconds
2024-07-09 22:18:59 | INFO | fairseq_cli.eval_lm | load time: 162.94 seconds
2024-07-09 22:19:01 | INFO | fairseq_cli.eval_lm | load time: 163.31 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 22:19:07 | INFO | fairseq_cli.eval_lm | load time: 168.95 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
W0709 22:19:22.844231 140569086777152 torch/multiprocessing/spawn.py:145] Terminating process 2380445 via signal SIGTERM
W0709 22:19:22.912409 140569086777152 torch/multiprocessing/spawn.py:145] Terminating process 2380449 via signal SIGTERM
W0709 22:19:22.912580 140569086777152 torch/multiprocessing/spawn.py:145] Terminating process 2380454 via signal SIGTERM
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 204, in top2gating
    return l_aux, combine_weights.to(orig_dtype), dispatch_mask, metadata
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 2.00 GiB. GPU 

srun: error: t007-002: task 5: Exited with exit code 1
W0709 22:19:29.392987 140332111062848 torch/multiprocessing/spawn.py:145] Terminating process 2380448 via signal SIGTERM
W0709 22:19:29.466701 140332111062848 torch/multiprocessing/spawn.py:145] Terminating process 2380452 via signal SIGTERM
W0709 22:19:29.466963 140332111062848 torch/multiprocessing/spawn.py:145] Terminating process 2380456 via signal SIGTERM
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 193, in top2gating
    combine1_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU 

Exception ignored in: <function PlasmaArray.__del__ at 0x7f9dabf550d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
Exception ignored in: <function PlasmaArray.__del__ at 0x7f8b32bc70d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Exception ignored in: <function PlasmaArray.__del__ at 0x7f7de55d40d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
Exception ignored in: <function PlasmaArray.__del__ at 0x7fefc77d40d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
srun: error: t007-002: task 7: Exited with exit code 1
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Exception ignored in: <function PlasmaArray.__del__ at 0x7fc0756b70d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
2024-07-09 22:19:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32544.927734375, gpu time: 32600.770553588867
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 34 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 22:19:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.820556640625, gpu time: 115.52742385864258
2024-07-09 22:19:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.7080078125, gpu time: 113.14917945861816
2024-07-09 22:19:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.826904296875, gpu time: 48.69890785217285
2024-07-09 22:19:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.507080078125, gpu time: 36.914581298828125
2024-07-09 22:19:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.48388671875, gpu time: 35.00673866271973
2024-07-09 22:19:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32546.887451171875, gpu time: 32655.365942001343
2024-07-09 22:19:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.1201171875, gpu time: 159.76440811157227
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 22:19:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.814453125, gpu time: 153.9455223083496
2024-07-09 22:19:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.10888671875, gpu time: 82.95908546447754
2024-07-09 22:19:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.896728515625, gpu time: 78.93204116821289
Exception ignored in: <function PlasmaArray.__del__ at 0x7fb67de370d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
2024-07-09 22:19:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.55126953125, gpu time: 82.6754035949707
2024-07-09 22:19:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 537.7822265625, gpu time: 521.5563011169434
2024-07-09 22:19:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32548.825927734375, gpu time: 32832.43084526062
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 34 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 22:19:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.728759765625, gpu time: 97.89285850524902
2024-07-09 22:19:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.69091796875, gpu time: 61.186594009399414
2024-07-09 22:19:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.271240234375, gpu time: 301.91040420532227
2024-07-09 22:19:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.80712890625, gpu time: 78.24564170837402
2024-07-09 22:19:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.405029296875, gpu time: 278.69406509399414
2024-07-09 22:19:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.701416015625, gpu time: 92.01700973510742
2024-07-09 22:19:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.73046875, gpu time: 115.89542388916016
2024-07-09 22:19:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 538.645263671875, gpu time: 578.2003326416016
2024-07-09 22:19:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.524658203125, gpu time: 693.9558963775635
2024-07-09 22:19:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.4521484375, gpu time: 222.8158130645752
2024-07-09 22:19:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.41064453125, gpu time: 113.38774108886719
2024-07-09 22:19:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.045654296875, gpu time: 227.6060447692871
2024-07-09 22:19:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.52490234375, gpu time: 157.7244052886963
2024-07-09 22:19:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.611328125, gpu time: 202.89323043823242
2024-07-09 22:19:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.418212890625, gpu time: 170.93401336669922
2024-07-09 22:19:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.44677734375, gpu time: 166.2309684753418
2024-07-09 22:19:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32550.76904296875, gpu time: 32944.28306388855
2024-07-09 22:19:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 539.3623046875, gpu time: 641.4370079040527
2024-07-09 22:19:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.695068359375, gpu time: 390.9000549316406
2024-07-09 22:19:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.0791015625, gpu time: 300.3608150482178
2024-07-09 22:19:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.144775390625, gpu time: 189.94042205810547
2024-07-09 22:19:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.076904296875, gpu time: 368.4253158569336
2024-07-09 22:19:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.1611328125, gpu time: 280.1499195098877
2024-07-09 22:19:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.3701171875, gpu time: 855.6699085235596
2024-07-09 22:19:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.0458984375, gpu time: 247.64013671875
2024-07-09 22:19:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.0810546875, gpu time: 214.4122714996338
2024-07-09 22:19:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.066162109375, gpu time: 327.8700981140137
2024-07-09 22:19:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 540.06591796875, gpu time: 693.333517074585
2024-07-09 22:19:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.145751953125, gpu time: 323.0492916107178
2024-07-09 22:19:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.701171875, gpu time: 344.621639251709
2024-07-09 22:19:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32552.084716796875, gpu time: 33055.63704872131
2024-07-09 22:19:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.964599609375, gpu time: 276.54687118530273
2024-07-09 22:19:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.849365234375, gpu time: 337.7433891296387
2024-07-09 22:19:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.82177734375, gpu time: 566.2118301391602
2024-07-09 22:19:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.780029296875, gpu time: 299.2358455657959
2024-07-09 22:19:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.75537109375, gpu time: 260.53597831726074
2024-07-09 22:19:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.202392578125, gpu time: 652.1051559448242
2024-07-09 22:19:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 540.797607421875, gpu time: 736.8577003479004
2024-07-09 22:19:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.337646484375, gpu time: 433.57192611694336
2024-07-09 22:19:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.54052734375, gpu time: 1129.6292629241943
2024-07-09 22:19:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.602783203125, gpu time: 355.9217929840088
2024-07-09 22:19:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.086669921875, gpu time: 426.3650321960449
2024-07-09 22:19:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.4765625, gpu time: 406.68310546875
2024-07-09 22:19:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.54736328125, gpu time: 353.6088352203369
2024-07-09 22:19:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.1962890625, gpu time: 443.9253635406494
2024-07-09 22:19:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.571533203125, gpu time: 310.23984718322754
2024-07-09 22:19:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32553.89208984375, gpu time: 33170.11759376526
2024-07-09 22:19:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 541.527587890625, gpu time: 809.8905391693115
2024-07-09 22:19:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.962158203125, gpu time: 490.8903560638428
2024-07-09 22:19:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.51806640625, gpu time: 686.8307800292969
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-07-09 22:19:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.2724609375, gpu time: 440.750638961792
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 22:19:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.7021484375, gpu time: 786.043628692627
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 22:19:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.150390625, gpu time: 503.4898796081543
2024-07-09 22:19:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.166748046875, gpu time: 415.2056713104248
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 22:19:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.52197265625, gpu time: 1255.3568515777588
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 22:19:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.243896484375, gpu time: 397.25989723205566
2024-07-09 22:19:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.608642578125, gpu time: 497.71818923950195
2024-07-09 22:19:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 542.2626953125, gpu time: 885.1360187530518
2024-07-09 22:19:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.770263671875, gpu time: 546.5070247650146
2024-07-09 22:19:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.864501953125, gpu time: 723.1731967926025
2024-07-09 22:19:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.896728515625, gpu time: 528.4478130340576
2024-07-09 22:19:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32556.266845703125, gpu time: 33319.94935798645
2024-07-09 22:19:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.77685546875, gpu time: 574.2940807342529
2024-07-09 22:19:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.889892578125, gpu time: 472.40522384643555
2024-07-09 22:19:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.385009765625, gpu time: 826.3406219482422
2024-07-09 22:19:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.005615234375, gpu time: 477.66490173339844
W0709 22:19:56.185555 140232485365568 torch/multiprocessing/spawn.py:145] Terminating process 639491 via signal SIGTERM
W0709 22:19:56.244910 140232485365568 torch/multiprocessing/spawn.py:145] Terminating process 639499 via signal SIGTERM
W0709 22:19:56.245184 140232485365568 torch/multiprocessing/spawn.py:145] Terminating process 639502 via signal SIGTERM
W0709 22:19:56.403962 140119948777280 torch/multiprocessing/spawn.py:145] Terminating process 639492 via signal SIGTERM
W0709 22:19:56.457364 140119948777280 torch/multiprocessing/spawn.py:145] Terminating process 639500 via signal SIGTERM
W0709 22:19:56.457576 140119948777280 torch/multiprocessing/spawn.py:145] Terminating process 639504 via signal SIGTERM
2024-07-09 22:19:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.41015625, gpu time: 895.2760047912598
2024-07-09 22:19:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 543.01806640625, gpu time: 958.837818145752
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 193, in top2gating
    combine1_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 560.00 MiB is free. Of the allocated memory 7.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2024-07-09 22:19:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.474853515625, gpu time: 598.4545745849609
2024-07-09 22:19:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.4599609375, gpu time: 1404.7018947601318
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 193, in top2gating
    combine1_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 656.00 MiB is free. Of the allocated memory 7.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2024-07-09 22:19:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.633544921875, gpu time: 654.2275676727295
2024-07-09 22:19:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.59814453125, gpu time: 585.5675239562988
2024-07-09 22:19:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.46826171875, gpu time: 643.6565189361572
W0709 22:19:57.888128 140487139546944 torch/multiprocessing/spawn.py:145] Terminating process 639498 via signal SIGTERM
W0709 22:19:57.940847 140487139546944 torch/multiprocessing/spawn.py:145] Terminating process 639503 via signal SIGTERM
W0709 22:19:57.941200 140487139546944 torch/multiprocessing/spawn.py:145] Terminating process 639506 via signal SIGTERM
2024-07-09 22:19:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.7646484375, gpu time: 545.8508682250977
2024-07-09 22:19:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.370849609375, gpu time: 874.6547298431396
W0709 22:19:58.528523 139967585347392 torch/multiprocessing/spawn.py:145] Terminating process 639501 via signal SIGTERM
W0709 22:19:58.579542 139967585347392 torch/multiprocessing/spawn.py:145] Terminating process 639505 via signal SIGTERM
2024-07-09 22:19:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.717529296875, gpu time: 536.0074920654297
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 193, in top2gating
    combine1_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU 

2024-07-09 22:19:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32557.492431640625, gpu time: 33431.72126579285
2024-07-09 22:19:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 543.751708984375, gpu time: 1019.8666534423828
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 204, in top2gating
    return l_aux, combine_weights.to(orig_dtype), dispatch_mask, metadata
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 2.00 GiB. GPU 

2024-07-09 22:19:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.214599609375, gpu time: 671.2504577636719
2024-07-09 22:19:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.94580078125, gpu time: 1007.826976776123
2024-07-09 22:19:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.2734375, gpu time: 717.4287242889404
2024-07-09 22:20:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.0859375, gpu time: 716.68776512146
2024-07-09 22:20:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.0810546875, gpu time: 1038.8853645324707
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
srun: error: t007-001: task 3: Exited with exit code 1
2024-07-09 22:20:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.45849609375, gpu time: 626.4176406860352
srun: error: t007-001: task 2: Exited with exit code 1
2024-07-09 22:20:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.470458984375, gpu time: 620.4689865112305
2024-07-09 22:20:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.523681640625, gpu time: 1710.1683101654053
2024-07-09 22:20:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 544.494140625, gpu time: 1078.7290859222412
2024-07-09 22:20:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.929931640625, gpu time: 750.3674659729004
2024-07-09 22:20:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.837890625, gpu time: 877.0963325500488
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 26 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
srun: error: t007-001: task 1: Exited with exit code 1
2024-07-09 22:20:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.89599609375, gpu time: 796.6644496917725
2024-07-09 22:20:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.123779296875, gpu time: 987.9367160797119
2024-07-09 22:20:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.7255859375, gpu time: 809.3169384002686
2024-07-09 22:20:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.09619140625, gpu time: 668.5587863922119
2024-07-09 22:20:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32558.21142578125, gpu time: 33795.08836174011
2024-07-09 22:20:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.25, gpu time: 704.1082363128662
srun: error: t007-001: task 0: Exited with exit code 1
2024-07-09 22:20:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 545.43896484375, gpu time: 1193.878921508789
2024-07-09 22:20:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.38330078125, gpu time: 1460.743724822998
2024-07-09 22:20:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.7421875, gpu time: 860.4388885498047
2024-07-09 22:20:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.529296875, gpu time: 919.8784465789795
2024-07-09 22:20:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.75537109375, gpu time: 1287.4575157165527
2024-07-09 22:20:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.416748046875, gpu time: 909.9923610687256
2024-07-09 22:20:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.736572265625, gpu time: 727.9337005615234
2024-07-09 22:20:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.24658203125, gpu time: 1890.7556171417236
2024-07-09 22:20:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.983642578125, gpu time: 767.3277969360352
2024-07-09 22:20:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.888427734375, gpu time: 1014.9485740661621
2024-07-09 22:20:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 546.1708984375, gpu time: 1267.3759231567383
2024-07-09 22:20:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.585205078125, gpu time: 914.4822807312012
2024-07-09 22:20:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.83544921875, gpu time: 1155.911226272583
2024-07-09 22:20:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.224609375, gpu time: 1019.8301887512207
2024-07-09 22:20:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.264892578125, gpu time: 988.3300094604492
2024-07-09 22:20:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32559.8544921875, gpu time: 34018.701150894165
2024-07-09 22:20:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.375732421875, gpu time: 802.0031890869141
2024-07-09 22:20:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.2138671875, gpu time: 1559.7501907348633
2024-07-09 22:20:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.6787109375, gpu time: 835.4094371795654
2024-07-09 22:20:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 546.8994140625, gpu time: 1316.017873764038
2024-07-09 22:20:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.5849609375, gpu time: 1568.5289115905762
2024-07-09 22:20:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.20849609375, gpu time: 1021.018669128418
2024-07-09 22:20:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.85009765625, gpu time: 1132.922903060913
2024-07-09 22:20:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.21337890625, gpu time: 2272.7817707061768
2024-07-09 22:20:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.885498046875, gpu time: 1070.7809429168701
2024-07-09 22:20:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.995361328125, gpu time: 859.2584247589111
2024-07-09 22:20:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.512451171875, gpu time: 1160.7995414733887
2024-07-09 22:20:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.304443359375, gpu time: 924.7765369415283
2024-07-09 22:20:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.158203125, gpu time: 1287.843313217163
2024-07-09 22:20:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 547.609619140625, gpu time: 1424.9891471862793
2024-07-09 22:20:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.8369140625, gpu time: 1068.916940689087
2024-07-09 22:20:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32560.557861328125, gpu time: 34167.16509056091
2024-07-09 22:20:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.5322265625, gpu time: 1177.8851718902588
2024-07-09 22:20:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.504638671875, gpu time: 1189.170461654663
2024-07-09 22:20:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.52783203125, gpu time: 1936.9152297973633
2024-07-09 22:20:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.640869140625, gpu time: 929.3735065460205
2024-07-09 22:20:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.95458984375, gpu time: 1012.296272277832
2024-07-09 22:20:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.755859375, gpu time: 1791.3719367980957
2024-07-09 22:20:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 548.343017578125, gpu time: 1509.6525630950928
2024-07-09 22:20:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.27587890625, gpu time: 2482.0406246185303
2024-07-09 22:20:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.467041015625, gpu time: 1173.5843715667725
2024-07-09 22:20:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.158935546875, gpu time: 1295.9687671661377
2024-07-09 22:20:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.24560546875, gpu time: 1340.243507385254
2024-07-09 22:20:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.258544921875, gpu time: 1251.0786628723145
2024-07-09 22:20:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.2880859375, gpu time: 987.821704864502
2024-07-09 22:20:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.3203125, gpu time: 1511.0361080169678
2024-07-09 22:20:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.587158203125, gpu time: 1083.4191989898682
2024-07-09 22:20:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 549.06640625, gpu time: 1626.0036811828613
2024-07-09 22:20:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32561.674072265625, gpu time: 34429.28079032898
2024-07-09 22:20:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.090087890625, gpu time: 1262.6746730804443
2024-07-09 22:20:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.53271484375, gpu time: 2108.3422317504883
2024-07-09 22:20:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.77880859375, gpu time: 1359.5907306671143
2024-07-09 22:20:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.889404296875, gpu time: 1383.8984298706055
2024-07-09 22:20:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.86181640625, gpu time: 2102.6225662231445
2024-07-09 22:20:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.917724609375, gpu time: 1062.6983947753906
2024-07-09 22:20:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.2275390625, gpu time: 1227.4101829528809
2024-07-09 22:20:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.453369140625, gpu time: 2802.3229389190674
2024-07-09 22:20:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 549.7255859375, gpu time: 1684.4330024719238
2024-07-09 22:20:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.713134765625, gpu time: 1329.686876296997
2024-07-09 22:20:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.374755859375, gpu time: 1471.4408836364746
2024-07-09 22:20:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.4013671875, gpu time: 1429.9200592041016
2024-07-09 22:20:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.51171875, gpu time: 1544.8708515167236
2024-07-09 22:20:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.79833984375, gpu time: 1734.934980392456
2024-07-09 22:20:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.55078125, gpu time: 1140.2514095306396
2024-07-09 22:20:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32562.488037109375, gpu time: 34616.44204521179
2024-07-09 22:20:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.9169921875, gpu time: 1277.929256439209
2024-07-09 22:20:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 550.605224609375, gpu time: 1773.563304901123
2024-07-09 22:20:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.60888671875, gpu time: 2275.205390930176
2024-07-09 22:20:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.187744140625, gpu time: 1407.4256496429443
2024-07-09 22:20:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.8955078125, gpu time: 2298.890869140625
2024-07-09 22:20:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.03857421875, gpu time: 1538.2711734771729
2024-07-09 22:20:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.148193359375, gpu time: 1663.4498176574707
2024-07-09 22:20:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.809326171875, gpu time: 3017.4344577789307
2024-07-09 22:20:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.185302734375, gpu time: 1224.2533931732178
2024-07-09 22:20:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.68408203125, gpu time: 1330.316816329956
2024-07-09 22:20:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.635009765625, gpu time: 1735.7511596679688
2024-07-09 22:20:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 551.427734375, gpu time: 1865.9979343414307
2024-07-09 22:20:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.814697265625, gpu time: 1530.9447803497314
2024-07-09 22:20:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.609375, gpu time: 1955.6546535491943
2024-07-09 22:20:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.677734375, gpu time: 1632.0182857513428
2024-07-09 22:20:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.8896484375, gpu time: 1748.4610805511475
2024-07-09 22:20:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32563.439453125, gpu time: 34787.780572891235
2024-07-09 22:20:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.825927734375, gpu time: 1314.6492938995361
2024-07-09 22:20:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.427490234375, gpu time: 2443.949996948242
2024-07-09 22:20:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.37255859375, gpu time: 1423.5080852508545
2024-07-09 22:20:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 552.165771484375, gpu time: 1960.3746433258057
2024-07-09 22:20:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.003662109375, gpu time: 2470.7844429016113
2024-07-09 22:20:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.44580078125, gpu time: 1608.0512409210205
2024-07-09 22:20:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.329345703125, gpu time: 1721.3105144500732
2024-07-09 22:20:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.733642578125, gpu time: 3232.5736446380615
2024-07-09 22:20:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.581298828125, gpu time: 1878.9869403839111
2024-07-09 22:20:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.44775390625, gpu time: 1370.6136589050293
2024-07-09 22:20:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.66552734375, gpu time: 1991.8380813598633
2024-07-09 22:20:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.99072265625, gpu time: 1497.8555011749268
2024-07-09 22:20:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 552.95703125, gpu time: 2075.157928466797
2024-07-09 22:20:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.580078125, gpu time: 2206.963010787964
2024-07-09 22:20:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.308349609375, gpu time: 1665.8047256469727
2024-07-09 22:20:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32565.33837890625, gpu time: 34984.847929000854
2024-07-09 22:20:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.953857421875, gpu time: 1859.7090282440186
2024-07-09 22:20:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.265869140625, gpu time: 1936.9844226837158
2024-07-09 22:20:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.451171875, gpu time: 2679.7633056640625
2024-07-09 22:20:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.11474609375, gpu time: 1446.0695571899414
2024-07-09 22:20:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.6494140625, gpu time: 1555.012825012207
2024-07-09 22:20:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.992431640625, gpu time: 2667.36092376709
2024-07-09 22:20:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 553.672119140625, gpu time: 2183.3210525512695
2024-07-09 22:20:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.6357421875, gpu time: 3422.921796798706
2024-07-09 22:20:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.01806640625, gpu time: 1744.035026550293
2024-07-09 22:20:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.631103515625, gpu time: 1967.90159034729
2024-07-09 22:20:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.3193359375, gpu time: 2155.5575637817383
2024-07-09 22:20:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.88232421875, gpu time: 2019.3952083587646
2024-07-09 22:20:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.792236328125, gpu time: 1516.4169731140137
2024-07-09 22:20:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.117919921875, gpu time: 2380.8735485076904
2024-07-09 22:20:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.83056640625, gpu time: 1643.7573776245117
2024-07-09 22:20:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32566.78857421875, gpu time: 35091.64050102234
2024-07-09 22:20:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 554.465576171875, gpu time: 2247.0935821533203
2024-07-09 22:20:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.645751953125, gpu time: 1825.6794128417969
2024-07-09 22:20:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.1572265625, gpu time: 2841.061508178711
2024-07-09 22:20:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.330810546875, gpu time: 2061.9029483795166
2024-07-09 22:20:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.651123046875, gpu time: 2791.7291831970215
2024-07-09 22:20:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.636474609375, gpu time: 2074.238613128662
2024-07-09 22:20:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.44140625, gpu time: 1579.560064315796
2024-07-09 22:20:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.693359375, gpu time: 3547.5831813812256
2024-07-09 22:20:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.460693359375, gpu time: 1722.1871967315674
2024-07-09 22:20:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 555.268798828125, gpu time: 2330.37908744812
2024-07-09 22:20:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.44140625, gpu time: 2332.9519538879395
2024-07-09 22:20:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.270263671875, gpu time: 1915.9127655029297
2024-07-09 22:20:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.726318359375, gpu time: 2541.729684829712
2024-07-09 22:20:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.078857421875, gpu time: 2127.943801879883
2024-07-09 22:20:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.319091796875, gpu time: 2159.1516437530518
2024-07-09 22:20:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32568.93701171875, gpu time: 35189.48330116272
2024-07-09 22:20:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.211181640625, gpu time: 1674.2564640045166
2024-07-09 22:20:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.005859375, gpu time: 2934.821750640869
2024-07-09 22:20:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.150146484375, gpu time: 1802.1099815368652
2024-07-09 22:20:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.870849609375, gpu time: 2878.2236518859863
2024-07-09 22:20:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 555.994140625, gpu time: 2403.4541873931885
2024-07-09 22:20:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.981689453125, gpu time: 1987.9150657653809
2024-07-09 22:20:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.99658203125, gpu time: 3638.645818710327
2024-07-09 22:20:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.7109375, gpu time: 2203.157787322998
2024-07-09 22:20:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.927001953125, gpu time: 2415.3141021728516
2024-07-09 22:20:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.947265625, gpu time: 2242.411392211914
2024-07-09 22:20:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.5302734375, gpu time: 2623.719831466675
2024-07-09 22:20:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.83251953125, gpu time: 1731.6158695220947
2024-07-09 22:20:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.78125, gpu time: 1887.0913352966309
2024-07-09 22:20:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32570.22998046875, gpu time: 35283.39778327942
2024-07-09 22:20:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 556.71435546875, gpu time: 2492.1601848602295
2024-07-09 22:20:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.717041015625, gpu time: 3073.5703506469727
2024-07-09 22:20:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.606201171875, gpu time: 2122.6014251708984
2024-07-09 22:20:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.34326171875, gpu time: 2256.5672721862793
2024-07-09 22:20:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.055908203125, gpu time: 2997.83895111084
2024-07-09 22:20:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.647216796875, gpu time: 2328.53338432312
2024-07-09 22:20:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.918212890625, gpu time: 3753.5567951202393
2024-07-09 22:20:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.4501953125, gpu time: 1824.4172248840332
2024-07-09 22:20:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.505126953125, gpu time: 1942.8472232818604
2024-07-09 22:20:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.650634765625, gpu time: 2559.153106689453
2024-07-09 22:20:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 557.51025390625, gpu time: 2572.5316162109375
2024-07-09 22:20:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.20361328125, gpu time: 2710.1215076446533
2024-07-09 22:20:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.225341796875, gpu time: 2191.9651641845703
2024-07-09 22:20:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.00146484375, gpu time: 2325.7794914245605
2024-07-09 22:20:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32571.2880859375, gpu time: 35363.80121421814
2024-07-09 22:20:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.4658203125, gpu time: 2428.033950805664
2024-07-09 22:20:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.972412109375, gpu time: 3208.884548187256
2024-07-09 22:20:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.1533203125, gpu time: 1887.7679996490479
2024-07-09 22:20:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.197998046875, gpu time: 2013.3373641967773
2024-07-09 22:20:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.1826171875, gpu time: 3149.066608428955
2024-07-09 22:20:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 558.221923828125, gpu time: 2726.7829513549805
2024-07-09 22:20:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.093017578125, gpu time: 3835.4287090301514
2024-07-09 22:20:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.940673828125, gpu time: 2243.0500106811523
2024-07-09 22:20:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.696044921875, gpu time: 2402.7411575317383
2024-07-09 22:20:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.046630859375, gpu time: 2681.5954551696777
2024-07-09 22:20:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.239013671875, gpu time: 2488.852565765381
2024-07-09 22:20:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.418212890625, gpu time: 2802.9686336517334
2024-07-09 22:20:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.856201171875, gpu time: 1946.7165336608887
2024-07-09 22:20:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.830322265625, gpu time: 2075.005100250244
2024-07-09 22:20:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32572.351318359375, gpu time: 35494.396852493286
2024-07-09 22:20:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 558.93408203125, gpu time: 2781.4801197052
2024-07-09 22:20:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.24853515625, gpu time: 3327.56929397583
2024-07-09 22:20:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.56494140625, gpu time: 2337.4264183044434
2024-07-09 22:20:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.298828125, gpu time: 2461.684730529785
2024-07-09 22:20:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.163818359375, gpu time: 3293.5840225219727
2024-07-09 22:20:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.864013671875, gpu time: 2578.0827255249023
2024-07-09 22:20:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.892578125, gpu time: 3934.0409564971924
2024-07-09 22:20:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.476806640625, gpu time: 2008.0514698028564
2024-07-09 22:20:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.49560546875, gpu time: 2136.1539554595947
2024-07-09 22:20:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.4716796875, gpu time: 2785.295711517334
2024-07-09 22:20:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 559.762939453125, gpu time: 2848.5420989990234
2024-07-09 22:20:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.39794921875, gpu time: 2887.21063041687
2024-07-09 22:20:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.231201171875, gpu time: 2425.487781524658
2024-07-09 22:20:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.050537109375, gpu time: 2522.2715034484863
2024-07-09 22:20:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32573.534912109375, gpu time: 35615.79905128479
2024-07-09 22:20:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.5322265625, gpu time: 2662.138961791992
2024-07-09 22:20:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.615478515625, gpu time: 3432.6423530578613
2024-07-09 22:20:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.111328125, gpu time: 2060.0486373901367
2024-07-09 22:20:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.18701171875, gpu time: 2222.975793838501
2024-07-09 22:20:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.0390625, gpu time: 3457.4356956481934
2024-07-09 22:20:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 560.492919921875, gpu time: 2900.6789474487305
2024-07-09 22:20:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.6396484375, gpu time: 4017.791757583618
2024-07-09 22:20:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.912353515625, gpu time: 2482.5345554351807
2024-07-09 22:20:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.657958984375, gpu time: 2586.9322052001953
2024-07-09 22:20:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.498291015625, gpu time: 2879.897720336914
2024-07-09 22:20:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.228515625, gpu time: 2726.2924633026123
2024-07-09 22:20:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.35693359375, gpu time: 2959.561098098755
2024-07-09 22:20:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.751220703125, gpu time: 2136.2528686523438
2024-07-09 22:20:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.86181640625, gpu time: 2294.70050239563
2024-07-09 22:20:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32575.3408203125, gpu time: 35753.80669975281
2024-07-09 22:20:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 561.178466796875, gpu time: 2986.725425720215
2024-07-09 22:20:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.523193359375, gpu time: 3641.4239921569824
2024-07-09 22:20:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.627197265625, gpu time: 2602.9148273468018
2024-07-09 22:20:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.294921875, gpu time: 2639.0554523468018
2024-07-09 22:20:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.90380859375, gpu time: 3600.490074157715
2024-07-09 22:20:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.85498046875, gpu time: 2820.6224689483643
2024-07-09 22:20:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.942138671875, gpu time: 4122.954900741577
2024-07-09 22:20:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.458740234375, gpu time: 2228.0011138916016
2024-07-09 22:20:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.63134765625, gpu time: 2355.1970386505127
2024-07-09 22:20:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.81201171875, gpu time: 2997.2736740112305
2024-07-09 22:20:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 561.886474609375, gpu time: 3047.3424434661865
2024-07-09 22:20:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.08154296875, gpu time: 3047.905824661255
2024-07-09 22:20:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.26171875, gpu time: 2657.5504035949707
2024-07-09 22:20:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.05859375, gpu time: 2726.555700302124
2024-07-09 22:20:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32576.478515625, gpu time: 35874.21306037903
2024-07-09 22:20:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.496826171875, gpu time: 2908.221597671509
2024-07-09 22:20:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.255615234375, gpu time: 3730.4685592651367
2024-07-09 22:20:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.206298828125, gpu time: 2281.0978031158447
2024-07-09 22:20:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.258544921875, gpu time: 2423.6476669311523
2024-07-09 22:20:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.533203125, gpu time: 3688.236396789551
2024-07-09 22:20:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 562.63134765625, gpu time: 3141.6548557281494
2024-07-09 22:20:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.977783203125, gpu time: 4263.651838302612
2024-07-09 22:20:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.935302734375, gpu time: 2752.7866497039795
2024-07-09 22:20:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.69677734375, gpu time: 2787.135597229004
2024-07-09 22:20:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.930419921875, gpu time: 3114.2651557922363
2024-07-09 22:20:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.202880859375, gpu time: 2971.4562225341797
2024-07-09 22:20:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.774169921875, gpu time: 3151.4547290802
2024-07-09 22:20:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.9189453125, gpu time: 2377.4596557617188
2024-07-09 22:21:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.887939453125, gpu time: 2478.239721298218
2024-07-09 22:21:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32577.99267578125, gpu time: 35977.228521347046
2024-07-09 22:21:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 563.427001953125, gpu time: 3214.6277256011963
2024-07-09 22:21:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.9189453125, gpu time: 3811.2707176208496
2024-07-09 22:21:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.556884765625, gpu time: 2836.473611831665
2024-07-09 22:21:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.2412109375, gpu time: 3793.1902618408203
2024-07-09 22:21:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.32177734375, gpu time: 2847.844457626343
2024-07-09 22:21:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.826904296875, gpu time: 3029.259801864624
2024-07-09 22:21:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.257080078125, gpu time: 4349.785524368286
2024-07-09 22:21:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.53759765625, gpu time: 2430.750268936157
2024-07-09 22:21:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.908447265625, gpu time: 3192.5308380126953
2024-07-09 22:21:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.52099609375, gpu time: 2546.6975479125977
2024-07-09 22:21:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 564.151611328125, gpu time: 3272.8973846435547
2024-07-09 22:21:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.4365234375, gpu time: 3331.025468826294
2024-07-09 22:21:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.218994140625, gpu time: 2936.8143520355225
2024-07-09 22:21:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32579.668701171875, gpu time: 36088.50799751282
2024-07-09 22:21:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.953857421875, gpu time: 2950.826005935669
2024-07-09 22:21:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.435302734375, gpu time: 3083.4936180114746
2024-07-09 22:21:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.3505859375, gpu time: 3937.331008911133
2024-07-09 22:21:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.161376953125, gpu time: 2491.2407302856445
2024-07-09 22:21:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.846435546875, gpu time: 3890.0262031555176
2024-07-09 22:21:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.13671875, gpu time: 2611.7526531219482
2024-07-09 22:21:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 564.96923828125, gpu time: 3325.385601043701
2024-07-09 22:21:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.78857421875, gpu time: 4497.171277999878
2024-07-09 22:21:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.88427734375, gpu time: 3004.2576217651367
2024-07-09 22:21:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.933349609375, gpu time: 3285.95845413208
2024-07-09 22:21:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.66845703125, gpu time: 3012.1777477264404
2024-07-09 22:21:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.127197265625, gpu time: 3146.594165802002
2024-07-09 22:21:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.532958984375, gpu time: 3457.566396713257
2024-07-09 22:21:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.773681640625, gpu time: 2543.970064163208
2024-07-09 22:21:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32581.114990234375, gpu time: 36194.92635536194
2024-07-09 22:21:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.744140625, gpu time: 2680.9568881988525
2024-07-09 22:21:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 565.61669921875, gpu time: 3407.891288757324
2024-07-09 22:21:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.737060546875, gpu time: 4070.019474029541
2024-07-09 22:21:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.653564453125, gpu time: 3063.277687072754
2024-07-09 22:21:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.03076171875, gpu time: 3986.8941497802734
2024-07-09 22:21:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.292724609375, gpu time: 3078.953981399536
2024-07-09 22:21:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.78759765625, gpu time: 3205.73166847229
2024-07-09 22:21:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.61181640625, gpu time: 4612.634920120239
2024-07-09 22:21:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.4072265625, gpu time: 2635.7325649261475
2024-07-09 22:21:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.4638671875, gpu time: 3381.829433441162
2024-07-09 22:21:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.378173828125, gpu time: 2732.9627017974854
2024-07-09 22:21:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 566.341064453125, gpu time: 3480.3792057037354
2024-07-09 22:21:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.790771484375, gpu time: 3572.8930797576904
2024-07-09 22:21:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.28466796875, gpu time: 3134.683849334717
2024-07-09 22:21:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32582.658203125, gpu time: 36270.65524101257
2024-07-09 22:21:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.93115234375, gpu time: 3182.454412460327
2024-07-09 22:21:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.405029296875, gpu time: 3288.9679164886475
2024-07-09 22:21:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.04541015625, gpu time: 2708.452325820923
2024-07-09 22:21:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.52880859375, gpu time: 4378.2223777771
2024-07-09 22:21:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.997314453125, gpu time: 2811.448392868042
2024-07-09 22:21:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.7421875, gpu time: 4097.204029083252
2024-07-09 22:21:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 567.07080078125, gpu time: 3569.9389839172363
2024-07-09 22:21:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.895263671875, gpu time: 3193.219114303589
2024-07-09 22:21:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.882080078125, gpu time: 4772.673501968384
2024-07-09 22:21:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.5400390625, gpu time: 3236.433349609375
2024-07-09 22:21:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.189453125, gpu time: 3370.8296070098877
2024-07-09 22:21:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.908447265625, gpu time: 3482.108585357666
2024-07-09 22:21:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.66552734375, gpu time: 2782.972089767456
2024-07-09 22:21:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.45458984375, gpu time: 3662.8653469085693
2024-07-09 22:21:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.769775390625, gpu time: 2861.884927749634
2024-07-09 22:21:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 568.7451171875, gpu time: 3695.0370445251465
2024-07-09 22:21:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32584.24072265625, gpu time: 36484.05163002014
2024-07-09 22:21:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.568603515625, gpu time: 3261.616630554199
2024-07-09 22:21:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.262451171875, gpu time: 3312.347677230835
2024-07-09 22:21:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.4228515625, gpu time: 4571.901638031006
2024-07-09 22:21:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.8876953125, gpu time: 3424.7360668182373
2024-07-09 22:21:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.3701171875, gpu time: 4173.7399559021
2024-07-09 22:21:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.33984375, gpu time: 2868.339548110962
2024-07-09 22:21:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.380126953125, gpu time: 2999.0686016082764
2024-07-09 22:21:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.0263671875, gpu time: 4909.760374069214
2024-07-09 22:21:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 569.575927734375, gpu time: 3763.656639099121
2024-07-09 22:21:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.25390625, gpu time: 3337.1083946228027
2024-07-09 22:21:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.01513671875, gpu time: 3682.982265472412
2024-07-09 22:21:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.875, gpu time: 3397.6120929718018
2024-07-09 22:21:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.106201171875, gpu time: 3749.354085922241
2024-07-09 22:21:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.6083984375, gpu time: 3481.5604515075684
2024-07-09 22:21:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.029541015625, gpu time: 2965.265256881714
2024-07-09 22:21:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32585.92626953125, gpu time: 36608.67289161682
2024-07-09 22:21:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.99609375, gpu time: 3061.9427528381348
2024-07-09 22:21:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.359130859375, gpu time: 4642.11051940918
2024-07-09 22:21:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 570.37890625, gpu time: 3829.9967136383057
2024-07-09 22:21:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.121337890625, gpu time: 4318.631801605225
2024-07-09 22:21:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.873779296875, gpu time: 3426.9886589050293
2024-07-09 22:21:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.48974609375, gpu time: 3455.6452770233154
2024-07-09 22:21:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.736328125, gpu time: 5054.226781845093
2024-07-09 22:21:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.225341796875, gpu time: 3562.76118850708
2024-07-09 22:21:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.864501953125, gpu time: 3770.381404876709
2024-07-09 22:21:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.645751953125, gpu time: 3024.6693267822266
2024-07-09 22:21:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.707275390625, gpu time: 3122.827621459961
2024-07-09 22:21:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.770751953125, gpu time: 3861.579824447632
2024-07-09 22:21:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 571.095458984375, gpu time: 3926.5934658050537
2024-07-09 22:21:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32586.73193359375, gpu time: 36699.476354599
2024-07-09 22:21:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.488037109375, gpu time: 3490.4516105651855
2024-07-09 22:21:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.12158203125, gpu time: 3520.146951675415
2024-07-09 22:21:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.056396484375, gpu time: 4782.09196472168
2024-07-09 22:21:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.90380859375, gpu time: 3716.278964996338
2024-07-09 22:21:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.27734375, gpu time: 4469.05997467041
2024-07-09 22:21:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.38037109375, gpu time: 3100.5441360473633
2024-07-09 22:21:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.406982421875, gpu time: 3211.40500831604
2024-07-09 22:21:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.00634765625, gpu time: 5212.268732070923
2024-07-09 22:21:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 571.8193359375, gpu time: 3990.647300720215
2024-07-09 22:21:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.034912109375, gpu time: 3874.9824829101562
2024-07-09 22:21:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.109130859375, gpu time: 3566.0832176208496
2024-07-09 22:21:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.74951171875, gpu time: 3574.630054473877
2024-07-09 22:21:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.44482421875, gpu time: 4010.465436935425
2024-07-09 22:21:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.528564453125, gpu time: 3808.748836517334
2024-07-09 22:21:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32588.173828125, gpu time: 36798.12014961243
2024-07-09 22:21:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.075927734375, gpu time: 3181.173990249634
2024-07-09 22:21:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.029541015625, gpu time: 3275.2566051483154
2024-07-09 22:21:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.771484375, gpu time: 4902.0900230407715
2024-07-09 22:21:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 572.53125, gpu time: 4070.2211589813232
2024-07-09 22:21:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.979248046875, gpu time: 4601.622539520264
2024-07-09 22:21:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.808349609375, gpu time: 3664.7919750213623
2024-07-09 22:21:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.36865234375, gpu time: 3627.5112380981445
2024-07-09 22:21:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.984619140625, gpu time: 5317.994939804077
2024-07-09 22:21:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.159912109375, gpu time: 3888.947973251343
2024-07-09 22:21:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.9375, gpu time: 3993.4850273132324
2024-07-09 22:21:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.692138671875, gpu time: 3227.3119621276855
2024-07-09 22:21:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.068603515625, gpu time: 4090.1592960357666
2024-07-09 22:21:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.79248046875, gpu time: 3337.479558944702
2024-07-09 22:21:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 573.32861328125, gpu time: 4123.339464187622
2024-07-09 22:21:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32589.83349609375, gpu time: 36888.978815078735
2024-07-09 22:21:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.447265625, gpu time: 3729.804374694824
2024-07-09 22:21:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.176513671875, gpu time: 5005.6743087768555
2024-07-09 22:21:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.00634765625, gpu time: 3691.8905181884766
2024-07-09 22:21:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.8291015625, gpu time: 3942.4117183685303
2024-07-09 22:21:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.822021484375, gpu time: 4757.120174407959
2024-07-09 22:21:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.44970703125, gpu time: 3312.2861461639404
2024-07-09 22:21:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.1748046875, gpu time: 5406.0003299713135
2024-07-09 22:21:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.496826171875, gpu time: 3397.522352218628
2024-07-09 22:21:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 574.153076171875, gpu time: 4168.035200119019
2024-07-09 22:21:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.551513671875, gpu time: 4145.850494384766
2024-07-09 22:21:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.1376953125, gpu time: 3798.4913387298584
2024-07-09 22:21:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.10400390625, gpu time: 4167.296831130981
2024-07-09 22:21:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.7138671875, gpu time: 3769.0328540802
2024-07-09 22:21:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.46044921875, gpu time: 4010.224922180176
2024-07-09 22:21:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32590.88330078125, gpu time: 37002.54855155945
2024-07-09 22:21:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.14794921875, gpu time: 3380.4047927856445
2024-07-09 22:21:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.664306640625, gpu time: 5122.421337127686
2024-07-09 22:21:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.12939453125, gpu time: 3446.702892303467
2024-07-09 22:21:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.53857421875, gpu time: 4845.325401306152
2024-07-09 22:21:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 574.87890625, gpu time: 4253.440101623535
2024-07-09 22:21:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.757080078125, gpu time: 3851.8434047698975
2024-07-09 22:21:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.8798828125, gpu time: 5554.228677749634
2024-07-09 22:21:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.405517578125, gpu time: 3859.2212886810303
2024-07-09 22:21:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.97998046875, gpu time: 4225.965316772461
2024-07-09 22:21:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.21826171875, gpu time: 4066.5205116271973
2024-07-09 22:21:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.76904296875, gpu time: 3447.7219944000244
2024-07-09 22:21:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.436279296875, gpu time: 4252.613092422485
2024-07-09 22:21:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.791259765625, gpu time: 3530.752914428711
2024-07-09 22:21:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32591.604736328125, gpu time: 37098.207387924194
2024-07-09 22:21:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 575.6015625, gpu time: 4309.437610626221
2024-07-09 22:21:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.391845703125, gpu time: 3913.3855590820312
2024-07-09 22:21:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.57373046875, gpu time: 5221.919860839844
2024-07-09 22:21:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.199462890625, gpu time: 3933.0930614471436
2024-07-09 22:21:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.10009765625, gpu time: 4933.077350616455
2024-07-09 22:21:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.84228515625, gpu time: 4140.1014041900635
2024-07-09 22:21:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.688232421875, gpu time: 5668.597143173218
2024-07-09 22:21:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.544921875, gpu time: 3505.64430809021
2024-07-09 22:21:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.4560546875, gpu time: 3584.9781017303467
2024-07-09 22:21:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.906005859375, gpu time: 4332.053611755371
2024-07-09 22:21:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 576.31201171875, gpu time: 4371.164571762085
2024-07-09 22:21:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.061767578125, gpu time: 4340.916723251343
2024-07-09 22:21:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.220947265625, gpu time: 3971.8665924072266
2024-07-09 22:21:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.81787109375, gpu time: 3989.2582511901855
2024-07-09 22:21:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32592.30322265625, gpu time: 37205.6704082489
2024-07-09 22:21:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.572265625, gpu time: 4216.76710319519
2024-07-09 22:21:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.77392578125, gpu time: 5356.547073364258
2024-07-09 22:21:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.184326171875, gpu time: 3609.739959716797
2024-07-09 22:21:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.084228515625, gpu time: 3630.39847946167
2024-07-09 22:21:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.9501953125, gpu time: 5058.725513458252
2024-07-09 22:21:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 577.112548828125, gpu time: 4441.106582641602
2024-07-09 22:21:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.389404296875, gpu time: 5806.605955123901
2024-07-09 22:21:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.838134765625, gpu time: 4008.6347999572754
2024-07-09 22:21:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.3525390625, gpu time: 4433.5260581970215
2024-07-09 22:21:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.575927734375, gpu time: 4050.639928817749
2024-07-09 22:21:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.197021484375, gpu time: 4259.880916595459
2024-07-09 22:21:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.675537109375, gpu time: 4473.530652999878
2024-07-09 22:21:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.81103515625, gpu time: 3692.8954277038574
2024-07-09 22:21:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32593.494140625, gpu time: 37294.13628196716
2024-07-09 22:21:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.8154296875, gpu time: 3691.609758377075
2024-07-09 22:21:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 577.849609375, gpu time: 4515.906200408936
2024-07-09 22:21:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.458740234375, gpu time: 5485.863395690918
2024-07-09 22:21:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.6005859375, gpu time: 4073.349603652954
2024-07-09 22:21:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.4794921875, gpu time: 5154.946437835693
2024-07-09 22:21:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.20849609375, gpu time: 4116.649936676025
2024-07-09 22:21:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.843505859375, gpu time: 4314.300186157227
2024-07-09 22:21:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.242431640625, gpu time: 5935.9430866241455
2024-07-09 22:21:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.4423828125, gpu time: 3763.6240005493164
2024-07-09 22:21:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.947998046875, gpu time: 4507.768077850342
2024-07-09 22:21:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.43994140625, gpu time: 3775.0481090545654
2024-07-09 22:21:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 578.6220703125, gpu time: 4569.940990447998
2024-07-09 22:21:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.178466796875, gpu time: 4572.713663101196
2024-07-09 22:21:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.216796875, gpu time: 4151.622186660767
2024-07-09 22:21:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32594.790283203125, gpu time: 37440.51022529602
2024-07-09 22:21:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.823974609375, gpu time: 4226.213441848755
2024-07-09 22:21:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.739501953125, gpu time: 4368.666658401489
2024-07-09 22:21:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.988037109375, gpu time: 5665.996116638184
2024-07-09 22:21:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.06494140625, gpu time: 3850.6119537353516
2024-07-09 22:21:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.177978515625, gpu time: 5252.308326721191
2024-07-09 22:21:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.11083984375, gpu time: 3825.2611331939697
2024-07-09 22:21:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 579.329345703125, gpu time: 4668.379838943481
2024-07-09 22:21:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.49169921875, gpu time: 6060.178602218628
2024-07-09 22:21:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.868896484375, gpu time: 4226.294122695923
2024-07-09 22:21:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.632080078125, gpu time: 4599.363235473633
2024-07-09 22:21:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.616943359375, gpu time: 4276.12566947937
2024-07-09 22:21:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.3662109375, gpu time: 4438.135232925415
2024-07-09 22:21:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.999267578125, gpu time: 4663.324502944946
2024-07-09 22:21:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.78564453125, gpu time: 3909.1123542785645
2024-07-09 22:21:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32595.507080078125, gpu time: 37522.22953605652
2024-07-09 22:21:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.752197265625, gpu time: 3876.764081954956
2024-07-09 22:21:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 580.051025390625, gpu time: 4722.623271942139
2024-07-09 22:21:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.698486328125, gpu time: 5789.006195068359
2024-07-09 22:21:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.627197265625, gpu time: 4291.873250961304
2024-07-09 22:21:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.873291015625, gpu time: 5372.193607330322
2024-07-09 22:21:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.30859375, gpu time: 4357.134738922119
2024-07-09 22:21:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.86669921875, gpu time: 6156.772970199585
2024-07-09 22:21:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.0048828125, gpu time: 4504.81964302063
2024-07-09 22:21:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.396728515625, gpu time: 3967.043951034546
2024-07-09 22:21:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.23974609375, gpu time: 4695.187206268311
2024-07-09 22:21:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.37548828125, gpu time: 3933.7892780303955
2024-07-09 22:21:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.8857421875, gpu time: 4759.516477584839
2024-07-09 22:21:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 580.7685546875, gpu time: 4780.341114044189
2024-07-09 22:21:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.368408203125, gpu time: 4350.787731170654
2024-07-09 22:21:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32596.411865234375, gpu time: 37638.21961402893
2024-07-09 22:21:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.979248046875, gpu time: 4415.0183391571045
2024-07-09 22:21:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.720458984375, gpu time: 5911.415481567383
2024-07-09 22:21:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.62548828125, gpu time: 4593.527284622192
2024-07-09 22:21:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.6796875, gpu time: 5470.644943237305
2024-07-09 22:21:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.006591796875, gpu time: 4033.95636177063
2024-07-09 22:21:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.982421875, gpu time: 3983.956066131592
2024-07-09 22:21:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.87255859375, gpu time: 6255.808465957642
2024-07-09 22:21:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 581.5634765625, gpu time: 4852.09161567688
2024-07-09 22:21:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.864013671875, gpu time: 4782.303966522217
2024-07-09 22:21:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.982666015625, gpu time: 4404.128286361694
2024-07-09 22:21:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.6318359375, gpu time: 4486.267553329468
2024-07-09 22:21:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.56298828125, gpu time: 4842.633390426636
2024-07-09 22:21:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.242431640625, gpu time: 4692.045503616333
2024-07-09 22:21:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32597.13134765625, gpu time: 37779.58764457703
2024-07-09 22:21:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.626220703125, gpu time: 4098.992292404175
2024-07-09 22:21:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.6220703125, gpu time: 4044.781909942627
2024-07-09 22:21:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.17333984375, gpu time: 6035.175811767578
2024-07-09 22:21:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 582.290283203125, gpu time: 4905.812810897827
2024-07-09 22:21:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.804443359375, gpu time: 5567.330997467041
2024-07-09 22:21:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.60693359375, gpu time: 4471.29797744751
2024-07-09 22:21:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.259765625, gpu time: 4545.451313018799
2024-07-09 22:21:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.6201171875, gpu time: 6400.732027053833
2024-07-09 22:21:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.997802734375, gpu time: 4759.483997344971
2024-07-09 22:21:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.697998046875, gpu time: 4882.407787322998
2024-07-09 22:21:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.488525390625, gpu time: 4160.417175292969
2024-07-09 22:21:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.25537109375, gpu time: 4109.336402893066
2024-07-09 22:21:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.56103515625, gpu time: 4972.911008834839
2024-07-09 22:21:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 583.098876953125, gpu time: 4960.735126495361
2024-07-09 22:21:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32598.3095703125, gpu time: 37878.58058357239
2024-07-09 22:21:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.234130859375, gpu time: 4544.982238769531
2024-07-09 22:22:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.8896484375, gpu time: 4603.131551742554
2024-07-09 22:22:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.802978515625, gpu time: 6160.213268280029
2024-07-09 22:22:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.819580078125, gpu time: 4811.126310348511
2024-07-09 22:22:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.61328125, gpu time: 5664.938816070557
2024-07-09 22:22:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.11328125, gpu time: 4221.408464431763
2024-07-09 22:22:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.93994140625, gpu time: 4189.453632354736
2024-07-09 22:22:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.98046875, gpu time: 6478.833574295044
2024-07-09 22:22:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 583.87841796875, gpu time: 5076.612567901611
2024-07-09 22:22:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.403564453125, gpu time: 5012.531169891357
2024-07-09 22:22:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.994384765625, gpu time: 4598.249193191528
2024-07-09 22:22:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.635009765625, gpu time: 4685.462549209595
2024-07-09 22:22:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.514892578125, gpu time: 5092.701097488403
2024-07-09 22:22:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.435302734375, gpu time: 4860.82301902771
2024-07-09 22:22:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32599.65869140625, gpu time: 37988.30969810486
2024-07-09 22:22:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.90869140625, gpu time: 4306.712425231934
2024-07-09 22:22:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.556884765625, gpu time: 4246.4929122924805
2024-07-09 22:22:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.26806640625, gpu time: 6267.343181610107
2024-07-09 22:22:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 584.6142578125, gpu time: 5138.329614639282
2024-07-09 22:22:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.82080078125, gpu time: 5759.300712585449
2024-07-09 22:22:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.626220703125, gpu time: 4658.78639793396
2024-07-09 22:22:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.24658203125, gpu time: 4737.852384567261
2024-07-09 22:22:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.60888671875, gpu time: 6627.973150253296
2024-07-09 22:22:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.156494140625, gpu time: 4927.628553390503
2024-07-09 22:22:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.865966796875, gpu time: 5110.605716705322
2024-07-09 22:22:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.5302734375, gpu time: 4377.0832443237305
2024-07-09 22:22:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.211669921875, gpu time: 4318.647899627686
2024-07-09 22:22:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.322021484375, gpu time: 5206.145906448364
2024-07-09 22:22:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 585.3232421875, gpu time: 5196.671297073364
2024-07-09 22:22:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32601.010986328125, gpu time: 38066.0296497345
2024-07-09 22:22:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.2421875, gpu time: 4739.383953094482
2024-07-09 22:22:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.9033203125, gpu time: 4799.061592102051
2024-07-09 22:22:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.080078125, gpu time: 6385.712310791016
2024-07-09 22:22:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.78759765625, gpu time: 5062.53098487854
2024-07-09 22:22:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.825439453125, gpu time: 5870.896396636963
2024-07-09 22:22:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.15185546875, gpu time: 4451.829111099243
2024-07-09 22:22:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.33935546875, gpu time: 6723.958250045776
2024-07-09 22:22:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.9013671875, gpu time: 4395.874889373779
2024-07-09 22:22:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 586.064453125, gpu time: 5261.783393859863
2024-07-09 22:22:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.498291015625, gpu time: 5200.886486053467
2024-07-09 22:22:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.9306640625, gpu time: 4795.678436279297
2024-07-09 22:22:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.2900390625, gpu time: 5302.23724937439
2024-07-09 22:22:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.54638671875, gpu time: 4866.281688690186
2024-07-09 22:22:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.423828125, gpu time: 5112.1886558532715
2024-07-09 22:22:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32602.14501953125, gpu time: 38177.95446205139
2024-07-09 22:22:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.794677734375, gpu time: 4541.360439300537
2024-07-09 22:22:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.02001953125, gpu time: 6507.724170684814
2024-07-09 22:22:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.55126953125, gpu time: 4439.30375289917
2024-07-09 22:22:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.634521484375, gpu time: 5964.739570617676
2024-07-09 22:22:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 586.79248046875, gpu time: 5327.493732452393
2024-07-09 22:22:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.5908203125, gpu time: 4848.613712310791
2024-07-09 22:22:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.239013671875, gpu time: 6840.586896896362
2024-07-09 22:22:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.16455078125, gpu time: 4923.500011444092
2024-07-09 22:22:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.186279296875, gpu time: 5309.40344619751
2024-07-09 22:22:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.205322265625, gpu time: 5191.9130935668945
2024-07-09 22:22:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.4794921875, gpu time: 4592.944835662842
2024-07-09 22:22:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.19482421875, gpu time: 5449.57074546814
2024-07-09 22:22:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.188232421875, gpu time: 4502.622245788574
2024-07-09 22:22:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32602.978759765625, gpu time: 38254.772020339966
2024-07-09 22:22:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 587.640625, gpu time: 5397.694635391235
2024-07-09 22:22:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.723388671875, gpu time: 6609.586563110352
2024-07-09 22:22:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.230224609375, gpu time: 4916.642133712769
2024-07-09 22:22:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.01171875, gpu time: 4977.35417175293
2024-07-09 22:22:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.79736328125, gpu time: 6050.1332931518555
2024-07-09 22:22:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.896240234375, gpu time: 5277.528739929199
2024-07-09 22:22:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.25439453125, gpu time: 6927.489423751831
2024-07-09 22:22:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.10205078125, gpu time: 4643.8337116241455
2024-07-09 22:22:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.003173828125, gpu time: 4558.65048789978
2024-07-09 22:22:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.885498046875, gpu time: 5434.075790405273
2024-07-09 22:22:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 588.369384765625, gpu time: 5479.708040237427
2024-07-09 22:22:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.171875, gpu time: 5557.091707229614
2024-07-09 22:22:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.940185546875, gpu time: 4987.531520843506
2024-07-09 22:22:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.69921875, gpu time: 5030.621770858765
2024-07-09 22:22:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32604.72021484375, gpu time: 38403.23032569885
2024-07-09 22:22:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.75048828125, gpu time: 5350.246128082275
2024-07-09 22:22:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.933837890625, gpu time: 6704.751987457275
2024-07-09 22:22:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.741943359375, gpu time: 4704.1678829193115
2024-07-09 22:22:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.638671875, gpu time: 4609.7913646698
2024-07-09 22:22:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.190673828125, gpu time: 6153.957130432129
2024-07-09 22:22:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 589.11181640625, gpu time: 5537.141405105591
2024-07-09 22:22:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.867919921875, gpu time: 6999.162492752075
2024-07-09 22:22:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.557861328125, gpu time: 5054.176259994507
2024-07-09 22:22:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.5908203125, gpu time: 5519.270641326904
2024-07-09 22:22:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.44482421875, gpu time: 5103.398040771484
2024-07-09 22:22:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.571533203125, gpu time: 5408.916456222534
2024-07-09 22:22:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.373046875, gpu time: 5678.214288711548
2024-07-09 22:22:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.43408203125, gpu time: 4754.307159423828
2024-07-09 22:22:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32605.97021484375, gpu time: 38494.013021469116
2024-07-09 22:22:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.382080078125, gpu time: 4671.706336975098
2024-07-09 22:22:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 589.818115234375, gpu time: 5610.972238540649
2024-07-09 22:22:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.947509765625, gpu time: 6810.819347381592
2024-07-09 22:22:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.224853515625, gpu time: 5110.696825027466
2024-07-09 22:22:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.890869140625, gpu time: 6255.141445159912
2024-07-09 22:22:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.251220703125, gpu time: 5182.131277084351
2024-07-09 22:22:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.423828125, gpu time: 5482.446971893311
2024-07-09 22:22:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.095703125, gpu time: 7093.152875900269
2024-07-09 22:22:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.2783203125, gpu time: 4825.058948516846
2024-07-09 22:22:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.595947265625, gpu time: 5599.366119384766
2024-07-09 22:22:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.109130859375, gpu time: 4746.474290847778
2024-07-09 22:22:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 590.54345703125, gpu time: 5655.759666442871
2024-07-09 22:22:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.470947265625, gpu time: 5837.172616958618
2024-07-09 22:22:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.947021484375, gpu time: 5226.9034061431885
2024-07-09 22:22:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32606.68603515625, gpu time: 38664.061124801636
2024-07-09 22:22:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.88232421875, gpu time: 5275.381338119507
2024-07-09 22:22:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.163330078125, gpu time: 5536.12225151062
2024-07-09 22:22:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.891845703125, gpu time: 6897.177558898926
2024-07-09 22:22:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.896728515625, gpu time: 4887.620803833008
2024-07-09 22:22:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.11474609375, gpu time: 6364.62561416626
2024-07-09 22:22:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.750244140625, gpu time: 4837.670276641846
2024-07-09 22:22:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 591.353271484375, gpu time: 5710.680551528931
2024-07-09 22:22:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.72216796875, gpu time: 7228.903009414673
2024-07-09 22:22:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.61669921875, gpu time: 5321.227874755859
2024-07-09 22:22:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.228759765625, gpu time: 5689.964500427246
2024-07-09 22:22:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.601806640625, gpu time: 5351.555212020874
2024-07-09 22:22:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.792724609375, gpu time: 5624.366704940796
2024-07-09 22:22:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.669677734375, gpu time: 5932.371324539185
2024-07-09 22:22:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.5556640625, gpu time: 4942.2962474823
2024-07-09 22:22:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32608.171142578125, gpu time: 38756.71278953552
2024-07-09 22:22:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.447998046875, gpu time: 4894.380283355713
2024-07-09 22:22:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 592.077392578125, gpu time: 5782.697301864624
2024-07-09 22:22:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.603515625, gpu time: 6982.248249053955
2024-07-09 22:22:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.239501953125, gpu time: 5413.317302703857
2024-07-09 22:22:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.837158203125, gpu time: 6487.209003448486
2024-07-09 22:22:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.418701171875, gpu time: 5456.606578826904
2024-07-09 22:22:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.417724609375, gpu time: 5683.258153915405
2024-07-09 22:22:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.432373046875, gpu time: 7339.173261642456
2024-07-09 22:22:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.281494140625, gpu time: 4999.788654327393
2024-07-09 22:22:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.8671875, gpu time: 5779.3668785095215
2024-07-09 22:22:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.07666015625, gpu time: 4948.169647216797
2024-07-09 22:22:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 592.917724609375, gpu time: 5858.418703079224
2024-07-09 22:22:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.390869140625, gpu time: 6058.872808456421
2024-07-09 22:22:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.928466796875, gpu time: 5457.499132156372
2024-07-09 22:22:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32608.880859375, gpu time: 38825.641538619995
2024-07-09 22:22:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.154541015625, gpu time: 5509.101062774658
2024-07-09 22:22:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.0908203125, gpu time: 5761.829797744751
2024-07-09 22:22:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.626708984375, gpu time: 7070.227909088135
2024-07-09 22:22:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.953369140625, gpu time: 5052.401218414307
2024-07-09 22:22:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.189208984375, gpu time: 6577.366744995117
2024-07-09 22:22:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.918701171875, gpu time: 5006.1513385772705
2024-07-09 22:22:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 593.6474609375, gpu time: 5914.244710922241
2024-07-09 22:22:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.23828125, gpu time: 7441.408464431763
2024-07-09 22:22:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.54296875, gpu time: 5529.476524353027
2024-07-09 22:22:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.673828125, gpu time: 5899.199546813965
2024-07-09 22:22:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.849853515625, gpu time: 5556.694898605347
2024-07-09 22:22:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.84326171875, gpu time: 6131.73948097229
2024-07-09 22:22:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.8095703125, gpu time: 5816.394683837891
2024-07-09 22:22:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.599365234375, gpu time: 5107.076347351074
2024-07-09 22:22:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32609.617919921875, gpu time: 38914.983278274536
2024-07-09 22:22:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.57275390625, gpu time: 5063.93111038208
2024-07-09 22:22:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.2373046875, gpu time: 7182.4194412231445
2024-07-09 22:22:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 594.377685546875, gpu time: 6009.646619796753
2024-07-09 22:22:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.20556640625, gpu time: 5582.539808273315
2024-07-09 22:22:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.99462890625, gpu time: 6730.470352172852
2024-07-09 22:22:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.477294921875, gpu time: 5649.5868854522705
2024-07-09 22:22:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.394775390625, gpu time: 7520.04762840271
2024-07-09 22:22:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.45361328125, gpu time: 5882.010149002075
2024-07-09 22:22:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.26318359375, gpu time: 5164.4607582092285
2024-07-09 22:22:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.927734375, gpu time: 6077.274871826172
2024-07-09 22:22:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.1865234375, gpu time: 5146.059406280518
2024-07-09 22:22:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.216064453125, gpu time: 6225.257394790649
2024-07-09 22:22:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 595.078857421875, gpu time: 6066.739351272583
2024-07-09 22:22:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.921630859375, gpu time: 5652.060880661011
2024-07-09 22:22:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32610.3193359375, gpu time: 39005.74246788025
2024-07-09 22:22:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.20068359375, gpu time: 5720.591802597046
2024-07-09 22:22:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.851806640625, gpu time: 7270.917186737061
2024-07-09 22:22:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.17626953125, gpu time: 5958.859552383423
2024-07-09 22:22:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.9404296875, gpu time: 5219.038444519043
2024-07-09 22:22:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.197998046875, gpu time: 6879.516204833984
2024-07-09 22:22:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.020751953125, gpu time: 5230.254421234131
2024-07-09 22:22:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.4580078125, gpu time: 7620.630994796753
2024-07-09 22:22:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 595.7861328125, gpu time: 6148.3742027282715
2024-07-09 22:22:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.544189453125, gpu time: 6173.480625152588
2024-07-09 22:22:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.649658203125, gpu time: 5724.663875579834
2024-07-09 22:22:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.9326171875, gpu time: 5775.445331573486
2024-07-09 22:22:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.16162109375, gpu time: 6349.751993179321
2024-07-09 22:22:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.919189453125, gpu time: 6023.011976242065
2024-07-09 22:22:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32611.4658203125, gpu time: 39087.15284156799
2024-07-09 22:22:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.576416015625, gpu time: 5291.795680999756
2024-07-09 22:22:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.45068359375, gpu time: 7359.639572143555
2024-07-09 22:22:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.66064453125, gpu time: 5307.068305969238
2024-07-09 22:22:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 596.511962890625, gpu time: 6199.3514041900635
2024-07-09 22:22:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.753173828125, gpu time: 7015.125385284424
2024-07-09 22:22:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.292236328125, gpu time: 5802.784164428711
2024-07-09 22:22:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.16796875, gpu time: 7711.653703689575
2024-07-09 22:22:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.63720703125, gpu time: 5842.026721954346
2024-07-09 22:22:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.576171875, gpu time: 6079.417346954346
2024-07-09 22:22:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.624755859375, gpu time: 6283.814407348633
2024-07-09 22:22:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.8076171875, gpu time: 5348.5522537231445
2024-07-09 22:22:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.192138671875, gpu time: 6461.804975509644
2024-07-09 22:22:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.283935546875, gpu time: 5348.031251907349
2024-07-09 22:22:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32613.2021484375, gpu time: 39175.0581073761
2024-07-09 22:22:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 597.313720703125, gpu time: 6253.4953327178955
2024-07-09 22:22:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.916015625, gpu time: 5859.769058227539
2024-07-09 22:22:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.0478515625, gpu time: 7479.875133514404
2024-07-09 22:22:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.29931640625, gpu time: 5905.167304992676
2024-07-09 22:22:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.36279296875, gpu time: 7136.749584197998
2024-07-09 22:22:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.20556640625, gpu time: 6144.3891315460205
2024-07-09 22:22:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.470703125, gpu time: 5401.816181182861
2024-07-09 22:22:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.97021484375, gpu time: 7821.623006820679
2024-07-09 22:22:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.947509765625, gpu time: 5410.427993774414
2024-07-09 22:22:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.59326171875, gpu time: 6377.517761230469
2024-07-09 22:22:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 598.037841796875, gpu time: 6316.420877456665
2024-07-09 22:22:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.62939453125, gpu time: 5913.136024475098
2024-07-09 22:22:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.841552734375, gpu time: 6615.2010707855225
2024-07-09 22:22:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.423583984375, gpu time: 5977.037666320801
2024-07-09 22:22:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32613.888671875, gpu time: 39276.86355781555
2024-07-09 22:22:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.9072265625, gpu time: 6243.4718589782715
2024-07-09 22:22:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.089111328125, gpu time: 5459.205717086792
2024-07-09 22:22:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.688232421875, gpu time: 7656.36967086792
2024-07-09 22:22:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.568603515625, gpu time: 5511.875679016113
2024-07-09 22:22:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.605712890625, gpu time: 7229.757579803467
2024-07-09 22:22:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 598.8349609375, gpu time: 6375.772016525269
2024-07-09 22:22:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.290283203125, gpu time: 6005.2748947143555
2024-07-09 22:22:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.007568359375, gpu time: 7941.085611343384
2024-07-09 22:22:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.04248046875, gpu time: 6024.537263870239
2024-07-09 22:22:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.875244140625, gpu time: 6458.512935638428
2024-07-09 22:22:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.5146484375, gpu time: 6301.438514709473
2024-07-09 22:22:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.76904296875, gpu time: 5505.761156082153
2024-07-09 22:22:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.190673828125, gpu time: 6752.520822525024
2024-07-09 22:22:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.17626953125, gpu time: 5609.5342445373535
2024-07-09 22:22:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32614.5869140625, gpu time: 39420.35724067688
2024-07-09 22:22:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 599.530517578125, gpu time: 6523.810182571411
2024-07-09 22:22:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.907958984375, gpu time: 6057.456256866455
2024-07-09 22:22:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.336669921875, gpu time: 7765.040416717529
2024-07-09 22:22:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.6494140625, gpu time: 6128.413278579712
2024-07-09 22:22:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.416748046875, gpu time: 7330.564311981201
2024-07-09 22:22:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.110595703125, gpu time: 6389.4733810424805
2024-07-09 22:22:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.377685546875, gpu time: 5561.73341178894
2024-07-09 22:22:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.840576171875, gpu time: 8057.3048458099365
2024-07-09 22:22:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.79736328125, gpu time: 5680.221082687378
2024-07-09 22:22:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.63525390625, gpu time: 6538.483791351318
2024-07-09 22:22:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 600.238525390625, gpu time: 6584.177803039551
2024-07-09 22:22:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.661865234375, gpu time: 6129.617977142334
2024-07-09 22:22:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.23291015625, gpu time: 6896.431303024292
2024-07-09 22:22:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.307861328125, gpu time: 6208.425893783569
2024-07-09 22:22:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32616.08984375, gpu time: 39522.861738204956
2024-07-09 22:22:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.8828125, gpu time: 6483.528900146484
2024-07-09 22:22:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.17822265625, gpu time: 5624.985515594482
2024-07-09 22:22:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.04345703125, gpu time: 7868.838832855225
2024-07-09 22:22:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.427734375, gpu time: 5747.267595291138
2024-07-09 22:22:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.043701171875, gpu time: 7420.736465454102
2024-07-09 22:22:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 600.95849609375, gpu time: 6649.925592422485
2024-07-09 22:22:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.282470703125, gpu time: 6177.689737319946
2024-07-09 22:22:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.5693359375, gpu time: 8165.349351882935
2024-07-09 22:22:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.02685546875, gpu time: 6306.38477897644
2024-07-09 22:22:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.351318359375, gpu time: 6659.27135848999
2024-07-09 22:22:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.59326171875, gpu time: 6585.877552032471
2024-07-09 22:22:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.845947265625, gpu time: 5671.771514892578
2024-07-09 22:22:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.236083984375, gpu time: 7095.862195968628
2024-07-09 22:22:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.1484375, gpu time: 5849.227767944336
2024-07-09 22:22:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32617.41015625, gpu time: 39617.38718223572
2024-07-09 22:22:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 601.689697265625, gpu time: 6710.980098724365
2024-07-09 22:22:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.947998046875, gpu time: 6236.40743637085
2024-07-09 22:22:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.201904296875, gpu time: 7990.32767868042
2024-07-09 22:22:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.673583984375, gpu time: 6391.654047012329
2024-07-09 22:22:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.766357421875, gpu time: 7519.021110534668
2024-07-09 22:22:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.29296875, gpu time: 6638.030601501465
2024-07-09 22:23:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.635986328125, gpu time: 5741.71883392334
2024-07-09 22:23:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.55078125, gpu time: 8268.712411880493
2024-07-09 22:23:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.806884765625, gpu time: 5910.59411239624
2024-07-09 22:23:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.262451171875, gpu time: 6752.668956756592
2024-07-09 22:23:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 602.51318359375, gpu time: 6764.82147026062
2024-07-09 22:23:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.615478515625, gpu time: 6289.020809173584
2024-07-09 22:23:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.938720703125, gpu time: 7192.408441543579
2024-07-09 22:23:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.291748046875, gpu time: 6455.96199798584
2024-07-09 22:23:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32618.133544921875, gpu time: 39767.512563705444
2024-07-09 22:23:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.943603515625, gpu time: 6730.379877090454
2024-07-09 22:23:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.27734375, gpu time: 5793.911081314087
2024-07-09 22:23:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.822021484375, gpu time: 8137.82345199585
2024-07-09 22:23:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.43701171875, gpu time: 5970.093732833862
2024-07-09 22:23:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.0380859375, gpu time: 7597.975646972656
2024-07-09 22:23:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 603.252685546875, gpu time: 6834.008148193359
2024-07-09 22:23:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.199951171875, gpu time: 8363.289693832397
2024-07-09 22:23:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.236083984375, gpu time: 6347.287469863892
2024-07-09 22:23:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.96435546875, gpu time: 6512.921615600586
2024-07-09 22:23:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.929443359375, gpu time: 6902.20121383667
2024-07-09 22:23:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.562255859375, gpu time: 6815.966428756714
2024-07-09 22:23:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.46044921875, gpu time: 7279.870515823364
2024-07-09 22:23:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.906982421875, gpu time: 5880.870115280151
2024-07-09 22:23:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.225341796875, gpu time: 6029.228233337402
2024-07-09 22:23:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32618.859130859375, gpu time: 39902.94463920593
2024-07-09 22:23:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 603.974609375, gpu time: 6894.180891036987
2024-07-09 22:23:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.519775390625, gpu time: 8228.923606872559
2024-07-09 22:23:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.013427734375, gpu time: 6412.628223419189
2024-07-09 22:23:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.600341796875, gpu time: 6581.838857650757
2024-07-09 22:23:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.261962890625, gpu time: 7739.365013122559
2024-07-09 22:23:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.328369140625, gpu time: 6874.317249298096
2024-07-09 22:23:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.935302734375, gpu time: 8461.977865219116
2024-07-09 22:23:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.61962890625, gpu time: 5939.605577468872
2024-07-09 22:23:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.90869140625, gpu time: 6081.806085586548
2024-07-09 22:23:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.599609375, gpu time: 7035.2726402282715
2024-07-09 22:23:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 604.751708984375, gpu time: 6989.866819381714
2024-07-09 22:23:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.1728515625, gpu time: 7414.085466384888
2024-07-09 22:23:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.640869140625, gpu time: 6497.731250762939
2024-07-09 22:23:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.223876953125, gpu time: 6639.784076690674
2024-07-09 22:23:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32619.573974609375, gpu time: 39998.85872840881
2024-07-09 22:23:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.9501953125, gpu time: 6932.94407081604
2024-07-09 22:23:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.976318359375, gpu time: 8309.375106811523
2024-07-09 22:23:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.248291015625, gpu time: 5992.878631591797
2024-07-09 22:23:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.5234375, gpu time: 6155.692453384399
2024-07-09 22:23:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.41796875, gpu time: 7830.472854614258
2024-07-09 22:23:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 605.4697265625, gpu time: 7075.557046890259
2024-07-09 22:23:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.06298828125, gpu time: 8620.193502426147
2024-07-09 22:23:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.279296875, gpu time: 6595.824068069458
2024-07-09 22:23:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.829345703125, gpu time: 6722.076539993286
2024-07-09 22:23:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.92138671875, gpu time: 7171.617679595947
2024-07-09 22:23:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.55029296875, gpu time: 6990.259531021118
2024-07-09 22:23:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.12890625, gpu time: 7512.590440750122
2024-07-09 22:23:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.029541015625, gpu time: 6086.366481781006
2024-07-09 22:23:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.1474609375, gpu time: 6220.993848800659
2024-07-09 22:23:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32620.28955078125, gpu time: 40120.89670372009
2024-07-09 22:23:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 606.18212890625, gpu time: 7138.429000854492
2024-07-09 22:23:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.694580078125, gpu time: 8403.065349578857
2024-07-09 22:23:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.0126953125, gpu time: 6646.459356307983
2024-07-09 22:23:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.521240234375, gpu time: 6777.441759109497
2024-07-09 22:23:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.787841796875, gpu time: 7917.164367675781
2024-07-09 22:23:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.21484375, gpu time: 7090.426429748535
2024-07-09 22:23:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.684326171875, gpu time: 8783.079229354858
2024-07-09 22:23:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.7021484375, gpu time: 6160.48645401001
2024-07-09 22:23:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.81591796875, gpu time: 6279.849473953247
2024-07-09 22:23:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.40576171875, gpu time: 7257.667755126953
2024-07-09 22:23:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 606.91064453125, gpu time: 7220.381147384644
2024-07-09 22:23:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.93896484375, gpu time: 7657.701902389526
2024-07-09 22:23:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.623779296875, gpu time: 6716.4934005737305
2024-07-09 22:23:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.218017578125, gpu time: 6841.40411567688
2024-07-09 22:23:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32622.039306640625, gpu time: 40242.75164985657
2024-07-09 22:23:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.88818359375, gpu time: 7143.857566833496
2024-07-09 22:23:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.876708984375, gpu time: 8474.116996765137
2024-07-09 22:23:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.5537109375, gpu time: 6243.317640304565
2024-07-09 22:23:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.521484375, gpu time: 6354.016008377075
2024-07-09 22:23:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.19873046875, gpu time: 8044.720436096191
2024-07-09 22:23:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 607.58984375, gpu time: 7286.593744277954
2024-07-09 22:23:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.3759765625, gpu time: 8874.485639572144
2024-07-09 22:23:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.308837890625, gpu time: 6773.326622009277
2024-07-09 22:23:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.895263671875, gpu time: 6927.133226394653
2024-07-09 22:23:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.341796875, gpu time: 7352.951286315918
2024-07-09 22:23:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.52001953125, gpu time: 7196.297981262207
2024-07-09 22:23:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.19384765625, gpu time: 7727.207468032837
2024-07-09 22:23:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.177001953125, gpu time: 6316.399850845337
2024-07-09 22:23:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32623.268798828125, gpu time: 40328.1892414093
2024-07-09 22:23:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.1318359375, gpu time: 6440.99408531189
2024-07-09 22:23:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 608.39453125, gpu time: 7344.929048538208
2024-07-09 22:23:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.50439453125, gpu time: 8561.487712860107
2024-07-09 22:23:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.940673828125, gpu time: 6843.628667831421
2024-07-09 22:23:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.82373046875, gpu time: 8123.675136566162
2024-07-09 22:23:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.528564453125, gpu time: 6977.539714813232
2024-07-09 22:23:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.154052734375, gpu time: 7267.580028533936
2024-07-09 22:23:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.0126953125, gpu time: 8963.502759933472
2024-07-09 22:23:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.796142578125, gpu time: 6392.506223678589
2024-07-09 22:23:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.234130859375, gpu time: 7443.8479347229
2024-07-09 22:23:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.75830078125, gpu time: 6501.699312210083
2024-07-09 22:23:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 609.110107421875, gpu time: 7441.520261764526
2024-07-09 22:23:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.271728515625, gpu time: 7850.082410812378
2024-07-09 22:23:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.576171875, gpu time: 6893.87228012085
2024-07-09 22:23:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32623.9970703125, gpu time: 40420.64029121399
2024-07-09 22:23:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.1689453125, gpu time: 7042.576469421387
2024-07-09 22:23:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.91943359375, gpu time: 7320.927484512329
2024-07-09 22:23:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.3134765625, gpu time: 8700.117401123047
2024-07-09 22:23:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.40478515625, gpu time: 6465.239950180054
2024-07-09 22:23:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.90673828125, gpu time: 8206.644886016846
2024-07-09 22:23:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.4931640625, gpu time: 6566.763111114502
2024-07-09 22:23:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 609.836181640625, gpu time: 7504.7544593811035
2024-07-09 22:23:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.703125, gpu time: 9087.271146774292
2024-07-09 22:23:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.3076171875, gpu time: 6956.978309631348
2024-07-09 22:23:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.8505859375, gpu time: 7520.048236846924
2024-07-09 22:23:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.858642578125, gpu time: 7116.052444458008
2024-07-09 22:23:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.72607421875, gpu time: 7403.707319259644
2024-07-09 22:23:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.88818359375, gpu time: 7997.320917129517
2024-07-09 22:23:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.068359375, gpu time: 6546.485059738159
2024-07-09 22:23:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32624.7158203125, gpu time: 40504.862047195435
2024-07-09 22:23:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.231201171875, gpu time: 6615.116319656372
2024-07-09 22:23:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 610.625244140625, gpu time: 7579.783874511719
2024-07-09 22:23:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.988037109375, gpu time: 8793.119651794434
2024-07-09 22:23:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.94970703125, gpu time: 7010.1894454956055
2024-07-09 22:23:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.648681640625, gpu time: 8350.669631958008
2024-07-09 22:23:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.555908203125, gpu time: 7223.911205291748
2024-07-09 22:23:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.432861328125, gpu time: 7461.753988265991
2024-07-09 22:23:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.428955078125, gpu time: 9221.816995620728
2024-07-09 22:23:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.677001953125, gpu time: 6613.173341751099
2024-07-09 22:23:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.554931640625, gpu time: 7646.138866424561
2024-07-09 22:23:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.839599609375, gpu time: 6657.041835784912
2024-07-09 22:23:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.5556640625, gpu time: 8090.548448562622
2024-07-09 22:23:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 611.340576171875, gpu time: 7639.081424713135
2024-07-09 22:23:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.57470703125, gpu time: 7066.871629714966
2024-07-09 22:23:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32625.4501953125, gpu time: 40585.600912094116
2024-07-09 22:23:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.215087890625, gpu time: 7301.488307952881
2024-07-09 22:23:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.29931640625, gpu time: 8875.260765075684
2024-07-09 22:23:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.187744140625, gpu time: 7534.916366577148
2024-07-09 22:23:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.476806640625, gpu time: 6667.357280731201
2024-07-09 22:23:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.278076171875, gpu time: 8478.124588012695
2024-07-09 22:23:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.4521484375, gpu time: 6767.250835418701
2024-07-09 22:23:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.054931640625, gpu time: 9335.812887191772
2024-07-09 22:23:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 612.10791015625, gpu time: 7694.3292026519775
2024-07-09 22:23:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.041748046875, gpu time: 7738.2775955200195
2024-07-09 22:23:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.352783203125, gpu time: 7125.257499694824
2024-07-09 22:23:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.926025390625, gpu time: 7353.878005981445
2024-07-09 22:23:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.40771484375, gpu time: 8191.128953933716
2024-07-09 22:23:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.939453125, gpu time: 7592.495830535889
2024-07-09 22:23:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32626.1650390625, gpu time: 40676.29036140442
2024-07-09 22:23:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.08447265625, gpu time: 6725.4036293029785
2024-07-09 22:23:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.190185546875, gpu time: 6830.395273208618
2024-07-09 22:23:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.021240234375, gpu time: 8999.307720184326
2024-07-09 22:23:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 612.806640625, gpu time: 7772.70583152771
2024-07-09 22:23:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.389404296875, gpu time: 8565.056427001953
2024-07-09 22:23:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.06591796875, gpu time: 7199.948196411133
2024-07-09 22:23:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.6875, gpu time: 7420.8725299835205
2024-07-09 22:23:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.774169921875, gpu time: 9470.189138412476
2024-07-09 22:23:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.666015625, gpu time: 7713.820854187012
2024-07-09 22:23:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.2099609375, gpu time: 7888.315475463867
2024-07-09 22:23:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.7431640625, gpu time: 6787.452386856079
2024-07-09 22:23:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.81103515625, gpu time: 6882.718090057373
2024-07-09 22:23:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.249755859375, gpu time: 8325.36872291565
2024-07-09 22:23:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 613.588134765625, gpu time: 7823.863525390625
2024-07-09 22:23:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32627.640625, gpu time: 40764.83244514465
2024-07-09 22:23:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.780517578125, gpu time: 7289.69108581543
2024-07-09 22:23:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.387451171875, gpu time: 7480.558559417725
2024-07-09 22:23:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.017333984375, gpu time: 9149.865283966064
2024-07-09 22:23:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.349365234375, gpu time: 7786.082273483276
2024-07-09 22:23:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.03173828125, gpu time: 8655.113075256348
2024-07-09 22:23:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.560546875, gpu time: 6849.829944610596
2024-07-09 22:23:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.43896484375, gpu time: 6938.704753875732
2024-07-09 22:23:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 22:23:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 22:23:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 22:23:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 22:23:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 22:23:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 22:23:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 22:23:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 22:23:38 | INFO | fairseq_cli.eval_lm | Evaluated 825,641 tokens in 270.8s (3049.14 tokens/s)
2024-07-09 22:23:38 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9464, Perplexity: 7.71
2024-07-09 22:23:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.36376953125, gpu time: 9598.78058052063
2024-07-09 22:23:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.859130859375, gpu time: 7925.700984954834
2024-07-09 22:23:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.42626953125, gpu time: 8359.706546783447
2024-07-09 22:23:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32628.328369140625, gpu time: 40805.16740036011
2024-07-09 22:23:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.40625, gpu time: 9189.245515823364
2024-07-09 22:23:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.6982421875, gpu time: 8690.163221359253
2024-07-09 22:23:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.7958984375, gpu time: 9637.997774124146
2024-07-09 22:23:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.758056640625, gpu time: 7960.06072807312
2024-07-09 22:23:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.708984375, gpu time: 8400.694143295288
2024-07-09 22:23:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32629.04296875, gpu time: 40846.460916519165
2024-07-09 22:23:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.023681640625, gpu time: 9223.247339248657
2024-07-09 22:23:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.54345703125, gpu time: 8725.449848175049
2024-07-09 22:23:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.71240234375, gpu time: 9677.317045211792
2024-07-09 22:23:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.622802734375, gpu time: 8006.217935562134
2024-07-09 22:23:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.515869140625, gpu time: 8441.846057891846
2024-07-09 22:23:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32630.03857421875, gpu time: 40887.662591934204
2024-07-09 22:23:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.843017578125, gpu time: 9271.350149154663
2024-07-09 22:23:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.3486328125, gpu time: 8767.24384689331
2024-07-09 22:23:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.427978515625, gpu time: 9722.685609817505
2024-07-09 22:23:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.86669921875, gpu time: 8041.158319473267
2024-07-09 22:23:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.33740234375, gpu time: 8481.182451248169
2024-07-09 22:23:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32630.927978515625, gpu time: 40937.36556434631
2024-07-09 22:23:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.18994140625, gpu time: 9311.921745300293
2024-07-09 22:23:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.3701171875, gpu time: 8820.67050743103
2024-07-09 22:23:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.107177734375, gpu time: 9768.369695663452
2024-07-09 22:23:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.5458984375, gpu time: 8092.197456359863
2024-07-09 22:23:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.12548828125, gpu time: 8525.889734268188
2024-07-09 22:23:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32631.92529296875, gpu time: 40984.863733291626
2024-07-09 22:23:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.827880859375, gpu time: 9349.264377593994
2024-07-09 22:23:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.14013671875, gpu time: 8865.847875595093
2024-07-09 22:23:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.88720703125, gpu time: 9815.89570426941
2024-07-09 22:23:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.192626953125, gpu time: 8140.332107543945
2024-07-09 22:23:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.7822265625, gpu time: 8567.639093399048
2024-07-09 22:23:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32632.639892578125, gpu time: 41028.02557563782
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 22:23:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.72705078125, gpu time: 9383.275482177734
2024-07-09 22:23:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.3173828125, gpu time: 8906.547630310059
2024-07-09 22:23:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.388916015625, gpu time: 9858.590986251831
2024-07-09 22:23:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.800537109375, gpu time: 8181.5536251068115
2024-07-09 22:23:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.39208984375, gpu time: 8601.925556182861
2024-07-09 22:23:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32633.3310546875, gpu time: 41072.060859680176
2024-07-09 22:23:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.3466796875, gpu time: 9417.486427307129
2024-07-09 22:23:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.615966796875, gpu time: 8941.327054977417
2024-07-09 22:23:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.356689453125, gpu time: 9904.390274047852
2024-07-09 22:23:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.90283203125, gpu time: 8216.390811920166
2024-07-09 22:23:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.020263671875, gpu time: 8636.329299926758
2024-07-09 22:23:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32634.05712890625, gpu time: 41122.71055603027
2024-07-09 22:23:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.552734375, gpu time: 9461.123310089111
2024-07-09 22:23:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.2470703125, gpu time: 8979.300567626953
2024-07-09 22:23:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.76220703125, gpu time: 9938.79257774353
2024-07-09 22:23:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.733642578125, gpu time: 8258.07377243042
2024-07-09 22:23:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.97216796875, gpu time: 8670.595603942871
2024-07-09 22:23:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32635.49267578125, gpu time: 41173.1741733551
2024-07-09 22:23:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.186279296875, gpu time: 9504.51283454895
2024-07-09 22:23:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.88427734375, gpu time: 9013.80703163147
2024-07-09 22:23:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.022216796875, gpu time: 9976.02672958374
2024-07-09 22:23:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.36962890625, gpu time: 8303.761220932007
2024-07-09 22:23:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.822021484375, gpu time: 8710.859680175781
2024-07-09 22:23:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32637.00244140625, gpu time: 41223.172508239746
2024-07-09 22:23:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.38720703125, gpu time: 9541.022504806519
2024-07-09 22:23:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.13720703125, gpu time: 9052.758464813232
2024-07-09 22:23:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.659423828125, gpu time: 10021.972898483276
2024-07-09 22:23:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.005126953125, gpu time: 8343.456657409668
2024-07-09 22:23:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.463134765625, gpu time: 8765.920904159546
2024-07-09 22:23:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32637.725830078125, gpu time: 41264.84443092346
2024-07-09 22:23:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.162841796875, gpu time: 9592.220045089722
2024-07-09 22:23:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.787841796875, gpu time: 9098.311351776123
2024-07-09 22:23:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.032958984375, gpu time: 10060.548490524292
2024-07-09 22:23:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.36572265625, gpu time: 8529.361492156982
2024-07-09 22:23:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.099853515625, gpu time: 8825.561981201172
2024-07-09 22:23:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32638.44677734375, gpu time: 41318.70853614807
2024-07-09 22:23:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.78759765625, gpu time: 9636.626209259033
2024-07-09 22:23:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.41064453125, gpu time: 9137.729507446289
2024-07-09 22:23:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.650390625, gpu time: 10106.235780715942
2024-07-09 22:23:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.1953125, gpu time: 8571.65805053711
2024-07-09 22:23:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.87109375, gpu time: 8879.535364151001
2024-07-09 22:23:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32639.60302734375, gpu time: 41362.19742012024
2024-07-09 22:23:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.401123046875, gpu time: 9679.145009994507
2024-07-09 22:23:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.021484375, gpu time: 9306.17064857483
2024-07-09 22:23:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.266357421875, gpu time: 10145.587055206299
2024-07-09 22:23:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.024169921875, gpu time: 8614.721334457397
2024-07-09 22:23:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.490478515625, gpu time: 8914.441192626953
2024-07-09 22:23:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32640.419921875, gpu time: 41409.43095397949
2024-07-09 22:23:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.007080078125, gpu time: 9721.90333366394
2024-07-09 22:23:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.810302734375, gpu time: 9340.335514068604
2024-07-09 22:23:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.380859375, gpu time: 10192.696586608887
2024-07-09 22:24:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.810302734375, gpu time: 8656.245094299316
2024-07-09 22:24:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.705078125, gpu time: 8948.570859909058
2024-07-09 22:24:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32641.161376953125, gpu time: 41446.8699054718
2024-07-09 22:24:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.0732421875, gpu time: 9760.921970367432
2024-07-09 22:24:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.44287109375, gpu time: 9385.083921432495
2024-07-09 22:24:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.509765625, gpu time: 10233.244985580444
2024-07-09 22:24:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.780029296875, gpu time: 8699.82661819458
2024-07-09 22:24:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.33203125, gpu time: 8988.360055923462
2024-07-09 22:24:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32642.038330078125, gpu time: 41484.04501724243
2024-07-09 22:24:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.083251953125, gpu time: 9945.430662155151
2024-07-09 22:24:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.08740234375, gpu time: 9464.094951629639
2024-07-09 22:24:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.146484375, gpu time: 10358.192113876343
2024-07-09 22:24:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.189453125, gpu time: 8880.865055084229
2024-07-09 22:24:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.02685546875, gpu time: 9171.734811782837
2024-07-09 22:24:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32642.716796875, gpu time: 41597.42651939392
2024-07-09 22:24:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.72216796875, gpu time: 10128.310705184937
2024-07-09 22:24:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.7080078125, gpu time: 9570.774518966675
2024-07-09 22:24:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.794921875, gpu time: 10543.822080612183
2024-07-09 22:24:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.19970703125, gpu time: 8995.018083572388
2024-07-09 22:24:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.669189453125, gpu time: 9358.741579055786
2024-07-09 22:24:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32643.444091796875, gpu time: 41713.689153671265
2024-07-09 22:24:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.373291015625, gpu time: 10331.68695640564
2024-07-09 22:24:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.34716796875, gpu time: 9687.451553344727
2024-07-09 22:24:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.08349609375, gpu time: 10731.966772079468
2024-07-09 22:24:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.828369140625, gpu time: 9177.7725315094
2024-07-09 22:24:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.314697265625, gpu time: 9464.072187423706
2024-07-09 22:24:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32644.623779296875, gpu time: 41937.244161605835
2024-07-09 22:24:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.011474609375, gpu time: 10475.71683883667
2024-07-09 22:24:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.350341796875, gpu time: 9930.660675048828
2024-07-09 22:24:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.172119140625, gpu time: 10804.214435577393
2024-07-09 22:24:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.46240234375, gpu time: 9328.039386749268
2024-07-09 22:24:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.07958984375, gpu time: 9720.994298934937
2024-07-09 22:24:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32645.4287109375, gpu time: 42090.14334487915
2024-07-09 22:24:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.1796875, gpu time: 10720.517810821533
2024-07-09 22:24:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.98193359375, gpu time: 10085.216512680054
2024-07-09 22:24:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.37646484375, gpu time: 10944.576309204102
2024-07-09 22:24:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.117919921875, gpu time: 9594.990161895752
2024-07-09 22:24:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.728271484375, gpu time: 9880.05318069458
2024-07-09 22:24:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32646.51806640625, gpu time: 42242.330211639404
2024-07-09 22:24:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.90625, gpu time: 10874.34564781189
2024-07-09 22:24:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.61376953125, gpu time: 10144.240633010864
2024-07-09 22:24:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.7119140625, gpu time: 10987.414476394653
2024-07-09 22:24:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.16015625, gpu time: 9636.892963409424
2024-07-09 22:24:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.811767578125, gpu time: 9920.546863555908
2024-07-09 22:24:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32647.65380859375, gpu time: 42286.16661834717
2024-07-09 22:24:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.366943359375, gpu time: 11038.585018157959
2024-07-09 22:24:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.2509765625, gpu time: 10192.993368148804
2024-07-09 22:24:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.34423828125, gpu time: 11028.69455909729
2024-07-09 22:24:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.965087890625, gpu time: 9675.176881790161
2024-07-09 22:24:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.881103515625, gpu time: 9972.197206497192
2024-07-09 22:24:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32648.373779296875, gpu time: 42337.97648239136
2024-07-09 22:24:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.4873046875, gpu time: 11090.824960708618
2024-07-09 22:24:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.867919921875, gpu time: 10246.93907546997
2024-07-09 22:24:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.119140625, gpu time: 11069.071599960327
2024-07-09 22:24:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.610107421875, gpu time: 9717.59984779358
2024-07-09 22:24:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.512939453125, gpu time: 10029.196201324463
2024-07-09 22:24:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32649.938232421875, gpu time: 42435.85123825073
2024-07-09 22:24:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.11669921875, gpu time: 11126.911754608154
2024-07-09 22:24:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.0576171875, gpu time: 10284.599151611328
2024-07-09 22:24:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.095458984375, gpu time: 11119.631378173828
2024-07-09 22:24:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.641845703125, gpu time: 9752.45576095581
2024-07-09 22:24:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.745361328125, gpu time: 10224.273561477661
2024-07-09 22:24:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32650.954833984375, gpu time: 42616.037200927734
2024-07-09 22:24:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.760986328125, gpu time: 11310.790370941162
2024-07-09 22:24:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.697509765625, gpu time: 10328.55940246582
2024-07-09 22:24:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.721923828125, gpu time: 11297.524534225464
2024-07-09 22:24:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.281005859375, gpu time: 9799.912656784058
2024-07-09 22:24:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 101.368408203125, gpu time: 10262.456998825073
2024-07-09 22:24:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32651.671875, gpu time: 42730.53055381775
2024-07-09 22:24:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.41650390625, gpu time: 11351.001651763916
2024-07-09 22:24:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.8369140625, gpu time: 10371.684610366821
2024-07-09 22:24:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 101.721435546875, gpu time: 11340.133581161499
2024-07-09 22:24:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.00146484375, gpu time: 9842.46042060852
2024-07-09 22:24:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 102.23291015625, gpu time: 10299.61339378357
2024-07-09 22:24:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32652.3916015625, gpu time: 42777.71640968323
2024-07-09 22:24:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 101.041259765625, gpu time: 11390.208129882812
2024-07-09 22:24:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.453857421875, gpu time: 10405.855878829956
2024-07-09 22:24:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 102.40283203125, gpu time: 11380.273021697998
2024-07-09 22:24:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.62158203125, gpu time: 9879.25121498108
2024-07-09 22:24:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.19482421875, gpu time: 10342.463399887085
2024-07-09 22:24:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32653.45751953125, gpu time: 42814.85728645325
2024-07-09 22:24:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 101.6669921875, gpu time: 11430.25269126892
2024-07-09 22:24:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.077880859375, gpu time: 10445.467321395874
2024-07-09 22:24:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.026611328125, gpu time: 11414.417570114136
2024-07-09 22:24:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 101.236572265625, gpu time: 9913.484086990356
2024-07-09 22:24:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 104.443359375, gpu time: 10383.89404296875
2024-07-09 22:24:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32654.176025390625, gpu time: 42854.58440589905
2024-07-09 22:24:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 102.6005859375, gpu time: 11465.285724639893
2024-07-09 22:24:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.696044921875, gpu time: 10488.83844947815
2024-07-09 22:24:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.841064453125, gpu time: 11449.696840286255
2024-07-09 22:24:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 102.265380859375, gpu time: 9949.30608177185
2024-07-09 22:24:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 105.074462890625, gpu time: 10429.799097061157
2024-07-09 22:24:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32655.29052734375, gpu time: 42893.91728591919
2024-07-09 22:24:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.23486328125, gpu time: 11512.311740875244
2024-07-09 22:24:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.315673828125, gpu time: 10523.25212097168
2024-07-09 22:24:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 104.47314453125, gpu time: 11487.20651626587
2024-07-09 22:24:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 102.892578125, gpu time: 9997.333379745483
2024-07-09 22:24:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 105.697509765625, gpu time: 10470.737741470337
2024-07-09 22:24:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32656.01806640625, gpu time: 42941.06746292114
2024-07-09 22:24:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.9267578125, gpu time: 11558.954557418823
2024-07-09 22:24:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.9482421875, gpu time: 10564.381484985352
2024-07-09 22:24:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 105.12060546875, gpu time: 11538.35557937622
2024-07-09 22:24:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.57763671875, gpu time: 10040.8657913208
2024-07-09 22:24:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 106.325439453125, gpu time: 10519.009519577026
2024-07-09 22:24:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32656.72998046875, gpu time: 42989.49764060974
2024-07-09 22:24:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 104.68359375, gpu time: 11600.183120727539
2024-07-09 22:24:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.580810546875, gpu time: 10608.078695297241
2024-07-09 22:24:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 105.821044921875, gpu time: 11572.5508518219
2024-07-09 22:24:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 104.2646484375, gpu time: 10086.371803283691
2024-07-09 22:24:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 107.451416015625, gpu time: 10560.850887298584
2024-07-09 22:24:32 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 22:24:32 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 22:24:32 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 22:24:32 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 22:24:32 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 22:24:32 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 22:24:32 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 22:24:32 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 22:24:32 | INFO | fairseq_cli.eval_lm | Evaluated 825,641 tokens in 377.1s (2189.44 tokens/s)
2024-07-09 22:24:32 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9464, Perplexity: 7.71
