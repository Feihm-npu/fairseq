2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10038
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15370
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15370
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19111
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19111
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19599
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 3
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19111
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19111
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15370
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19599
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 1
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10038
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10038
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19599
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10038
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19599
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15370
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 1
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 2
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 0
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14841
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17842
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17851
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14349
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17842
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14841
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14841
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17851
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14841
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14349
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17842
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 2
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14349
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17851
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 2
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17842
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17851
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14349
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 3
2024-07-09 03:57:38 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 3
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15370', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:38 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 03:57:38 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 03:57:38 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 03:57:38 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 1
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 3
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 3
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 3
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 2
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 0
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 2
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 0
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 1
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 2
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 0
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 1
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 1
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 1
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 2
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 2
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 3
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 0
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 1
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 3
2024-07-09 03:57:39 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19111', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19599', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10038', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:39 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 03:57:39 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 03:57:39 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 03:57:39 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 03:57:39 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 03:57:39 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 03:57:39 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 03:57:39 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 03:57:39 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 03:57:39 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17842', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 03:57:40 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 03:57:40 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 03:57:40 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14349', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17851', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14841', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 03:57:40 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 03:57:40 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 03:57:40 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 03:57:40 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 03:57:40 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 03:57:40 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 03:57:40 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 03:57:40 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 03:57:40 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 03:57:40 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 03:57:42 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 03:57:43 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 03:57:44 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 03:58:04 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 03:58:05 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 03:58:06 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 03:58:06 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 03:58:08 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 03:58:09 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 03:58:09 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 03:58:10 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 03:58:28 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 03:58:28 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 03:58:29 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 03:58:31 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 03:58:56 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 03:58:56 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 03:58:56 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 03:58:56 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 03:59:54 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 03:59:59 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:00:07 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:00:10 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:00:18 | INFO | fairseq_cli.eval_lm | load time: 158.15 seconds
2024-07-09 04:00:23 | INFO | fairseq_cli.eval_lm | load time: 165.05 seconds
2024-07-09 04:00:33 | INFO | fairseq_cli.eval_lm | load time: 173.44 seconds
2024-07-09 04:00:33 | INFO | fairseq_cli.eval_lm | load time: 173.62 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
W0709 04:00:52.889274 140587354502976 torch/multiprocessing/spawn.py:145] Terminating process 136909 via signal SIGTERM
W0709 04:00:52.889839 140587354502976 torch/multiprocessing/spawn.py:145] Terminating process 136910 via signal SIGTERM
W0709 04:00:52.890102 140587354502976 torch/multiprocessing/spawn.py:145] Terminating process 136912 via signal SIGTERM
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
W0709 04:00:55.659721 140067751233344 torch/multiprocessing/spawn.py:145] Terminating process 576647 via signal SIGTERM
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
W0709 04:00:55.717220 140067751233344 torch/multiprocessing/spawn.py:145] Terminating process 576650 via signal SIGTERM
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
W0709 04:00:55.717733 140067751233344 torch/multiprocessing/spawn.py:145] Terminating process 576657 via signal SIGTERM
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 169, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
W0709 04:00:56.075243 139705327531840 torch/multiprocessing/spawn.py:145] Terminating process 576643 via signal SIGTERM
W0709 04:00:56.081378 139705327531840 torch/multiprocessing/spawn.py:145] Terminating process 576645 via signal SIGTERM
W0709 04:00:56.082054 139705327531840 torch/multiprocessing/spawn.py:145] Terminating process 576652 via signal SIGTERM
srun: error: t004-005: task 1: Exited with exit code 1
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 2 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 204, in top2gating
    return l_aux, combine_weights.to(orig_dtype), dispatch_mask, metadata
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 2.00 GiB. GPU  has a total capacity of 63.98 GiB of which 1.30 GiB is free. Of the allocated memory 20.10 GiB is allocated by PyTorch, and 713.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 2 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 193, in top2gating
    combine1_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 1.00 GiB is free. Of the allocated memory 7.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

srun: error: t004-006: task 7: Exited with exit code 1
Exception ignored in: <function PlasmaArray.__del__ at 0x7fc77fa560d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Exception ignored in: <function PlasmaArray.__del__ at 0x7f671e6770d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
Exception ignored in: <function PlasmaArray.__del__ at 0x7fdeefc600d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:01:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10547.52294921875, gpu time: 10547.519400596619
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:01:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.516845703125, gpu time: 34.64301872253418
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 25 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
srun: error: t004-006: task 6: Exited with exit code 1
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 35 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 04:01:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.3876953125, gpu time: 81.84571075439453
2024-07-09 04:01:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.375244140625, gpu time: 34.28861999511719
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:01:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.914794921875, gpu time: 30.057899475097656
2024-07-09 04:01:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.362548828125, gpu time: 26.71998405456543
2024-07-09 04:01:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10549.267333984375, gpu time: 10699.175953865051
2024-07-09 04:01:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.11767578125, gpu time: 71.89051532745361
2024-07-09 04:01:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.261474609375, gpu time: 117.86792945861816
2024-07-09 04:01:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.228271484375, gpu time: 129.77063941955566
2024-07-09 04:01:03 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:01:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.1279296875, gpu time: 67.94155502319336
2024-07-09 04:01:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.73583984375, gpu time: 58.149245262145996
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:01:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10550.672607421875, gpu time: 10738.74617099762
2024-07-09 04:01:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.87841796875, gpu time: 132.6003999710083
2024-07-09 04:01:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.1748046875, gpu time: 190.63140678405762
Exception ignored in: <function PlasmaArray.__del__ at 0x7f5a99a380d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
2024-07-09 04:01:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.007568359375, gpu time: 174.04597282409668
2024-07-09 04:01:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.102783203125, gpu time: 111.96408653259277
2024-07-09 04:01:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.903076171875, gpu time: 98.3172197341919
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 11 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 04:01:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2919.664794921875, gpu time: 3163.186767578125
2024-07-09 04:01:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10552.023681640625, gpu time: 10885.797600746155
2024-07-09 04:01:06 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:01:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.562744140625, gpu time: 206.99811840057373
2024-07-09 04:01:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.338134765625, gpu time: 235.46113777160645
2024-07-09 04:01:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.85595703125, gpu time: 214.70642852783203
2024-07-09 04:01:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.468505859375, gpu time: 144.2130250930786
2024-07-09 04:01:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.431640625, gpu time: 152.2901487350464
2024-07-09 04:01:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.340087890625, gpu time: 1419.2842407226562
2024-07-09 04:01:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10552.786376953125, gpu time: 10971.577229499817
2024-07-09 04:01:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.2939453125, gpu time: 237.9019365310669
2024-07-09 04:01:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.3701171875, gpu time: 78.64475440979004
2024-07-09 04:01:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.90087890625, gpu time: 292.9763011932373
2024-07-09 04:01:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.324951171875, gpu time: 49.23836708068848
2024-07-09 04:01:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.225341796875, gpu time: 253.04656410217285
2024-07-09 04:01:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.26025390625, gpu time: 175.9962034225464
2024-07-09 04:01:09 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:01:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.3173828125, gpu time: 57.24092483520508
2024-07-09 04:01:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.296875, gpu time: 203.50531578063965
2024-07-09 04:01:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.32373046875, gpu time: 77.91466903686523
2024-07-09 04:01:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10554.002685546875, gpu time: 11011.818481445312
2024-07-09 04:01:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.49267578125, gpu time: 280.7068672180176
2024-07-09 04:01:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2920.14697265625, gpu time: 3240.2790393829346
2024-07-09 04:01:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.58056640625, gpu time: 347.62538719177246
2024-07-09 04:01:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.66796875, gpu time: 1475.7914028167725
2024-07-09 04:01:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.92724609375, gpu time: 283.9414224624634
2024-07-09 04:01:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.226806640625, gpu time: 207.49090194702148
2024-07-09 04:01:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.718994140625, gpu time: 141.03159523010254
2024-07-09 04:01:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.433349609375, gpu time: 257.9363203048706
2024-07-09 04:01:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.2529296875, gpu time: 134.4480743408203
2024-07-09 04:01:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10555.436767578125, gpu time: 11081.035876274109
2024-07-09 04:01:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.71337890625, gpu time: 314.53020572662354
2024-07-09 04:01:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.12548828125, gpu time: 119.4282455444336
2024-07-09 04:01:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.623046875, gpu time: 401.31063079833984
2024-07-09 04:01:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.69189453125, gpu time: 132.65399551391602
2024-07-09 04:01:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.483642578125, gpu time: 316.931001663208
2024-07-09 04:01:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.84423828125, gpu time: 244.8515167236328
2024-07-09 04:01:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2921.0908203125, gpu time: 3314.5290718078613
2024-07-09 04:01:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.446533203125, gpu time: 309.87468814849854
2024-07-09 04:01:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.0712890625, gpu time: 1555.4430294036865
2024-07-09 04:01:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10556.291015625, gpu time: 11146.924312591553
2024-07-09 04:01:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.4052734375, gpu time: 346.5714645385742
2024-07-09 04:01:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.036865234375, gpu time: 194.15348434448242
2024-07-09 04:01:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.848388671875, gpu time: 457.47939682006836
2024-07-09 04:01:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.579345703125, gpu time: 190.54563903808594
2024-07-09 04:01:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.5166015625, gpu time: 353.19161796569824
2024-07-09 04:01:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.489990234375, gpu time: 279.64221382141113
2024-07-09 04:01:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.445556640625, gpu time: 215.68354034423828
2024-07-09 04:01:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.099365234375, gpu time: 383.5650396347046
2024-07-09 04:01:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10557.80322265625, gpu time: 11181.468607902527
2024-07-09 04:01:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.026123046875, gpu time: 234.86145401000977
2024-07-09 04:01:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.681884765625, gpu time: 408.1671028137207
2024-07-09 04:01:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2922.229248046875, gpu time: 3363.54727935791
2024-07-09 04:01:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.77099609375, gpu time: 490.0220947265625
2024-07-09 04:01:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.157958984375, gpu time: 387.88071632385254
2024-07-09 04:01:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.0908203125, gpu time: 1615.566349029541
2024-07-09 04:01:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.037109375, gpu time: 317.3509883880615
2024-07-09 04:01:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.138916015625, gpu time: 436.54388332366943
2024-07-09 04:01:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.446533203125, gpu time: 243.8820915222168
2024-07-09 04:01:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10559.361572265625, gpu time: 11227.538979530334
2024-07-09 04:01:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.026123046875, gpu time: 261.5204734802246
2024-07-09 04:01:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.288818359375, gpu time: 437.7514019012451
2024-07-09 04:01:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.81640625, gpu time: 519.301435470581
2024-07-09 04:01:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.78369140625, gpu time: 284.6815757751465
2024-07-09 04:01:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.822998046875, gpu time: 431.8907661437988
2024-07-09 04:01:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.399169921875, gpu time: 345.81400966644287
2024-07-09 04:01:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.034912109375, gpu time: 386.85720443725586
2024-07-09 04:01:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.796875, gpu time: 482.3100919723511
2024-07-09 04:01:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2923.32177734375, gpu time: 3409.385488510132
2024-07-09 04:01:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10560.142578125, gpu time: 11255.06568145752
2024-07-09 04:01:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.799560546875, gpu time: 468.63954162597656
2024-07-09 04:01:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.149658203125, gpu time: 1669.0111122131348
2024-07-09 04:01:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.6611328125, gpu time: 551.5018930435181
2024-07-09 04:01:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.23193359375, gpu time: 466.0205020904541
2024-07-09 04:01:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.891357421875, gpu time: 437.4525337219238
2024-07-09 04:01:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.7744140625, gpu time: 380.92854499816895
2024-07-09 04:01:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.707275390625, gpu time: 520.1574277877808
2024-07-09 04:01:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.704833984375, gpu time: 329.80859375
2024-07-09 04:01:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10560.942138671875, gpu time: 11307.690128326416
2024-07-09 04:01:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.11962890625, gpu time: 388.3120651245117
2024-07-09 04:01:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.18115234375, gpu time: 504.39999771118164
2024-07-09 04:01:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.280517578125, gpu time: 588.8426694869995
2024-07-09 04:01:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.25146484375, gpu time: 438.510929107666
2024-07-09 04:01:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.368408203125, gpu time: 526.9371032714844
2024-07-09 04:01:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2924.45166015625, gpu time: 3459.5641746520996
2024-07-09 04:01:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.148193359375, gpu time: 415.67236328125
2024-07-09 04:01:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.029052734375, gpu time: 555.1202840805054
2024-07-09 04:01:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.476806640625, gpu time: 1732.75315284729
2024-07-09 04:01:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10561.91796875, gpu time: 11342.599064826965
2024-07-09 04:01:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.831787109375, gpu time: 480.85522270202637
2024-07-09 04:01:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.770263671875, gpu time: 539.7826948165894
2024-07-09 04:01:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.436767578125, gpu time: 629.565203666687
2024-07-09 04:01:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.03466796875, gpu time: 387.7171974182129
2024-07-09 04:01:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.302490234375, gpu time: 563.6894016265869
2024-07-09 04:01:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.525146484375, gpu time: 436.968355178833
2024-07-09 04:01:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.8740234375, gpu time: 470.7657661437988
2024-07-09 04:01:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.90869140625, gpu time: 595.4685792922974
2024-07-09 04:01:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.7705078125, gpu time: 505.8708839416504
2024-07-09 04:01:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10562.2900390625, gpu time: 11395.19631099701
2024-07-09 04:01:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2924.880615234375, gpu time: 3524.575336456299
2024-07-09 04:01:27 | INFO | fairseq_cli.eval_lm | load time: 227.08 seconds
2024-07-09 04:01:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.29296875, gpu time: 603.4868173599243
2024-07-09 04:01:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.378173828125, gpu time: 681.7806911468506
2024-07-09 04:01:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.1025390625, gpu time: 1784.9030418395996
2024-07-09 04:01:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.669677734375, gpu time: 603.5176954269409
2024-07-09 04:01:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.242431640625, gpu time: 528.9358348846436
2024-07-09 04:01:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.577392578125, gpu time: 528.224292755127
2024-07-09 04:01:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.52587890625, gpu time: 633.7776765823364
2024-07-09 04:01:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.35986328125, gpu time: 454.04259490966797
2024-07-09 04:01:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10562.657958984375, gpu time: 11447.398999214172
2024-07-09 04:01:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.85498046875, gpu time: 497.7271976470947
2024-07-09 04:01:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.1083984375, gpu time: 647.1167116165161
2024-07-09 04:01:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.746337890625, gpu time: 724.0609855651855
2024-07-09 04:01:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.140625, gpu time: 575.5753192901611
2024-07-09 04:01:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.618896484375, gpu time: 654.8523817062378
2024-07-09 04:01:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2925.306640625, gpu time: 3593.8028144836426
2024-07-09 04:01:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.756103515625, gpu time: 563.8313093185425
2024-07-09 04:01:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.33984375, gpu time: 661.185019493103
2024-07-09 04:01:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.38525390625, gpu time: 1836.5199699401855
2024-07-09 04:01:30 | INFO | fairseq_cli.eval_lm | load time: 230.76 seconds
2024-07-09 04:01:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10563.3759765625, gpu time: 11500.305846214294
2024-07-09 04:01:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.205810546875, gpu time: 579.0359649658203
2024-07-09 04:01:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.462646484375, gpu time: 678.4998912811279
2024-07-09 04:01:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.30810546875, gpu time: 759.2494430541992
2024-07-09 04:01:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.695556640625, gpu time: 518.096155166626
2024-07-09 04:01:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.358642578125, gpu time: 705.7206687927246
2024-07-09 04:01:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.245361328125, gpu time: 554.5670032501221
2024-07-09 04:01:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.7255859375, gpu time: 609.7839221954346
2024-07-09 04:01:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.207763671875, gpu time: 689.8378009796143
2024-07-09 04:01:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.54052734375, gpu time: 651.4749565124512
2024-07-09 04:01:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10564.809326171875, gpu time: 11547.186615943909
2024-07-09 04:01:33 | INFO | fairseq_cli.eval_lm | load time: 233.17 seconds
2024-07-09 04:01:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2926.166748046875, gpu time: 3646.163261413574
2024-07-09 04:01:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.930908203125, gpu time: 707.892993927002
2024-07-09 04:01:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.30029296875, gpu time: 793.8135814666748
2024-07-09 04:01:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.71728515625, gpu time: 1903.3188095092773
2024-07-09 04:01:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.722900390625, gpu time: 763.160472869873
2024-07-09 04:01:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.083984375, gpu time: 657.6928787231445
2024-07-09 04:01:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.35693359375, gpu time: 665.3050079345703
2024-07-09 04:01:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.541259765625, gpu time: 748.0088081359863
2024-07-09 04:01:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.351806640625, gpu time: 572.3230037689209
2024-07-09 04:01:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10566.000732421875, gpu time: 11581.32595539093
2024-07-09 04:01:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.012939453125, gpu time: 615.668888092041
2024-07-09 04:01:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.286865234375, gpu time: 743.7123308181763
2024-07-09 04:01:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.67431640625, gpu time: 850.6290693283081
2024-07-09 04:01:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.760498046875, gpu time: 889.9776830673218
2024-07-09 04:01:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.875244140625, gpu time: 902.3828201293945
2024-07-09 04:01:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.72265625, gpu time: 703.4446668624878
2024-07-09 04:01:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.904541015625, gpu time: 783.4723052978516
2024-07-09 04:01:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2927.31591796875, gpu time: 3858.1065063476562
2024-07-09 04:01:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10566.3671875, gpu time: 11633.269125938416
2024-07-09 04:01:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.049560546875, gpu time: 1971.8981285095215
2024-07-09 04:01:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.974609375, gpu time: 768.8337564468384
2024-07-09 04:01:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.8095703125, gpu time: 882.3783311843872
2024-07-09 04:01:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.4287109375, gpu time: 866.151008605957
2024-07-09 04:01:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.425048828125, gpu time: 949.782130241394
2024-07-09 04:01:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.877685546875, gpu time: 782.355185508728
2024-07-09 04:01:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.689453125, gpu time: 689.1327037811279
2024-07-09 04:01:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.472900390625, gpu time: 807.9950103759766
2024-07-09 04:01:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10567.1171875, gpu time: 11676.426383018494
2024-07-09 04:01:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.344482421875, gpu time: 790.1038360595703
2024-07-09 04:01:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.479248046875, gpu time: 809.0578947067261
2024-07-09 04:01:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.61083984375, gpu time: 909.5581560134888
2024-07-09 04:01:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.83056640625, gpu time: 999.8067455291748
2024-07-09 04:01:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.245361328125, gpu time: 1276.857192993164
2024-07-09 04:01:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.922119140625, gpu time: 858.3047475814819
2024-07-09 04:01:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.8134765625, gpu time: 872.504415512085
2024-07-09 04:01:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10567.965087890625, gpu time: 11702.476927757263
2024-07-09 04:01:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2927.719482421875, gpu time: 4420.560150146484
2024-07-09 04:01:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.324951171875, gpu time: 844.9437952041626
2024-07-09 04:01:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.969482421875, gpu time: 982.7737951278687
2024-07-09 04:01:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.197265625, gpu time: 1033.5761680603027
2024-07-09 04:01:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.58349609375, gpu time: 2290.299571990967
2024-07-09 04:01:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.449951171875, gpu time: 917.2973546981812
2024-07-09 04:01:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.787841796875, gpu time: 931.312894821167
2024-07-09 04:01:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.14501953125, gpu time: 908.5247182846069
2024-07-09 04:01:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10568.332763671875, gpu time: 11731.744590759277
2024-07-09 04:01:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.00927734375, gpu time: 736.1621208190918
2024-07-09 04:01:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.810546875, gpu time: 900.3205652236938
2024-07-09 04:01:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.670166015625, gpu time: 834.9785308837891
2024-07-09 04:01:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.0595703125, gpu time: 1013.2651386260986
2024-07-09 04:01:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.314453125, gpu time: 1084.1423835754395
2024-07-09 04:01:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.5595703125, gpu time: 1387.4213008880615
2024-07-09 04:01:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.09619140625, gpu time: 954.9992542266846
2024-07-09 04:01:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2928.86474609375, gpu time: 4478.336923599243
2024-07-09 04:01:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.9541015625, gpu time: 939.7170219421387
2024-07-09 04:01:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10568.70849609375, gpu time: 11755.8495388031
2024-07-09 04:01:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.020751953125, gpu time: 2353.76065826416
2024-07-09 04:01:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.178955078125, gpu time: 935.7170267105103
2024-07-09 04:01:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.109130859375, gpu time: 986.6973495483398
2024-07-09 04:01:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.89794921875, gpu time: 1043.9968032836914
2024-07-09 04:01:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.10595703125, gpu time: 1112.0546884536743
2024-07-09 04:01:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.340576171875, gpu time: 780.6790580749512
2024-07-09 04:01:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.764404296875, gpu time: 989.987717628479
2024-07-09 04:01:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.005615234375, gpu time: 903.7333793640137
2024-07-09 04:01:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.501708984375, gpu time: 972.6075639724731
2024-07-09 04:01:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10569.34033203125, gpu time: 11787.824882507324
2024-07-09 04:01:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.878662109375, gpu time: 1444.8926334381104
2024-07-09 04:01:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.539306640625, gpu time: 977.2547674179077
2024-07-09 04:01:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.2666015625, gpu time: 1078.383825302124
2024-07-09 04:01:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2929.212890625, gpu time: 4551.247131347656
2024-07-09 04:01:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.463623046875, gpu time: 1156.1762685775757
2024-07-09 04:01:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.6787109375, gpu time: 2467.252290725708
2024-07-09 04:01:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.22705078125, gpu time: 1038.791054725647
2024-07-09 04:01:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.8720703125, gpu time: 1003.5637121200562
2024-07-09 04:01:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.431396484375, gpu time: 1076.2857933044434
2024-07-09 04:01:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10570.220703125, gpu time: 11851.687572479248
2024-07-09 04:01:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.328369140625, gpu time: 841.2894306182861
2024-07-09 04:01:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.9130859375, gpu time: 1001.6857967376709
2024-07-09 04:01:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.716552734375, gpu time: 1103.2786931991577
2024-07-09 04:01:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.325927734375, gpu time: 955.4643955230713
2024-07-09 04:01:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.334228515625, gpu time: 1210.3045654296875
2024-07-09 04:01:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.197509765625, gpu time: 1514.7438068389893
2024-07-09 04:01:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.842529296875, gpu time: 1066.890881538391
2024-07-09 04:01:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.2392578125, gpu time: 1039.3568172454834
2024-07-09 04:01:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2929.58837890625, gpu time: 4619.882621765137
2024-07-09 04:01:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10570.846923828125, gpu time: 11906.52626991272
2024-07-09 04:01:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.9921875, gpu time: 2541.519941329956
2024-07-09 04:01:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.443603515625, gpu time: 1052.7856149673462
2024-07-09 04:01:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.045654296875, gpu time: 1156.860909461975
2024-07-09 04:01:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.7890625, gpu time: 1197.8563041687012
2024-07-09 04:01:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.701171875, gpu time: 1245.4047117233276
2024-07-09 04:01:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.794921875, gpu time: 893.6722888946533
2024-07-09 04:01:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.566162109375, gpu time: 1115.7585411071777
2024-07-09 04:01:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.08984375, gpu time: 1064.3768062591553
2024-07-09 04:01:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.66259765625, gpu time: 1010.974292755127
2024-07-09 04:01:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10571.4501953125, gpu time: 11938.783535003662
2024-07-09 04:01:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.678466796875, gpu time: 1593.5047397613525
2024-07-09 04:01:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.417236328125, gpu time: 1092.0804796218872
2024-07-09 04:01:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.876708984375, gpu time: 1182.0436191558838
2024-07-09 04:01:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2930.767333984375, gpu time: 4667.765962600708
2024-07-09 04:01:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.74658203125, gpu time: 1297.6773290634155
2024-07-09 04:01:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.808349609375, gpu time: 2608.300395965576
2024-07-09 04:01:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.414794921875, gpu time: 1166.2935609817505
2024-07-09 04:01:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.53369140625, gpu time: 1096.4435138702393
2024-07-09 04:01:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.1171875, gpu time: 1248.0319652557373
2024-07-09 04:01:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10572.101806640625, gpu time: 11976.160962104797
2024-07-09 04:01:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.175048828125, gpu time: 943.01930809021
2024-07-09 04:01:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.54736328125, gpu time: 1119.0643100738525
2024-07-09 04:01:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.683349609375, gpu time: 1215.7396049499512
2024-07-09 04:01:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.087890625, gpu time: 1087.6888236999512
2024-07-09 04:01:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.513671875, gpu time: 1324.9192390441895
2024-07-09 04:01:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.73095703125, gpu time: 1203.2261896133423
2024-07-09 04:01:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.032470703125, gpu time: 1659.3903179168701
2024-07-09 04:01:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.480712890625, gpu time: 1137.5471801757812
2024-07-09 04:01:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2931.152099609375, gpu time: 4763.406892776489
2024-07-09 04:01:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10573.13134765625, gpu time: 12020.07470703125
2024-07-09 04:01:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.05810546875, gpu time: 1164.0044555664062
2024-07-09 04:01:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.811767578125, gpu time: 2693.0546073913574
2024-07-09 04:01:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.07275390625, gpu time: 1257.2522277832031
2024-07-09 04:01:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.4384765625, gpu time: 1316.403621673584
2024-07-09 04:01:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.37451171875, gpu time: 1377.2515439987183
2024-07-09 04:01:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.3740234375, gpu time: 1239.946177482605
2024-07-09 04:01:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.525390625, gpu time: 1032.685998916626
2024-07-09 04:01:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.728515625, gpu time: 1174.900447845459
2024-07-09 04:01:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.41162109375, gpu time: 1156.9953651428223
2024-07-09 04:01:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10573.52734375, gpu time: 12050.875495910645
2024-07-09 04:02:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.996826171875, gpu time: 1193.6540460586548
2024-07-09 04:02:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.357666015625, gpu time: 1785.1806888580322
2024-07-09 04:02:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.170654296875, gpu time: 1299.4533348083496
2024-07-09 04:02:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.06982421875, gpu time: 1401.757776260376
2024-07-09 04:02:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2931.74267578125, gpu time: 4861.399187088013
2024-07-09 04:02:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.9345703125, gpu time: 1295.4871225357056
2024-07-09 04:02:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.15478515625, gpu time: 2763.3313941955566
2024-07-09 04:02:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.189453125, gpu time: 1201.2253999710083
2024-07-09 04:02:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10573.911865234375, gpu time: 12076.075807571411
2024-07-09 04:02:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.787109375, gpu time: 1393.952236175537
2024-07-09 04:02:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.37109375, gpu time: 1250.908911705017
2024-07-09 04:02:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.8916015625, gpu time: 1106.3704586029053
2024-07-09 04:02:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.437744140625, gpu time: 1343.7413234710693
2024-07-09 04:02:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.99169921875, gpu time: 1447.1624011993408
2024-07-09 04:02:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.80810546875, gpu time: 1232.669906616211
2024-07-09 04:02:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.746826171875, gpu time: 1331.9379920959473
2024-07-09 04:02:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.941162109375, gpu time: 1833.2168369293213
2024-07-09 04:02:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.7216796875, gpu time: 1247.2925882339478
2024-07-09 04:02:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10574.2900390625, gpu time: 12101.246520996094
2024-07-09 04:02:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2932.21533203125, gpu time: 4927.143814086914
2024-07-09 04:02:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.08984375, gpu time: 1278.3975448608398
2024-07-09 04:02:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.562255859375, gpu time: 2814.8558616638184
2024-07-09 04:02:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.000244140625, gpu time: 1391.966272354126
2024-07-09 04:02:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.062744140625, gpu time: 1481.549753189087
2024-07-09 04:02:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.111328125, gpu time: 1474.7602195739746
2024-07-09 04:02:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.12890625, gpu time: 1367.0282249450684
2024-07-09 04:02:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.27978515625, gpu time: 1170.4754066467285
2024-07-09 04:02:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.413330078125, gpu time: 1297.8650579452515
2024-07-09 04:02:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10574.680419921875, gpu time: 12138.841873168945
2024-07-09 04:02:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.7490234375, gpu time: 1303.0060501098633
2024-07-09 04:02:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.446533203125, gpu time: 1329.1567344665527
2024-07-09 04:02:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.25732421875, gpu time: 1884.4141063690186
2024-07-09 04:02:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.386474609375, gpu time: 1425.6598653793335
2024-07-09 04:02:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.275634765625, gpu time: 1519.2961444854736
2024-07-09 04:02:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2932.60888671875, gpu time: 4992.761880874634
2024-07-09 04:02:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.8603515625, gpu time: 1418.6157321929932
2024-07-09 04:02:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.894287109375, gpu time: 2894.3883266448975
2024-07-09 04:02:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.82080078125, gpu time: 1354.5253648757935
2024-07-09 04:02:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10575.56689453125, gpu time: 12177.857864379883
2024-07-09 04:02:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.279296875, gpu time: 1556.0659637451172
2024-07-09 04:02:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.352294921875, gpu time: 1370.10888671875
2024-07-09 04:02:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.605712890625, gpu time: 1235.0929946899414
2024-07-09 04:02:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.59765625, gpu time: 1458.4382600784302
2024-07-09 04:02:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.0166015625, gpu time: 1553.0263757705688
2024-07-09 04:02:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.103515625, gpu time: 1361.527479171753
2024-07-09 04:02:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.6552734375, gpu time: 1453.6264457702637
2024-07-09 04:02:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.2353515625, gpu time: 1385.6560792922974
2024-07-09 04:02:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.588623046875, gpu time: 1953.3176136016846
2024-07-09 04:02:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10576.1474609375, gpu time: 12217.390655517578
2024-07-09 04:02:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2933.080322265625, gpu time: 5092.451623916626
2024-07-09 04:02:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.005126953125, gpu time: 1411.883602142334
2024-07-09 04:02:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.166015625, gpu time: 1488.081295967102
2024-07-09 04:02:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.227294921875, gpu time: 2949.123998641968
2024-07-09 04:02:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.54150390625, gpu time: 1590.7940483093262
2024-07-09 04:02:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.603271484375, gpu time: 1610.3187580108643
2024-07-09 04:02:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.6591796875, gpu time: 1507.3625965118408
2024-07-09 04:02:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.60986328125, gpu time: 1418.970314025879
2024-07-09 04:02:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.98486328125, gpu time: 1315.015863418579
2024-07-09 04:02:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10576.916259765625, gpu time: 12280.09720993042
2024-07-09 04:02:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.432861328125, gpu time: 1426.647792816162
2024-07-09 04:02:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.738037109375, gpu time: 1454.6242361068726
2024-07-09 04:02:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.4580078125, gpu time: 1522.2030515670776
2024-07-09 04:02:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.909912109375, gpu time: 2019.0240058898926
2024-07-09 04:02:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.21826171875, gpu time: 1643.0750007629395
2024-07-09 04:02:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2933.476318359375, gpu time: 5158.588417053223
2024-07-09 04:02:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.378662109375, gpu time: 1549.5000324249268
2024-07-09 04:02:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.98095703125, gpu time: 1461.9957485198975
2024-07-09 04:02:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.6171875, gpu time: 3023.0894317626953
2024-07-09 04:02:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10577.42333984375, gpu time: 12313.643927574158
2024-07-09 04:02:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.954833984375, gpu time: 1680.0910739898682
2024-07-09 04:02:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.127197265625, gpu time: 1507.4354333877563
2024-07-09 04:02:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.60986328125, gpu time: 1559.7292852401733
2024-07-09 04:02:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.309814453125, gpu time: 1422.0840091705322
2024-07-09 04:02:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.7490234375, gpu time: 1673.0509977340698
2024-07-09 04:02:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.75048828125, gpu time: 1478.179786682129
2024-07-09 04:02:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.75244140625, gpu time: 1588.9089879989624
2024-07-09 04:02:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.373046875, gpu time: 1502.8141450881958
2024-07-09 04:02:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.031005859375, gpu time: 2067.4544010162354
2024-07-09 04:02:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10577.796630859375, gpu time: 12391.799761772156
2024-07-09 04:02:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2933.8916015625, gpu time: 5213.5868129730225
2024-07-09 04:02:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.503173828125, gpu time: 1540.8874311447144
2024-07-09 04:02:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.60400390625, gpu time: 1596.622241973877
2024-07-09 04:02:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.953125, gpu time: 3072.2025508880615
2024-07-09 04:02:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.410400390625, gpu time: 1727.428596496582
2024-07-09 04:02:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.271728515625, gpu time: 1752.7134685516357
2024-07-09 04:02:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.27734375, gpu time: 1657.0649843215942
2024-07-09 04:02:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.736083984375, gpu time: 1527.3352632522583
2024-07-09 04:02:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.6728515625, gpu time: 1474.7489681243896
2024-07-09 04:02:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10578.549072265625, gpu time: 12444.001997947693
2024-07-09 04:02:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.071044921875, gpu time: 1549.8985061645508
2024-07-09 04:02:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.982421875, gpu time: 1582.5256700515747
2024-07-09 04:02:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.107421875, gpu time: 1639.1798391342163
2024-07-09 04:02:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.415771484375, gpu time: 2153.998239517212
2024-07-09 04:02:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.333740234375, gpu time: 1756.2764348983765
2024-07-09 04:02:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2934.398681640625, gpu time: 5276.486333847046
2024-07-09 04:02:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.575439453125, gpu time: 1688.5953855514526
2024-07-09 04:02:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.1064453125, gpu time: 1571.2024641036987
2024-07-09 04:02:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.34716796875, gpu time: 3135.7835083007812
2024-07-09 04:02:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10579.29248046875, gpu time: 12495.654797554016
2024-07-09 04:02:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.60498046875, gpu time: 1831.8432292938232
2024-07-09 04:02:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.344482421875, gpu time: 1643.63623046875
2024-07-09 04:02:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.679931640625, gpu time: 1671.5548791885376
2024-07-09 04:02:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.00439453125, gpu time: 1558.1420879364014
2024-07-09 04:02:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.84619140625, gpu time: 1789.517234802246
2024-07-09 04:02:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.391357421875, gpu time: 1606.6481075286865
2024-07-09 04:02:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.87353515625, gpu time: 1720.5222644805908
2024-07-09 04:02:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.74853515625, gpu time: 1597.607265472412
2024-07-09 04:02:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.839599609375, gpu time: 2209.042079925537
2024-07-09 04:02:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10580.66455078125, gpu time: 12554.186955451965
2024-07-09 04:02:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2934.8740234375, gpu time: 5341.880254745483
2024-07-09 04:02:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.061279296875, gpu time: 1686.4312715530396
2024-07-09 04:02:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.434814453125, gpu time: 1700.4379196166992
2024-07-09 04:02:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.677001953125, gpu time: 3283.1036682128906
2024-07-09 04:02:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.77490234375, gpu time: 1851.3573961257935
2024-07-09 04:02:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.37353515625, gpu time: 1750.3142642974854
2024-07-09 04:02:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.930419921875, gpu time: 1962.789161682129
2024-07-09 04:02:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.4912109375, gpu time: 1658.6711082458496
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:02:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.354248046875, gpu time: 1612.5051288604736
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-07-09 04:02:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10581.233642578125, gpu time: 12584.764235496521
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:02:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.065673828125, gpu time: 1715.178952217102
2024-07-09 04:02:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.057861328125, gpu time: 1695.1253986358643
2024-07-09 04:02:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.957763671875, gpu time: 1753.2876834869385
2024-07-09 04:02:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.1484375, gpu time: 2263.104164123535
2024-07-09 04:02:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.39599609375, gpu time: 1883.3641204833984
2024-07-09 04:02:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.333740234375, gpu time: 1781.2661066055298
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:02:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2935.34228515625, gpu time: 5435.244100570679
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-07-09 04:02:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.21923828125, gpu time: 1703.5994329452515
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:02:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.02978515625, gpu time: 3373.583034515381
2024-07-09 04:02:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10581.859619140625, gpu time: 12615.966157913208
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:02:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.4140625, gpu time: 1748.017674446106
2024-07-09 04:02:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.365234375, gpu time: 2027.2259674072266
2024-07-09 04:02:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.342529296875, gpu time: 1788.589126586914
2024-07-09 04:02:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.9599609375, gpu time: 1913.2807636260986
2024-07-09 04:02:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.6767578125, gpu time: 1739.557622909546
2024-07-09 04:02:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.85693359375, gpu time: 1939.8882036209106
2024-07-09 04:02:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.386474609375, gpu time: 1987.1782245635986
2024-07-09 04:02:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.978759765625, gpu time: 1820.8866415023804
2024-07-09 04:02:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10582.43310546875, gpu time: 12643.158640861511
2024-07-09 04:02:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.47509765625, gpu time: 2503.767879486084
2024-07-09 04:02:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.934326171875, gpu time: 1829.7279253005981
2024-07-09 04:02:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2936.484375, gpu time: 5666.541900634766
2024-07-09 04:02:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.1572265625, gpu time: 1883.2305736541748
2024-07-09 04:02:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.67236328125, gpu time: 1942.1730880737305
2024-07-09 04:02:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.35205078125, gpu time: 3463.5072059631348
2024-07-09 04:02:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.347900390625, gpu time: 2017.8602142333984
W0709 04:02:31.037272 140357240219456 torch/multiprocessing/spawn.py:145] Terminating process 136897 via signal SIGTERM
W0709 04:02:31.037871 140357240219456 torch/multiprocessing/spawn.py:145] Terminating process 136899 via signal SIGTERM
W0709 04:02:31.038274 140357240219456 torch/multiprocessing/spawn.py:145] Terminating process 136901 via signal SIGTERM
2024-07-09 04:02:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.68359375, gpu time: 2165.152545928955
2024-07-09 04:02:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.823974609375, gpu time: 1853.6999254226685
2024-07-09 04:02:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10583.7470703125, gpu time: 12722.744730949402
W0709 04:02:31.748400 139888380602176 torch/multiprocessing/spawn.py:145] Terminating process 136898 via signal SIGTERM
W0709 04:02:31.749047 139888380602176 torch/multiprocessing/spawn.py:145] Terminating process 136900 via signal SIGTERM
W0709 04:02:31.749210 139888380602176 torch/multiprocessing/spawn.py:145] Terminating process 136905 via signal SIGTERM
W0709 04:02:31.804224 139752973477696 torch/multiprocessing/spawn.py:145] Terminating process 136908 via signal SIGTERM
W0709 04:02:31.856055 139752973477696 torch/multiprocessing/spawn.py:145] Terminating process 136913 via signal SIGTERM
W0709 04:02:31.856176 139752973477696 torch/multiprocessing/spawn.py:145] Terminating process 136914 via signal SIGTERM
2024-07-09 04:02:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.00048828125, gpu time: 1958.4355907440186
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 197, in top2gating
    combine2_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 3.47 GiB is free. Of the allocated memory 11.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2024-07-09 04:02:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.8359375, gpu time: 1907.471459388733
2024-07-09 04:02:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.822265625, gpu time: 2117.129762649536
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 2 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 197, in top2gating
    combine2_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 3.33 GiB is free. Of the allocated memory 11.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2024-07-09 04:02:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.652587890625, gpu time: 1913.1291389465332
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 37 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 197, in top2gating
    combine2_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 3.28 GiB is free. Of the allocated memory 11.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

srun: error: t004-005: task 0: Exited with exit code 1
2024-07-09 04:02:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.16162109375, gpu time: 1994.2199802398682
2024-07-09 04:02:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.8115234375, gpu time: 2606.300699234009
srun: error: t004-005: task 3: Exited with exit code 1
2024-07-09 04:02:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.74560546875, gpu time: 2068.6218242645264
2024-07-09 04:02:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2936.8623046875, gpu time: 5722.6745529174805
2024-07-09 04:02:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.201416015625, gpu time: 1889.634651184082
2024-07-09 04:02:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10584.126708984375, gpu time: 12750.914814949036
2024-07-09 04:02:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.67529296875, gpu time: 3510.2020950317383
2024-07-09 04:02:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.21923828125, gpu time: 1943.8010654449463
2024-07-09 04:02:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.005859375, gpu time: 2239.0867977142334
2024-07-09 04:02:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.341796875, gpu time: 1956.640027999878
2024-07-09 04:02:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.515380859375, gpu time: 2034.5363082885742
2024-07-09 04:02:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.325927734375, gpu time: 2036.1818447113037
2024-07-09 04:02:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.876220703125, gpu time: 2127.795274734497
srun: error: t004-005: task 2: Exited with exit code 1
2024-07-09 04:02:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.663330078125, gpu time: 2176.5488147735596
2024-07-09 04:02:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.577392578125, gpu time: 1918.129056930542
2024-07-09 04:02:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10584.786865234375, gpu time: 12783.522500991821
2024-07-09 04:02:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.133544921875, gpu time: 2676.2421531677246
2024-07-09 04:02:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.265380859375, gpu time: 1994.2820348739624
2024-07-09 04:02:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2937.236083984375, gpu time: 5792.947044372559
2024-07-09 04:02:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.725341796875, gpu time: 1991.9312343597412
2024-07-09 04:02:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.37646484375, gpu time: 2061.998713493347
2024-07-09 04:02:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.1826171875, gpu time: 3580.9381103515625
2024-07-09 04:02:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.336669921875, gpu time: 2176.7917671203613
2024-07-09 04:02:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.497802734375, gpu time: 2311.2653732299805
2024-07-09 04:02:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.334716796875, gpu time: 1953.3341836929321
2024-07-09 04:02:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10585.256591796875, gpu time: 12820.027629852295
2024-07-09 04:02:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.64697265625, gpu time: 2091.691457748413
2024-07-09 04:02:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.82958984375, gpu time: 2039.307804107666
2024-07-09 04:02:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.99658203125, gpu time: 2226.6101055145264
2024-07-09 04:02:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.1123046875, gpu time: 2020.051721572876
2024-07-09 04:02:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.652587890625, gpu time: 2102.8436822891235
2024-07-09 04:02:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.4482421875, gpu time: 2761.701057434082
2024-07-09 04:02:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.8818359375, gpu time: 2229.0460205078125
2024-07-09 04:02:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2937.614013671875, gpu time: 5856.614421844482
2024-07-09 04:02:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.73388671875, gpu time: 1994.2373914718628
2024-07-09 04:02:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10586.353271484375, gpu time: 12854.849238395691
2024-07-09 04:02:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.49951171875, gpu time: 3669.7821350097656
2024-07-09 04:02:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.111572265625, gpu time: 2084.0986976623535
2024-07-09 04:02:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.82958984375, gpu time: 2377.9041137695312
2024-07-09 04:02:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.971923828125, gpu time: 2068.9470911026
2024-07-09 04:02:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.09375, gpu time: 2130.177610397339
2024-07-09 04:02:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.966552734375, gpu time: 2159.6748371124268
2024-07-09 04:02:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.4365234375, gpu time: 2286.5865154266357
2024-07-09 04:02:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.42236328125, gpu time: 2292.666124343872
2024-07-09 04:02:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.19677734375, gpu time: 2036.7570838928223
2024-07-09 04:02:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10587.259765625, gpu time: 12886.267806053162
2024-07-09 04:02:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.840576171875, gpu time: 2811.1817150115967
2024-07-09 04:02:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.997802734375, gpu time: 2136.217752456665
2024-07-09 04:02:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2938.005859375, gpu time: 5935.295404434204
2024-07-09 04:02:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.20849609375, gpu time: 2110.781184196472
2024-07-09 04:02:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.444580078125, gpu time: 2157.0856189727783
2024-07-09 04:02:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.866455078125, gpu time: 3742.6647186279297
2024-07-09 04:02:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.817626953125, gpu time: 2325.3015670776367
2024-07-09 04:02:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.246826171875, gpu time: 2423.916130065918
2024-07-09 04:02:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.1962890625, gpu time: 2066.6644525527954
2024-07-09 04:02:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10588.412109375, gpu time: 12921.543177604675
2024-07-09 04:02:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.296142578125, gpu time: 2255.171350479126
2024-07-09 04:02:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.861572265625, gpu time: 2188.055687904358
2024-07-09 04:02:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.754638671875, gpu time: 2370.154951095581
2024-07-09 04:02:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.587890625, gpu time: 2161.8402404785156
2024-07-09 04:02:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.822998046875, gpu time: 2226.386444091797
2024-07-09 04:02:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.15966796875, gpu time: 2937.5006370544434
2024-07-09 04:02:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.331787109375, gpu time: 2360.936619758606
2024-07-09 04:02:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.98193359375, gpu time: 2110.0467081069946
2024-07-09 04:02:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2938.44873046875, gpu time: 6061.866811752319
2024-07-09 04:02:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10588.88427734375, gpu time: 12955.106709480286
2024-07-09 04:02:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.906982421875, gpu time: 3804.1489028930664
2024-07-09 04:02:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.25390625, gpu time: 2238.9945878982544
2024-07-09 04:02:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.783203125, gpu time: 2194.0098514556885
2024-07-09 04:02:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.73779296875, gpu time: 2491.3739166259766
2024-07-09 04:02:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.474609375, gpu time: 2284.138624191284
2024-07-09 04:02:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.673583984375, gpu time: 2309.784809112549
2024-07-09 04:02:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.704345703125, gpu time: 2391.903190612793
2024-07-09 04:02:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.672607421875, gpu time: 2140.955518722534
2024-07-09 04:02:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.083251953125, gpu time: 2430.0354537963867
2024-07-09 04:02:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10589.277099609375, gpu time: 13006.72928905487
2024-07-09 04:02:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.484130859375, gpu time: 3000.6227416992188
2024-07-09 04:02:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.63916015625, gpu time: 2294.877007484436
2024-07-09 04:02:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.3984375, gpu time: 2225.016583442688
2024-07-09 04:02:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2938.90625, gpu time: 6120.469074249268
2024-07-09 04:02:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.675048828125, gpu time: 2315.1829557418823
2024-07-09 04:02:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.26513671875, gpu time: 3869.628128051758
2024-07-09 04:02:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.081787109375, gpu time: 2452.5374546051025
2024-07-09 04:02:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.601806640625, gpu time: 2169.1449699401855
2024-07-09 04:02:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.60400390625, gpu time: 2565.135389328003
2024-07-09 04:02:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10589.742919921875, gpu time: 13065.693150520325
2024-07-09 04:02:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.987060546875, gpu time: 2386.2110748291016
2024-07-09 04:02:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.586181640625, gpu time: 2328.296217918396
2024-07-09 04:02:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.33154296875, gpu time: 2253.3865156173706
2024-07-09 04:02:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.401611328125, gpu time: 2515.690532684326
2024-07-09 04:02:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.0517578125, gpu time: 2353.6204118728638
2024-07-09 04:02:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.797607421875, gpu time: 3051.5840435028076
2024-07-09 04:02:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.461181640625, gpu time: 2486.68194770813
2024-07-09 04:02:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.504638671875, gpu time: 2193.985939025879
2024-07-09 04:02:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2939.377197265625, gpu time: 6213.170391082764
2024-07-09 04:02:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10590.149169921875, gpu time: 13097.624363899231
2024-07-09 04:02:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.843994140625, gpu time: 3937.893274307251
2024-07-09 04:02:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.96728515625, gpu time: 2361.108711242676
2024-07-09 04:02:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.8466796875, gpu time: 2288.7946910858154
2024-07-09 04:02:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.91357421875, gpu time: 2614.1102924346924
2024-07-09 04:02:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.816162109375, gpu time: 2385.491946220398
2024-07-09 04:02:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.30908203125, gpu time: 2443.9120597839355
2024-07-09 04:02:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.870361328125, gpu time: 2537.4154090881348
2024-07-09 04:02:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.959716796875, gpu time: 2219.5365104675293
2024-07-09 04:02:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.827392578125, gpu time: 2565.7553577423096
2024-07-09 04:02:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10590.895263671875, gpu time: 13127.71317768097
2024-07-09 04:02:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.511962890625, gpu time: 2397.939929962158
2024-07-09 04:02:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.210205078125, gpu time: 3120.075912475586
2024-07-09 04:02:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.2060546875, gpu time: 2343.0647945404053
2024-07-09 04:02:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2939.767822265625, gpu time: 6303.7176303863525
2024-07-09 04:02:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.21875, gpu time: 2462.632781982422
2024-07-09 04:02:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.732177734375, gpu time: 2561.755100250244
2024-07-09 04:02:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.168212890625, gpu time: 3981.6340942382812
2024-07-09 04:02:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.354736328125, gpu time: 2256.668685913086
2024-07-09 04:02:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.118408203125, gpu time: 2679.8293647766113
2024-07-09 04:02:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10591.26806640625, gpu time: 13159.54471206665
2024-07-09 04:02:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.65966796875, gpu time: 2436.4146690368652
2024-07-09 04:02:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.035888671875, gpu time: 2507.651288986206
2024-07-09 04:02:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.5849609375, gpu time: 2398.4157009124756
2024-07-09 04:02:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.162841796875, gpu time: 2623.843385696411
2024-07-09 04:02:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.33935546875, gpu time: 2500.3966388702393
2024-07-09 04:02:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.124267578125, gpu time: 2589.9730348587036
2024-07-09 04:02:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.53564453125, gpu time: 3181.8415393829346
2024-07-09 04:02:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.728759765625, gpu time: 2318.085678100586
2024-07-09 04:02:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2940.149658203125, gpu time: 6356.553977966309
2024-07-09 04:02:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10591.820068359375, gpu time: 13205.37353515625
2024-07-09 04:02:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.43017578125, gpu time: 2462.2444410324097
2024-07-09 04:02:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.576904296875, gpu time: 4082.5787811279297
2024-07-09 04:02:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.460693359375, gpu time: 2453.9002075195312
2024-07-09 04:03:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.720947265625, gpu time: 2543.6342582702637
2024-07-09 04:03:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.325439453125, gpu time: 2746.584119796753
2024-07-09 04:03:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.176513671875, gpu time: 2641.5645809173584
2024-07-09 04:03:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.579833984375, gpu time: 2553.593713760376
2024-07-09 04:03:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.38623046875, gpu time: 2350.4498538970947
2024-07-09 04:03:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10592.198486328125, gpu time: 13236.256588935852
2024-07-09 04:03:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.4853515625, gpu time: 2684.604700088501
2024-07-09 04:03:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.8154296875, gpu time: 2493.1942167282104
2024-07-09 04:03:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.824951171875, gpu time: 2491.271265029907
2024-07-09 04:03:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.94189453125, gpu time: 3254.5049362182617
2024-07-09 04:03:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.207275390625, gpu time: 2580.622917175293
2024-07-09 04:03:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2941.241455078125, gpu time: 6419.288089752197
2024-07-09 04:03:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.2578125, gpu time: 2677.9788398742676
2024-07-09 04:03:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.761474609375, gpu time: 2391.8522748947144
2024-07-09 04:03:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.076904296875, gpu time: 4124.205205917358
2024-07-09 04:03:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10592.7109375, gpu time: 13269.825565338135
2024-07-09 04:03:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.777587890625, gpu time: 2537.203360557556
2024-07-09 04:03:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.793212890625, gpu time: 2802.5555114746094
2024-07-09 04:03:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.195068359375, gpu time: 2528.4975242614746
2024-07-09 04:03:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.946533203125, gpu time: 2604.522060394287
2024-07-09 04:03:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.602783203125, gpu time: 2641.479911804199
2024-07-09 04:03:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.9345703125, gpu time: 2704.2174129486084
2024-07-09 04:03:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.60791015625, gpu time: 2739.98184967041
2024-07-09 04:03:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.220947265625, gpu time: 2448.4239892959595
2024-07-09 04:03:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.270263671875, gpu time: 3343.4769859313965
2024-07-09 04:03:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10593.37646484375, gpu time: 13337.832642555237
2024-07-09 04:03:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.171142578125, gpu time: 2563.0988960266113
2024-07-09 04:03:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2941.647705078125, gpu time: 6476.761241912842
2024-07-09 04:03:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.600830078125, gpu time: 2585.1498794555664
2024-07-09 04:03:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.4033203125, gpu time: 4176.5199546813965
2024-07-09 04:03:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.245849609375, gpu time: 2672.562970161438
2024-07-09 04:03:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.41162109375, gpu time: 2737.6164722442627
2024-07-09 04:03:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.111572265625, gpu time: 2874.7723541259766
2024-07-09 04:03:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.557861328125, gpu time: 2496.4977769851685
2024-07-09 04:03:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.269287109375, gpu time: 2664.7676963806152
2024-07-09 04:03:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10594.08251953125, gpu time: 13365.005296707153
2024-07-09 04:03:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.531982421875, gpu time: 2591.636833190918
2024-07-09 04:03:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.942138671875, gpu time: 2787.7097187042236
2024-07-09 04:03:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.95703125, gpu time: 2613.4375772476196
2024-07-09 04:03:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.6123046875, gpu time: 3409.0375003814697
2024-07-09 04:03:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.63818359375, gpu time: 2711.804433822632
2024-07-09 04:03:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.948974609375, gpu time: 2779.938896179199
2024-07-09 04:03:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2942.030029296875, gpu time: 6563.364492416382
2024-07-09 04:03:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.34716796875, gpu time: 2539.457001686096
2024-07-09 04:03:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.73681640625, gpu time: 4219.460618972778
2024-07-09 04:03:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10595.27197265625, gpu time: 13391.199712753296
2024-07-09 04:03:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.892822265625, gpu time: 2628.474615097046
2024-07-09 04:03:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.580322265625, gpu time: 2943.976236343384
2024-07-09 04:03:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.67138671875, gpu time: 2664.6776065826416
2024-07-09 04:03:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.615966796875, gpu time: 2713.997323989868
2024-07-09 04:03:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.998046875, gpu time: 2755.1015796661377
2024-07-09 04:03:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.306884765625, gpu time: 2805.64227104187
2024-07-09 04:03:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.258544921875, gpu time: 2854.144956588745
2024-07-09 04:03:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.5791015625, gpu time: 2574.3216638565063
2024-07-09 04:03:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.941162109375, gpu time: 3462.402332305908
2024-07-09 04:03:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10595.981689453125, gpu time: 13424.121971130371
2024-07-09 04:03:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.095458984375, gpu time: 2656.898952484131
2024-07-09 04:03:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2942.402587890625, gpu time: 6611.326601028442
2024-07-09 04:03:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.055419921875, gpu time: 2715.0704383850098
2024-07-09 04:03:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.137939453125, gpu time: 4275.284494400024
2024-07-09 04:03:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.37890625, gpu time: 2793.8585634231567
2024-07-09 04:03:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.303955078125, gpu time: 2844.929494857788
2024-07-09 04:03:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.029296875, gpu time: 3007.8055572509766
2024-07-09 04:03:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.02197265625, gpu time: 2616.866011619568
2024-07-09 04:03:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.99267578125, gpu time: 2771.6269607543945
2024-07-09 04:03:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10596.732666015625, gpu time: 13457.725190162659
2024-07-09 04:03:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.5419921875, gpu time: 2690.2141733169556
2024-07-09 04:03:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.70751953125, gpu time: 2934.2805309295654
2024-07-09 04:03:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.423095703125, gpu time: 2759.6512660980225
2024-07-09 04:03:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.302490234375, gpu time: 3511.084602355957
2024-07-09 04:03:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.76220703125, gpu time: 2826.004825592041
2024-07-09 04:03:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.552490234375, gpu time: 2876.530156135559
2024-07-09 04:03:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2942.84716796875, gpu time: 6669.714160919189
2024-07-09 04:03:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.408203125, gpu time: 2668.761727333069
2024-07-09 04:03:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.515869140625, gpu time: 4319.151882171631
2024-07-09 04:03:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10597.101806640625, gpu time: 13501.995778083801
2024-07-09 04:03:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.391845703125, gpu time: 2734.69628238678
2024-07-09 04:03:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.39990234375, gpu time: 3078.6489658355713
2024-07-09 04:03:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.802490234375, gpu time: 2789.963444709778
2024-07-09 04:03:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.41748046875, gpu time: 2822.313554763794
2024-07-09 04:03:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.44091796875, gpu time: 2858.5096473693848
2024-07-09 04:03:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.1279296875, gpu time: 2913.5444192886353
2024-07-09 04:03:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.139404296875, gpu time: 3017.2972240448
2024-07-09 04:03:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.76904296875, gpu time: 2717.3318395614624
2024-07-09 04:03:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.70263671875, gpu time: 3573.786724090576
2024-07-09 04:03:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10597.62744140625, gpu time: 13567.44286441803
2024-07-09 04:03:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.913330078125, gpu time: 2807.885293006897
2024-07-09 04:03:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2943.25146484375, gpu time: 6722.407634735107
2024-07-09 04:03:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.369140625, gpu time: 2817.9159440994263
2024-07-09 04:03:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.8603515625, gpu time: 4372.906797409058
2024-07-09 04:03:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.47509765625, gpu time: 2891.1911087036133
2024-07-09 04:03:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.221435546875, gpu time: 2942.4468383789062
2024-07-09 04:03:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.72216796875, gpu time: 3131.6419620513916
2024-07-09 04:03:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.734130859375, gpu time: 2769.1867542266846
2024-07-09 04:03:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.760986328125, gpu time: 2904.09601020813
2024-07-09 04:03:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10598.057861328125, gpu time: 13627.761464118958
2024-07-09 04:03:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.777587890625, gpu time: 2835.015711784363
2024-07-09 04:03:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.531005859375, gpu time: 3157.300199508667
2024-07-09 04:03:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.75634765625, gpu time: 2891.3969526290894
2024-07-09 04:03:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.2138671875, gpu time: 3644.788055419922
2024-07-09 04:03:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.962646484375, gpu time: 2941.0388221740723
2024-07-09 04:03:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.701171875, gpu time: 2975.872302055359
2024-07-09 04:03:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2943.629150390625, gpu time: 6783.8955154418945
2024-07-09 04:03:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.1162109375, gpu time: 2807.994140625
2024-07-09 04:03:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.177978515625, gpu time: 4428.649078369141
2024-07-09 04:03:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10598.43701171875, gpu time: 13660.788045883179
2024-07-09 04:03:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.76025390625, gpu time: 2864.8173332214355
2024-07-09 04:03:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.045654296875, gpu time: 3200.665210723877
2024-07-09 04:03:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.130615234375, gpu time: 2922.336332321167
2024-07-09 04:03:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.09423828125, gpu time: 2960.1608486175537
2024-07-09 04:03:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.437744140625, gpu time: 2973.4327640533447
2024-07-09 04:03:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.275390625, gpu time: 3004.2867221832275
2024-07-09 04:03:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.191162109375, gpu time: 3225.315927505493
2024-07-09 04:03:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.272216796875, gpu time: 2866.0207386016846
2024-07-09 04:03:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.549072265625, gpu time: 3708.8815422058105
2024-07-09 04:03:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10598.822509765625, gpu time: 13694.50855064392
2024-07-09 04:03:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.130615234375, gpu time: 2892.243911743164
2024-07-09 04:03:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2944.057861328125, gpu time: 6854.64116859436
2024-07-09 04:03:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.141845703125, gpu time: 2980.6166915893555
2024-07-09 04:03:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.499755859375, gpu time: 4495.899848937988
2024-07-09 04:03:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.784423828125, gpu time: 3028.710082054138
2024-07-09 04:03:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.422119140625, gpu time: 3028.6707401275635
2024-07-09 04:03:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.36474609375, gpu time: 3248.3818855285645
2024-07-09 04:03:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.591064453125, gpu time: 2925.1411056518555
2024-07-09 04:03:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.412353515625, gpu time: 3022.3815326690674
2024-07-09 04:03:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10599.889892578125, gpu time: 13725.515451431274
2024-07-09 04:03:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.494873046875, gpu time: 2916.4311294555664
2024-07-09 04:03:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.596923828125, gpu time: 3283.90749168396
2024-07-09 04:03:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.5634765625, gpu time: 3037.31001663208
2024-07-09 04:03:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.009765625, gpu time: 3754.094533920288
2024-07-09 04:03:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.14794921875, gpu time: 3060.3395442962646
2024-07-09 04:03:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.140380859375, gpu time: 3066.5702896118164
2024-07-09 04:03:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2945.2451171875, gpu time: 6927.825700759888
2024-07-09 04:03:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.0771484375, gpu time: 2971.9248180389404
2024-07-09 04:03:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.91796875, gpu time: 4554.860692977905
2024-07-09 04:03:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10600.455078125, gpu time: 13774.9577293396
2024-07-09 04:03:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.058349609375, gpu time: 2947.5772314071655
2024-07-09 04:03:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.705810546875, gpu time: 3321.0227394104004
2024-07-09 04:03:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.929443359375, gpu time: 3093.322702407837
2024-07-09 04:03:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.7412109375, gpu time: 3081.8252544403076
2024-07-09 04:03:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.64013671875, gpu time: 3088.2488441467285
2024-07-09 04:03:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.504150390625, gpu time: 3092.7640686035156
2024-07-09 04:03:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.9228515625, gpu time: 3359.8262729644775
2024-07-09 04:03:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.444091796875, gpu time: 3030.954303741455
2024-07-09 04:03:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.975830078125, gpu time: 3809.0108947753906
2024-07-09 04:03:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10601.161376953125, gpu time: 13806.02127456665
2024-07-09 04:03:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.4296875, gpu time: 2976.4206113815308
2024-07-09 04:03:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2945.698486328125, gpu time: 6972.105573654175
2024-07-09 04:03:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.93603515625, gpu time: 3145.259062767029
2024-07-09 04:03:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.3828125, gpu time: 4614.207777023315
2024-07-09 04:03:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.023193359375, gpu time: 3122.7367095947266
2024-07-09 04:03:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.48046875, gpu time: 3119.2460079193115
2024-07-09 04:03:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.0380859375, gpu time: 3384.802146911621
2024-07-09 04:03:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.808349609375, gpu time: 3088.688428878784
2024-07-09 04:03:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.10986328125, gpu time: 3142.9267406463623
2024-07-09 04:03:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10603.333251953125, gpu time: 13844.35842514038
2024-07-09 04:03:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.4853515625, gpu time: 3024.2699308395386
2024-07-09 04:03:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.244873046875, gpu time: 3457.506830215454
2024-07-09 04:03:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.295166015625, gpu time: 3220.7552824020386
2024-07-09 04:03:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.63427734375, gpu time: 3860.6712551116943
2024-07-09 04:03:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.383544921875, gpu time: 3149.988890647888
2024-07-09 04:03:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.42529296875, gpu time: 3158.1073179244995
2024-07-09 04:03:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2946.093505859375, gpu time: 7047.924030303955
2024-07-09 04:03:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.17431640625, gpu time: 3135.5443029403687
2024-07-09 04:03:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.70068359375, gpu time: 4670.14109992981
2024-07-09 04:03:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10604.174560546875, gpu time: 13872.446926116943
2024-07-09 04:03:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.858642578125, gpu time: 3048.4385890960693
2024-07-09 04:03:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.3828125, gpu time: 3433.4919452667236
2024-07-09 04:03:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.658935546875, gpu time: 3267.6284379959106
2024-07-09 04:03:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.51123046875, gpu time: 3204.8163890838623
2024-07-09 04:03:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.8955078125, gpu time: 3192.269245147705
2024-07-09 04:03:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.798828125, gpu time: 3192.114384651184
2024-07-09 04:03:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.625, gpu time: 3520.4419231414795
2024-07-09 04:03:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.625732421875, gpu time: 3202.3685159683228
2024-07-09 04:03:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.95703125, gpu time: 3909.2013759613037
2024-07-09 04:03:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10604.540771484375, gpu time: 13902.186148643494
2024-07-09 04:03:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.343994140625, gpu time: 3080.169174194336
2024-07-09 04:03:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2946.768310546875, gpu time: 7097.411428451538
2024-07-09 04:03:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.71435546875, gpu time: 3320.0372772216797
2024-07-09 04:03:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.238525390625, gpu time: 4721.572982788086
2024-07-09 04:03:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.43603515625, gpu time: 3228.2143936157227
2024-07-09 04:03:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.0322265625, gpu time: 3218.6572847366333
2024-07-09 04:03:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.761474609375, gpu time: 3509.4244861602783
2024-07-09 04:03:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.501708984375, gpu time: 3236.6162252426147
2024-07-09 04:03:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.038818359375, gpu time: 3264.1660385131836
2024-07-09 04:03:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10605.396728515625, gpu time: 13956.044428825378
2024-07-09 04:03:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.162841796875, gpu time: 3110.9211978912354
2024-07-09 04:03:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.6298828125, gpu time: 3572.0834045410156
2024-07-09 04:03:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.246826171875, gpu time: 3371.793478012085
2024-07-09 04:03:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.28369140625, gpu time: 3955.7682914733887
2024-07-09 04:03:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.73779296875, gpu time: 3259.35057926178
2024-07-09 04:03:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.69140625, gpu time: 3257.186436653137
2024-07-09 04:03:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2947.84619140625, gpu time: 7141.666343688965
2024-07-09 04:03:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.86572265625, gpu time: 3265.4317684173584
2024-07-09 04:03:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.5869140625, gpu time: 4780.383749008179
2024-07-09 04:03:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10606.275390625, gpu time: 14008.171507835388
2024-07-09 04:03:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.53173828125, gpu time: 3148.881709098816
2024-07-09 04:03:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.08544921875, gpu time: 3583.9122257232666
2024-07-09 04:03:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.975341796875, gpu time: 3426.4280824661255
2024-07-09 04:03:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.35693359375, gpu time: 3307.203832626343
2024-07-09 04:03:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.306640625, gpu time: 3287.809642791748
2024-07-09 04:03:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.056884765625, gpu time: 3294.939106941223
2024-07-09 04:03:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.02099609375, gpu time: 3631.7175331115723
2024-07-09 04:03:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.628173828125, gpu time: 3295.359793663025
2024-07-09 04:03:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.614990234375, gpu time: 4003.2488117218018
2024-07-09 04:03:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10606.640380859375, gpu time: 14041.359855651855
2024-07-09 04:03:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.843017578125, gpu time: 3177.368453025818
2024-07-09 04:03:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2948.24267578125, gpu time: 7186.975021362305
2024-07-09 04:03:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.322509765625, gpu time: 3477.096604347229
2024-07-09 04:03:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.902587890625, gpu time: 4826.881706237793
2024-07-09 04:03:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.69091796875, gpu time: 3329.905996322632
2024-07-09 04:03:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.623046875, gpu time: 3326.9376916885376
2024-07-09 04:03:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.412841796875, gpu time: 3650.2148418426514
2024-07-09 04:03:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.133544921875, gpu time: 3331.14302444458
2024-07-09 04:03:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.682373046875, gpu time: 3351.7310676574707
2024-07-09 04:03:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10607.560302734375, gpu time: 14067.888676643372
2024-07-09 04:03:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.184814453125, gpu time: 3207.5758380889893
2024-07-09 04:03:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.384765625, gpu time: 3675.956289291382
2024-07-09 04:03:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.71923828125, gpu time: 3578.3107690811157
2024-07-09 04:03:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.75830078125, gpu time: 3354.4544973373413
2024-07-09 04:03:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.03564453125, gpu time: 4059.844701766968
2024-07-09 04:03:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.99951171875, gpu time: 3380.791657447815
2024-07-09 04:03:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.5068359375, gpu time: 3370.7433795928955
2024-07-09 04:03:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2948.716796875, gpu time: 7282.972385406494
2024-07-09 04:03:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10608.031494140625, gpu time: 14127.851288795471
2024-07-09 04:03:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.27001953125, gpu time: 4870.041904449463
2024-07-09 04:03:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.552490234375, gpu time: 3250.933313369751
2024-07-09 04:03:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.098388671875, gpu time: 3624.6901693344116
2024-07-09 04:03:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.7353515625, gpu time: 3725.6344261169434
2024-07-09 04:03:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.123046875, gpu time: 3385.7406034469604
2024-07-09 04:03:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.042724609375, gpu time: 3404.5891914367676
2024-07-09 04:03:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.53466796875, gpu time: 3414.6068868637085
2024-07-09 04:03:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.876953125, gpu time: 3400.391405105591
2024-07-09 04:03:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.734619140625, gpu time: 3731.3518562316895
2024-07-09 04:03:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10609.375, gpu time: 14171.929246902466
2024-07-09 04:03:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.37548828125, gpu time: 4151.143981933594
2024-07-09 04:03:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.946044921875, gpu time: 3311.287923812866
2024-07-09 04:03:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.47900390625, gpu time: 3657.266836166382
2024-07-09 04:03:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2949.106201171875, gpu time: 7382.123352050781
2024-07-09 04:03:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.591064453125, gpu time: 3425.590880393982
2024-07-09 04:03:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.69189453125, gpu time: 4924.26275062561
2024-07-09 04:03:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.900146484375, gpu time: 3444.873152732849
2024-07-09 04:03:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.905029296875, gpu time: 3429.6010303497314
2024-07-09 04:03:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.2412109375, gpu time: 3783.9461574554443
2024-07-09 04:03:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10610.19482421875, gpu time: 14223.705290794373
2024-07-09 04:03:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.37109375, gpu time: 3456.951955795288
2024-07-09 04:03:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.3798828125, gpu time: 3345.5545139312744
2024-07-09 04:03:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.18505859375, gpu time: 3684.72797870636
2024-07-09 04:03:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.050537109375, gpu time: 3784.1957416534424
2024-07-09 04:03:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.667236328125, gpu time: 3480.9205293655396
2024-07-09 04:03:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.7001953125, gpu time: 4214.062274932861
2024-07-09 04:03:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.258544921875, gpu time: 3482.3413457870483
2024-07-09 04:03:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.264892578125, gpu time: 3460.872576713562
2024-07-09 04:03:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2949.452392578125, gpu time: 7454.05637550354
2024-07-09 04:03:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10610.720703125, gpu time: 14288.435587882996
2024-07-09 04:03:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.020751953125, gpu time: 4966.599590301514
2024-07-09 04:03:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.48486328125, gpu time: 3375.912459373474
2024-07-09 04:03:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.69921875, gpu time: 3732.4448204040527
2024-07-09 04:03:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.567138671875, gpu time: 3889.5065727233887
2024-07-09 04:03:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.76708984375, gpu time: 3534.557375907898
2024-07-09 04:03:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.765869140625, gpu time: 3508.7584018707275
2024-07-09 04:03:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.1787109375, gpu time: 3515.026972770691
2024-07-09 04:03:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.64013671875, gpu time: 3486.386999130249
2024-07-09 04:03:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.0634765625, gpu time: 3828.6010608673096
2024-07-09 04:03:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10611.08349609375, gpu time: 14340.946193695068
2024-07-09 04:03:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.037841796875, gpu time: 4281.956413269043
2024-07-09 04:03:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.515380859375, gpu time: 3411.6881704330444
2024-07-09 04:03:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.281982421875, gpu time: 3767.4267721176147
2024-07-09 04:03:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2949.802734375, gpu time: 7517.218832015991
2024-07-09 04:03:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.14013671875, gpu time: 3587.3649435043335
2024-07-09 04:03:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.347900390625, gpu time: 5026.326843261719
2024-07-09 04:03:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.564697265625, gpu time: 3544.456118583679
2024-07-09 04:03:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.32958984375, gpu time: 3517.5567874908447
2024-07-09 04:03:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.09375, gpu time: 3934.807092666626
2024-07-09 04:03:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10611.696533203125, gpu time: 14394.950244903564
2024-07-09 04:03:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.106689453125, gpu time: 3563.001489639282
2024-07-09 04:03:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.4453125, gpu time: 3441.2597160339355
2024-07-09 04:03:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.1845703125, gpu time: 3797.6939992904663
2024-07-09 04:03:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.401123046875, gpu time: 3889.190715789795
2024-07-09 04:03:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.19580078125, gpu time: 3640.390110015869
2024-07-09 04:03:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.066650390625, gpu time: 4346.415990829468
2024-07-09 04:03:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.938720703125, gpu time: 3593.8033628463745
2024-07-09 04:03:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.6943359375, gpu time: 3553.0792198181152
2024-07-09 04:03:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2950.1982421875, gpu time: 7585.554252624512
2024-07-09 04:04:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10612.077392578125, gpu time: 14427.852995872498
2024-07-09 04:04:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.6767578125, gpu time: 5079.067209243774
2024-07-09 04:04:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.955078125, gpu time: 3473.881664276123
2024-07-09 04:04:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.648681640625, gpu time: 3829.219946861267
2024-07-09 04:04:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.48046875, gpu time: 4005.8098754882812
2024-07-09 04:04:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.53662109375, gpu time: 3694.133038520813
2024-07-09 04:04:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.44287109375, gpu time: 3620.5945014953613
2024-07-09 04:04:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.9228515625, gpu time: 3624.9480295181274
2024-07-09 04:04:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.595458984375, gpu time: 3578.3376417160034
2024-07-09 04:04:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.74267578125, gpu time: 3971.1643924713135
2024-07-09 04:04:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10612.6064453125, gpu time: 14498.051140785217
2024-07-09 04:04:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.387939453125, gpu time: 4401.337963104248
2024-07-09 04:04:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.346435546875, gpu time: 3498.098165512085
2024-07-09 04:04:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.589599609375, gpu time: 3867.6593408584595
2024-07-09 04:04:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2950.57275390625, gpu time: 7638.2390995025635
2024-07-09 04:04:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.6806640625, gpu time: 3746.3916444778442
2024-07-09 04:04:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.99072265625, gpu time: 5122.687728881836
2024-07-09 04:04:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.515869140625, gpu time: 3656.207896232605
2024-07-09 04:04:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.01513671875, gpu time: 3607.9443893432617
2024-07-09 04:04:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.805908203125, gpu time: 4060.6998462677
2024-07-09 04:04:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10613.001220703125, gpu time: 14537.959655761719
2024-07-09 04:04:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.7978515625, gpu time: 3668.5830249786377
2024-07-09 04:04:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.858154296875, gpu time: 3523.9268283843994
2024-07-09 04:04:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.45361328125, gpu time: 3898.53360748291
2024-07-09 04:04:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.46435546875, gpu time: 4045.5537395477295
2024-07-09 04:04:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.0537109375, gpu time: 3790.098084449768
2024-07-09 04:04:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.716796875, gpu time: 4468.68762588501
2024-07-09 04:04:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.10693359375, gpu time: 3705.7649030685425
2024-07-09 04:04:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.359375, gpu time: 3639.510019302368
2024-07-09 04:04:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2950.958740234375, gpu time: 7699.506834030151
2024-07-09 04:04:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10613.38232421875, gpu time: 14590.190264701843
2024-07-09 04:04:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.31591796875, gpu time: 5182.65482711792
2024-07-09 04:04:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.402587890625, gpu time: 3586.628807067871
2024-07-09 04:04:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.666015625, gpu time: 3926.8336334228516
2024-07-09 04:04:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.1328125, gpu time: 4122.106782913208
2024-07-09 04:04:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.426513671875, gpu time: 3837.3846883773804
2024-07-09 04:04:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.1171875, gpu time: 3722.424196243286
2024-07-09 04:04:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.503173828125, gpu time: 3736.516929626465
2024-07-09 04:04:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.734130859375, gpu time: 3670.0871686935425
2024-07-09 04:04:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.8994140625, gpu time: 4103.985153198242
2024-07-09 04:04:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10613.759521484375, gpu time: 14642.743592262268
2024-07-09 04:04:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.072265625, gpu time: 4518.686710357666
2024-07-09 04:04:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.151123046875, gpu time: 3617.8531551361084
2024-07-09 04:04:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.052734375, gpu time: 3963.374786376953
2024-07-09 04:04:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2951.421142578125, gpu time: 7753.314723968506
2024-07-09 04:04:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.7958984375, gpu time: 3867.2155952453613
2024-07-09 04:04:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.68017578125, gpu time: 5237.455358505249
2024-07-09 04:04:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.912109375, gpu time: 3795.3865852355957
2024-07-09 04:04:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.104248046875, gpu time: 3701.0971155166626
2024-07-09 04:04:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.50537109375, gpu time: 4172.52986907959
2024-07-09 04:04:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10614.90185546875, gpu time: 14694.104759216309
2024-07-09 04:04:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.43701171875, gpu time: 3797.971948623657
2024-07-09 04:04:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.52197265625, gpu time: 3683.432572364807
2024-07-09 04:04:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.558837890625, gpu time: 3992.002974510193
2024-07-09 04:04:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.213134765625, gpu time: 4185.779949188232
2024-07-09 04:04:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.1748046875, gpu time: 3930.8239765167236
2024-07-09 04:04:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.40185546875, gpu time: 4576.449005126953
2024-07-09 04:04:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.9453125, gpu time: 3825.7261323928833
2024-07-09 04:04:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.450439453125, gpu time: 3745.4091577529907
2024-07-09 04:04:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2951.816162109375, gpu time: 7820.83846282959
2024-07-09 04:04:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10616.03125, gpu time: 14740.360960006714
2024-07-09 04:04:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.99853515625, gpu time: 5293.998128890991
2024-07-09 04:04:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.88671875, gpu time: 3727.250054359436
2024-07-09 04:04:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.139892578125, gpu time: 4022.20396232605
2024-07-09 04:04:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.822998046875, gpu time: 4237.328172683716
2024-07-09 04:04:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.531494140625, gpu time: 3975.0849781036377
2024-07-09 04:04:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.8017578125, gpu time: 3869.5142574310303
2024-07-09 04:04:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.27587890625, gpu time: 3895.4095611572266
2024-07-09 04:04:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.8115234375, gpu time: 3772.314461708069
2024-07-09 04:04:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.61865234375, gpu time: 4265.28674697876
2024-07-09 04:04:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10616.40576171875, gpu time: 14788.981485366821
2024-07-09 04:04:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.20947265625, gpu time: 3761.456967353821
2024-07-09 04:04:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.71630859375, gpu time: 4651.433559417725
2024-07-09 04:04:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.4755859375, gpu time: 4054.1180725097656
2024-07-09 04:04:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2952.1845703125, gpu time: 7877.497713088989
2024-07-09 04:04:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.138427734375, gpu time: 4000.7352418899536
2024-07-09 04:04:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.822021484375, gpu time: 3921.419825553894
2024-07-09 04:04:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.413330078125, gpu time: 5361.358833312988
2024-07-09 04:04:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.84619140625, gpu time: 3816.556586265564
2024-07-09 04:04:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.146484375, gpu time: 4300.151111602783
2024-07-09 04:04:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10616.7900390625, gpu time: 14818.810312271118
2024-07-09 04:04:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.55078125, gpu time: 3787.7037115097046
2024-07-09 04:04:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.1669921875, gpu time: 3926.740707397461
2024-07-09 04:04:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.91015625, gpu time: 4084.229299545288
2024-07-09 04:04:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.96728515625, gpu time: 4338.0845737457275
2024-07-09 04:04:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.515869140625, gpu time: 4037.0917568206787
2024-07-09 04:04:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.199951171875, gpu time: 3994.821816444397
2024-07-09 04:04:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.03515625, gpu time: 4771.575115203857
2024-07-09 04:04:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.3798828125, gpu time: 3849.316138267517
2024-07-09 04:04:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10617.162353515625, gpu time: 14854.20618724823
2024-07-09 04:04:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2952.628173828125, gpu time: 7959.216993331909
2024-07-09 04:04:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.935546875, gpu time: 3851.8789739608765
2024-07-09 04:04:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.729736328125, gpu time: 5415.068166732788
2024-07-09 04:04:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.217529296875, gpu time: 4108.766922950745
2024-07-09 04:04:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.71435546875, gpu time: 4084.2265224456787
2024-07-09 04:04:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.471435546875, gpu time: 4371.761741638184
2024-07-09 04:04:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.566162109375, gpu time: 4032.7816915512085
2024-07-09 04:04:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.48583984375, gpu time: 3983.137559890747
2024-07-09 04:04:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.662841796875, gpu time: 3907.6373147964478
2024-07-09 04:04:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10621.265625, gpu time: 14885.266695976257
2024-07-09 04:04:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.301025390625, gpu time: 4420.768972396851
2024-07-09 04:04:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.5185546875, gpu time: 3903.398706436157
2024-07-09 04:04:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.46044921875, gpu time: 4844.431343078613
2024-07-09 04:04:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.142822265625, gpu time: 4162.7570543289185
2024-07-09 04:04:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.06982421875, gpu time: 4108.5092668533325
2024-07-09 04:04:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2953.0830078125, gpu time: 8039.482671737671
2024-07-09 04:04:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.70068359375, gpu time: 4093.9529504776
2024-07-09 04:04:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.080078125, gpu time: 5468.420379638672
2024-07-09 04:04:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.376953125, gpu time: 3931.7322177886963
2024-07-09 04:04:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10621.647216796875, gpu time: 14923.087851524353
2024-07-09 04:04:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.7890625, gpu time: 4426.281955718994
2024-07-09 04:04:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.331298828125, gpu time: 3954.9792375564575
2024-07-09 04:04:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.91845703125, gpu time: 4043.769618988037
2024-07-09 04:04:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.5244140625, gpu time: 4206.701735496521
2024-07-09 04:04:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.45068359375, gpu time: 4134.177770614624
2024-07-09 04:04:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.735595703125, gpu time: 4479.903268814087
2024-07-09 04:04:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.24658203125, gpu time: 4150.023886680603
2024-07-09 04:04:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.789794921875, gpu time: 4909.061008453369
2024-07-09 04:04:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.48046875, gpu time: 3993.4791584014893
2024-07-09 04:04:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10622.033203125, gpu time: 14955.794922828674
2024-07-09 04:04:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2953.449951171875, gpu time: 8104.527854919434
2024-07-09 04:04:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.64794921875, gpu time: 4018.382821083069
2024-07-09 04:04:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.464111328125, gpu time: 5516.788108825684
2024-07-09 04:04:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.898193359375, gpu time: 4232.085599899292
2024-07-09 04:04:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.831787109375, gpu time: 4164.646278381348
2024-07-09 04:04:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.110107421875, gpu time: 4482.4538497924805
2024-07-09 04:04:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.26171875, gpu time: 4206.174341201782
2024-07-09 04:04:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.97998046875, gpu time: 4096.806791305542
2024-07-09 04:04:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.833984375, gpu time: 4029.499034881592
2024-07-09 04:04:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10622.408935546875, gpu time: 14991.18423652649
2024-07-09 04:04:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.059814453125, gpu time: 4558.435346603394
2024-07-09 04:04:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.0419921875, gpu time: 4047.0662088394165
2024-07-09 04:04:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.108154296875, gpu time: 4960.146018981934
2024-07-09 04:04:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.005615234375, gpu time: 4269.033954620361
2024-07-09 04:04:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.8955078125, gpu time: 4189.009502410889
2024-07-09 04:04:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2953.8408203125, gpu time: 8147.692216873169
2024-07-09 04:04:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.970947265625, gpu time: 4265.040319442749
2024-07-09 04:04:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.880615234375, gpu time: 5560.073268890381
2024-07-09 04:04:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.202392578125, gpu time: 4056.0790605545044
2024-07-09 04:04:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10623.501220703125, gpu time: 15018.446663856506
2024-07-09 04:04:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.457763671875, gpu time: 4529.40877532959
2024-07-09 04:04:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.38525390625, gpu time: 4093.1032161712646
2024-07-09 04:04:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.2958984375, gpu time: 4153.219005584717
2024-07-09 04:04:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.660400390625, gpu time: 4330.1917724609375
2024-07-09 04:04:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.235107421875, gpu time: 4217.381851196289
2024-07-09 04:04:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.387939453125, gpu time: 4609.168035507202
2024-07-09 04:04:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.474853515625, gpu time: 4321.349653244019
2024-07-09 04:04:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.555908203125, gpu time: 5008.5548667907715
2024-07-09 04:04:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.209228515625, gpu time: 4080.25732421875
2024-07-09 04:04:31 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:04:31 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:04:31 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:04:31 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:04:31 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:04:31 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:04:31 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:04:31 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:04:31 | INFO | fairseq_cli.eval_lm | Evaluated 825,641 tokens in 253.2s (3260.40 tokens/s)
2024-07-09 04:04:31 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9061, Perplexity: 7.50
2024-07-09 04:04:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2954.306396484375, gpu time: 8171.294640541077
2024-07-09 04:04:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.202880859375, gpu time: 5583.786091804504
2024-07-09 04:04:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.43505859375, gpu time: 4564.825289726257
2024-07-09 04:04:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.619140625, gpu time: 4177.103988647461
2024-07-09 04:04:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.796875, gpu time: 4642.403908729553
2024-07-09 04:04:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.870361328125, gpu time: 5032.892330169678
2024-07-09 04:04:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2954.740966796875, gpu time: 8194.970184326172
2024-07-09 04:04:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.607666015625, gpu time: 5617.71940612793
2024-07-09 04:04:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.800048828125, gpu time: 4610.916374206543
2024-07-09 04:04:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.001708984375, gpu time: 4205.199856758118
2024-07-09 04:04:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.11865234375, gpu time: 4676.3461809158325
2024-07-09 04:04:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.19580078125, gpu time: 5056.867552757263
2024-07-09 04:04:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2955.125244140625, gpu time: 8219.117407798767
2024-07-09 04:04:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.919189453125, gpu time: 5647.982476234436
2024-07-09 04:04:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.11083984375, gpu time: 4637.080560684204
2024-07-09 04:04:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.31884765625, gpu time: 4232.340522766113
2024-07-09 04:04:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.428955078125, gpu time: 4703.910048484802
2024-07-09 04:04:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.521240234375, gpu time: 5081.663896560669
2024-07-09 04:04:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2955.497314453125, gpu time: 8249.153436660767
2024-07-09 04:04:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.28662109375, gpu time: 5671.827939987183
2024-07-09 04:04:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.423828125, gpu time: 4660.950503349304
2024-07-09 04:04:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.777099609375, gpu time: 4262.74503326416
2024-07-09 04:04:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.735595703125, gpu time: 4730.233273506165
2024-07-09 04:04:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.86083984375, gpu time: 5110.445844650269
2024-07-09 04:04:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2955.891845703125, gpu time: 8274.846742630005
2024-07-09 04:04:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.787109375, gpu time: 5703.162212371826
2024-07-09 04:04:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.892822265625, gpu time: 4694.324457168579
2024-07-09 04:04:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.2744140625, gpu time: 4294.364905357361
2024-07-09 04:04:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.127685546875, gpu time: 4760.931064605713
2024-07-09 04:04:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.427001953125, gpu time: 5140.6941957473755
2024-07-09 04:04:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2956.278564453125, gpu time: 8305.79957485199
2024-07-09 04:04:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.151123046875, gpu time: 5730.775678634644
2024-07-09 04:04:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.250732421875, gpu time: 4724.365928649902
2024-07-09 04:04:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.584228515625, gpu time: 4330.051821708679
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 04:04:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.48583984375, gpu time: 4790.338294029236
2024-07-09 04:04:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.786376953125, gpu time: 5171.728627204895
2024-07-09 04:04:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2956.656005859375, gpu time: 8337.258645057678
2024-07-09 04:04:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.518310546875, gpu time: 5768.972997665405
2024-07-09 04:04:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.612548828125, gpu time: 4754.8249979019165
2024-07-09 04:04:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.95751953125, gpu time: 4360.444651603699
2024-07-09 04:04:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.09375, gpu time: 4816.338640213013
2024-07-09 04:04:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.225341796875, gpu time: 5207.861624717712
2024-07-09 04:04:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2957.02734375, gpu time: 8369.552597999573
2024-07-09 04:04:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.86572265625, gpu time: 5795.025503158569
2024-07-09 04:04:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.9853515625, gpu time: 4785.886949539185
2024-07-09 04:04:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.273681640625, gpu time: 4397.672852516174
2024-07-09 04:04:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.47412109375, gpu time: 4840.382662773132
2024-07-09 04:04:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.5439453125, gpu time: 5238.891896247864
2024-07-09 04:04:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2957.397216796875, gpu time: 8400.381108283997
2024-07-09 04:04:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.246826171875, gpu time: 5823.258972167969
2024-07-09 04:04:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.731689453125, gpu time: 4810.217694282532
2024-07-09 04:04:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.619873046875, gpu time: 4428.054481506348
2024-07-09 04:04:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.804931640625, gpu time: 4871.542693138123
2024-07-09 04:04:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.854736328125, gpu time: 5264.6152811050415
2024-07-09 04:04:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2957.778076171875, gpu time: 8430.323379516602
2024-07-09 04:04:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.56298828125, gpu time: 5852.199481964111
2024-07-09 04:04:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.091552734375, gpu time: 4838.802682876587
2024-07-09 04:04:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.92431640625, gpu time: 4461.650673866272
2024-07-09 04:04:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.122314453125, gpu time: 4898.421440124512
2024-07-09 04:04:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.228271484375, gpu time: 5298.988435745239
2024-07-09 04:04:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2958.166259765625, gpu time: 8462.425171852112
2024-07-09 04:04:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.90869140625, gpu time: 5883.715672492981
2024-07-09 04:04:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.416748046875, gpu time: 4881.977127075195
2024-07-09 04:04:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.28466796875, gpu time: 4493.666226387024
2024-07-09 04:04:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.4443359375, gpu time: 4929.064350128174
2024-07-09 04:04:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.569580078125, gpu time: 5324.957421302795
2024-07-09 04:04:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2958.55029296875, gpu time: 8494.153684616089
2024-07-09 04:04:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.225341796875, gpu time: 5921.166750907898
2024-07-09 04:04:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.753173828125, gpu time: 4914.824038505554
2024-07-09 04:04:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.633056640625, gpu time: 4523.581456184387
2024-07-09 04:04:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.76171875, gpu time: 4960.027262687683
2024-07-09 04:04:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.041259765625, gpu time: 5354.962092399597
2024-07-09 04:04:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2958.942626953125, gpu time: 8530.700761795044
2024-07-09 04:04:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.539794921875, gpu time: 5950.877499580383
2024-07-09 04:04:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.0615234375, gpu time: 4950.782633781433
2024-07-09 04:04:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.960205078125, gpu time: 4550.681324005127
2024-07-09 04:04:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.0888671875, gpu time: 4998.2682638168335
2024-07-09 04:04:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.359619140625, gpu time: 5379.547876358032
2024-07-09 04:04:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2960.13134765625, gpu time: 8557.224628448486
2024-07-09 04:04:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.8505859375, gpu time: 5974.823443412781
2024-07-09 04:04:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.390380859375, gpu time: 4975.365538597107
2024-07-09 04:04:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.263671875, gpu time: 4575.345668792725
2024-07-09 04:04:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.40380859375, gpu time: 5023.136610031128
2024-07-09 04:04:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.71435546875, gpu time: 5403.529180526733
2024-07-09 04:04:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2960.504638671875, gpu time: 8583.149775505066
2024-07-09 04:04:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.342041015625, gpu time: 5998.759788513184
2024-07-09 04:04:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.731201171875, gpu time: 4999.064922332764
2024-07-09 04:04:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.594970703125, gpu time: 4601.227295875549
2024-07-09 04:04:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.737060546875, gpu time: 5047.699034690857
2024-07-09 04:04:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.02490234375, gpu time: 5430.254648208618
2024-07-09 04:04:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2960.86474609375, gpu time: 8607.284680366516
2024-07-09 04:04:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.6865234375, gpu time: 6022.689251899719
2024-07-09 04:04:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.048583984375, gpu time: 5023.1201457977295
2024-07-09 04:04:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.974365234375, gpu time: 4625.14940071106
2024-07-09 04:04:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.0419921875, gpu time: 5072.174740791321
2024-07-09 04:04:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.32861328125, gpu time: 5457.566355705261
2024-07-09 04:04:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2961.23681640625, gpu time: 8631.283584594727
2024-07-09 04:04:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.9931640625, gpu time: 6047.166076660156
2024-07-09 04:04:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.49267578125, gpu time: 5056.604021072388
2024-07-09 04:04:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.306396484375, gpu time: 4651.875347137451
2024-07-09 04:04:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.3837890625, gpu time: 5103.7499742507935
2024-07-09 04:04:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.68310546875, gpu time: 5484.444303512573
2024-07-09 04:04:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2962.186767578125, gpu time: 8655.795450210571
2024-07-09 04:04:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.41552734375, gpu time: 6079.67795085907
2024-07-09 04:04:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.803466796875, gpu time: 5080.4003648757935
2024-07-09 04:04:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.61181640625, gpu time: 4683.310580253601
2024-07-09 04:04:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.689453125, gpu time: 5132.811122894287
2024-07-09 04:04:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.99560546875, gpu time: 5513.56657409668
2024-07-09 04:04:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2962.552490234375, gpu time: 8694.319169998169
2024-07-09 04:04:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.7275390625, gpu time: 6110.92374420166
2024-07-09 04:04:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.10546875, gpu time: 5114.754319190979
2024-07-09 04:04:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.92333984375, gpu time: 4707.2978048324585
2024-07-09 04:04:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.013427734375, gpu time: 5163.818034172058
2024-07-09 04:04:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.32568359375, gpu time: 5551.115732192993
2024-07-09 04:04:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2962.92138671875, gpu time: 8731.76720905304
2024-07-09 04:04:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.135986328125, gpu time: 6142.257856369019
2024-07-09 04:04:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.459716796875, gpu time: 5139.270665168762
2024-07-09 04:04:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.2353515625, gpu time: 4731.434791564941
2024-07-09 04:04:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.333251953125, gpu time: 5201.696312904358
2024-07-09 04:04:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.645263671875, gpu time: 5575.874798774719
2024-07-09 04:04:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2963.28466796875, gpu time: 8761.953159332275
2024-07-09 04:05:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.473876953125, gpu time: 6166.303641319275
2024-07-09 04:05:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.8818359375, gpu time: 5163.200609207153
2024-07-09 04:05:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.6416015625, gpu time: 4762.062342643738
2024-07-09 04:05:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.659912109375, gpu time: 5246.304518699646
2024-07-09 04:05:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.961181640625, gpu time: 5605.5818700790405
2024-07-09 04:05:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2963.6572265625, gpu time: 8800.59095954895
2024-07-09 04:05:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.793212890625, gpu time: 6194.422710418701
2024-07-09 04:05:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.234375, gpu time: 5195.539520263672
2024-07-09 04:05:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.648681640625, gpu time: 4800.599501609802
2024-07-09 04:05:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.02490234375, gpu time: 5270.059103012085
2024-07-09 04:05:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.279296875, gpu time: 5646.167193412781
2024-07-09 04:05:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2964.03955078125, gpu time: 8837.463317871094
2024-07-09 04:05:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.198974609375, gpu time: 6226.031223297119
2024-07-09 04:05:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.59033203125, gpu time: 5234.8232421875
2024-07-09 04:05:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.96337890625, gpu time: 4824.76352596283
2024-07-09 04:05:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.328125, gpu time: 5310.166822433472
2024-07-09 04:05:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.644775390625, gpu time: 5676.936186790466
2024-07-09 04:05:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2964.4111328125, gpu time: 8869.649750709534
2024-07-09 04:05:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.984375, gpu time: 6271.21911239624
2024-07-09 04:05:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.417724609375, gpu time: 5259.522308349609
2024-07-09 04:05:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.279296875, gpu time: 4864.924368858337
2024-07-09 04:05:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.03173828125, gpu time: 5343.0753383636475
2024-07-09 04:05:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.308349609375, gpu time: 5713.753344535828
2024-07-09 04:05:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2964.801025390625, gpu time: 8906.225950241089
2024-07-09 04:05:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.378173828125, gpu time: 6295.288417816162
2024-07-09 04:05:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.72705078125, gpu time: 5296.238664627075
2024-07-09 04:05:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.612060546875, gpu time: 4889.48871421814
2024-07-09 04:05:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.412353515625, gpu time: 5377.869773864746
2024-07-09 04:05:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.61328125, gpu time: 5737.795289993286
2024-07-09 04:05:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2965.1875, gpu time: 8930.241815567017
2024-07-09 04:05:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.69482421875, gpu time: 6329.5586948394775
2024-07-09 04:05:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.036865234375, gpu time: 5320.052609443665
2024-07-09 04:05:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.966796875, gpu time: 4919.736746788025
2024-07-09 04:05:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.733154296875, gpu time: 5403.038280487061
2024-07-09 04:05:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.930908203125, gpu time: 5761.761875152588
2024-07-09 04:05:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2965.547607421875, gpu time: 8961.013688087463
2024-07-09 04:05:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.010986328125, gpu time: 6360.6672077178955
2024-07-09 04:05:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.431884765625, gpu time: 5349.854880332947
2024-07-09 04:05:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.273681640625, gpu time: 4944.639653205872
2024-07-09 04:05:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.69580078125, gpu time: 5433.5125522613525
2024-07-09 04:05:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.245849609375, gpu time: 5792.7257471084595
2024-07-09 04:05:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2965.910400390625, gpu time: 8991.590680122375
2024-07-09 04:05:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.322998046875, gpu time: 6391.630920410156
2024-07-09 04:05:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.761962890625, gpu time: 5380.392351150513
2024-07-09 04:05:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.322265625, gpu time: 4976.540327072144
2024-07-09 04:05:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.080078125, gpu time: 5466.346025466919
2024-07-09 04:05:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.929931640625, gpu time: 5826.132983207703
2024-07-09 04:05:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2966.28076171875, gpu time: 9023.887833595276
2024-07-09 04:05:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.633056640625, gpu time: 6424.353516578674
2024-07-09 04:05:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.269775390625, gpu time: 5412.578624725342
2024-07-09 04:05:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.693115234375, gpu time: 5000.397472381592
2024-07-09 04:05:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.395263671875, gpu time: 5490.463490486145
2024-07-09 04:05:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.518310546875, gpu time: 5856.638454437256
2024-07-09 04:05:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2966.669921875, gpu time: 9056.054428100586
2024-07-09 04:05:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.965087890625, gpu time: 6460.052753448486
2024-07-09 04:05:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.72412109375, gpu time: 5444.73273563385
2024-07-09 04:05:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.00830078125, gpu time: 5025.038777351379
2024-07-09 04:05:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.713623046875, gpu time: 5522.8976039886475
2024-07-09 04:05:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.830810546875, gpu time: 5888.9575271606445
2024-07-09 04:05:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2967.048828125, gpu time: 9082.821655273438
2024-07-09 04:05:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.35400390625, gpu time: 6492.133746147156
2024-07-09 04:05:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.029052734375, gpu time: 5468.642200469971
2024-07-09 04:05:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.349853515625, gpu time: 5057.26713180542
2024-07-09 04:05:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.026611328125, gpu time: 5547.2389097213745
2024-07-09 04:05:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.146484375, gpu time: 5914.519474029541
2024-07-09 04:05:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2967.509033203125, gpu time: 9114.277528762817
2024-07-09 04:05:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.673828125, gpu time: 6515.968651771545
2024-07-09 04:05:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.340087890625, gpu time: 5500.175834655762
2024-07-09 04:05:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.665771484375, gpu time: 5081.075156211853
2024-07-09 04:05:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.43359375, gpu time: 5579.559904098511
2024-07-09 04:05:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.478759765625, gpu time: 5938.6473388671875
2024-07-09 04:05:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2967.875732421875, gpu time: 9147.398684501648
2024-07-09 04:05:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.99560546875, gpu time: 6539.686596870422
2024-07-09 04:05:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.651123046875, gpu time: 5533.942750930786
2024-07-09 04:05:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.9765625, gpu time: 5115.723512649536
2024-07-09 04:05:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.752685546875, gpu time: 5603.944730758667
2024-07-09 04:05:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.793212890625, gpu time: 5970.43745136261
2024-07-09 04:05:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2968.25537109375, gpu time: 9171.03182888031
2024-07-09 04:05:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.30859375, gpu time: 6574.095594406128
2024-07-09 04:05:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.968994140625, gpu time: 5557.655895233154
2024-07-09 04:05:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.512939453125, gpu time: 5150.831069946289
2024-07-09 04:05:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.07763671875, gpu time: 5633.315800666809
2024-07-09 04:05:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.11865234375, gpu time: 5998.980040550232
2024-07-09 04:05:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2968.634521484375, gpu time: 9194.725293159485
2024-07-09 04:05:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.1025390625, gpu time: 6600.962983131409
2024-07-09 04:05:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.274169921875, gpu time: 5584.458323478699
2024-07-09 04:05:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.8369140625, gpu time: 5177.379578590393
2024-07-09 04:05:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.420654296875, gpu time: 5657.790865898132
2024-07-09 04:05:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.435546875, gpu time: 6022.913665771484
2024-07-09 04:05:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2968.991455078125, gpu time: 9226.344844818115
2024-07-09 04:05:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.423583984375, gpu time: 6627.473410606384
2024-07-09 04:05:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.60205078125, gpu time: 5613.645393371582
2024-07-09 04:05:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.170166015625, gpu time: 5201.376883506775
2024-07-09 04:05:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.724853515625, gpu time: 5681.6422510147095
2024-07-09 04:05:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.220458984375, gpu time: 6050.082494735718
2024-07-09 04:05:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2969.354736328125, gpu time: 9252.050631523132
2024-07-09 04:05:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.741455078125, gpu time: 6653.018237113953
2024-07-09 04:05:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.037841796875, gpu time: 5637.555818557739
2024-07-09 04:05:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.481201171875, gpu time: 5228.464912414551
2024-07-09 04:05:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.044921875, gpu time: 5707.137957572937
2024-07-09 04:05:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.660888671875, gpu time: 6074.632121086121
2024-07-09 04:05:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2969.735595703125, gpu time: 9276.533535957336
2024-07-09 04:05:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.178955078125, gpu time: 6676.66450214386
2024-07-09 04:05:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.375, gpu time: 5662.063364982605
2024-07-09 04:05:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.8076171875, gpu time: 5252.443337440491
2024-07-09 04:05:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.430908203125, gpu time: 5731.000062942505
2024-07-09 04:05:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.986328125, gpu time: 6099.652787208557
2024-07-09 04:05:25 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:05:25 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:05:25 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:05:25 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:05:25 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:05:25 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:05:25 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:05:25 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:05:25 | INFO | fairseq_cli.eval_lm | Evaluated 825,641 tokens in 292.1s (2826.96 tokens/s)
2024-07-09 04:05:25 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9061, Perplexity: 7.50
