2024-07-12 03:40:17 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12170
2024-07-12 03:40:17 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12170
2024-07-12 03:40:17 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12170
2024-07-12 03:40:17 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 1
2024-07-12 03:40:17 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 2
2024-07-12 03:40:17 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12170
2024-07-12 03:40:17 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 3
2024-07-12 03:40:17 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.05}", 'results_path': None, 'is_moe': True}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12170', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 10, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': 10, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 10}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | model	None
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 10, 'batch_size_valid': 10, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-12 03:40:17 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-12 03:40:18 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-12 03:40:18 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-12 03:40:18 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-12 03:40:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-12 03:40:23 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:40:25 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:40:28 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:40:31 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:40:34 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:40:36 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:40:38 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-12 03:40:46 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-12 03:40:54 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-12 03:40:59 | INFO | fairseq_cli.eval_lm | load time: 41.85 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
New cuda time without quantization: 3376.859375
torch.Size([524288, 768]) torch.float16
New cuda time: 3376.9697265625
New cuda time without quantization: 24.18825340270996
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 24.261371612548828
New cuda time without quantization: 160.18133544921875
torch.Size([524288, 768]) torch.float16
New cuda time: 160.25941467285156
New cuda time without quantization: 16.0212345123291
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.12347412109375
New cuda time without quantization: 15.699478149414062
torch.Size([524288, 768]) torch.float16
New cuda time: 15.779155731201172
New cuda time without quantization: 18.147310256958008
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.206829071044922
New cuda time without quantization: 16.30091667175293
torch.Size([524288, 768]) torch.float16
New cuda time: 16.384113311767578
New cuda time without quantization: 21.296419143676758
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.357059478759766
New cuda time without quantization: 15.774036407470703
torch.Size([524288, 768]) torch.float16
New cuda time: 15.824915885925293
New cuda time without quantization: 17.267791748046875
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.38747215270996
New cuda time without quantization: 15.899477005004883
torch.Size([524288, 768]) torch.float16
New cuda time: 15.958675384521484
New cuda time without quantization: 22.333377838134766
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.50969886779785
New cuda time without quantization: 12.31884479522705
torch.Size([524288, 768]) torch.float16
New cuda time: 12.4012451171875
New cuda time without quantization: 17.890350341796875
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.945070266723633
New cuda time without quantization: 22.835298538208008
torch.Size([524288, 768]) torch.float16
New cuda time: 22.920095443725586
New cuda time without quantization: 17.84971046447754
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.90506935119629
New cuda time without quantization: 11.833087921142578
torch.Size([524288, 768]) torch.float16
New cuda time: 11.913886070251465
New cuda time without quantization: 22.378978729248047
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.442977905273438
New cuda time without quantization: 11.82492733001709
torch.Size([524288, 768]) torch.float16
New cuda time: 11.87836742401123
New cuda time without quantization: 22.23818016052246
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.364418029785156
New cuda time without quantization: 11.737247467041016
torch.Size([524288, 768]) torch.float16
New cuda time: 11.790367126464844
New cuda time without quantization: 20.810344696044922
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 20.872901916503906
New cuda time without quantization: 11.95020580291748
torch.Size([524288, 768]) torch.float16
New cuda time: 12.036605834960938
New cuda time without quantization: 18.0634708404541
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.12363052368164
New cuda time without quantization: 12.033407211303711
torch.Size([524288, 768]) torch.float16
New cuda time: 12.15820598602295
New cuda time without quantization: 19.141868591308594
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 19.201387405395508
New cuda time without quantization: 11.792608261108398
torch.Size([524288, 768]) torch.float16
New cuda time: 11.847805976867676
New cuda time without quantization: 17.875471115112305
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.931629180908203
New cuda time without quantization: 15.016918182373047
torch.Size([524288, 768]) torch.float16
New cuda time: 15.078838348388672
New cuda time without quantization: 17.95819091796875
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.08395004272461
New cuda time without quantization: 12.027327537536621
torch.Size([524288, 768]) torch.float16
New cuda time: 12.082845687866211
New cuda time without quantization: 18.337867736816406
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.394668579101562
New cuda time without quantization: 20.88666343688965
torch.Size([524288, 768]) torch.float16
New cuda time: 20.943782806396484
New cuda time without quantization: 12.042845726013184
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.171006202697754
New cuda time without quantization: 17.814672470092773
torch.Size([524288, 768]) torch.float16
New cuda time: 17.87274932861328
New cuda time without quantization: 23.503456115722656
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 23.569215774536133
New cuda time without quantization: 11.969246864318848
torch.Size([524288, 768]) torch.float16
New cuda time: 12.04460620880127
New cuda time without quantization: 18.73626708984375
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.80042839050293
New cuda time without quantization: 11.852128028869629
torch.Size([524288, 768]) torch.float16
New cuda time: 11.94412612915039
New cuda time without quantization: 22.533538818359375
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.58873748779297
New cuda time without quantization: 15.819795608520508
torch.Size([524288, 768]) torch.float16
New cuda time: 15.871636390686035
New cuda time without quantization: 12.101885795593262
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.15660572052002
New cuda time without quantization: 21.590822219848633
torch.Size([524288, 768]) torch.float16
New cuda time: 21.64505958557129
New cuda time without quantization: 16.385074615478516
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.51307487487793
New cuda time without quantization: 18.17291259765625
torch.Size([524288, 768]) torch.float16
New cuda time: 18.230188369750977
New cuda time without quantization: 12.080765724182129
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.137565612792969
New cuda time without quantization: 20.66602325439453
torch.Size([524288, 768]) torch.float16
New cuda time: 20.722501754760742
New cuda time without quantization: 12.103006362915039
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.15756607055664
New cuda time without quantization: 18.15275001525879
torch.Size([524288, 768]) torch.float16
New cuda time: 18.206829071044922
New cuda time without quantization: 23.707775115966797
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 23.767616271972656
New cuda time without quantization: 18.098989486694336
torch.Size([524288, 768]) torch.float16
New cuda time: 18.150510787963867
New cuda time without quantization: 12.026366233825684
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.079646110534668
New cuda time without quantization: 18.097551345825195
torch.Size([524288, 768]) torch.float16
New cuda time: 18.180587768554688
New cuda time without quantization: 16.158674240112305
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.234514236450195
New cuda time without quantization: 18.19483184814453
torch.Size([524288, 768]) torch.float16
New cuda time: 18.25354766845703
New cuda time without quantization: 12.003005981445312
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.062365531921387
New cuda time without quantization: 18.03339195251465
torch.Size([524288, 768]) torch.float16
New cuda time: 18.130027770996094
New cuda time without quantization: 21.163301467895508
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.22170066833496
New cuda time without quantization: 17.814191818237305
torch.Size([524288, 768]) torch.float16
New cuda time: 17.868112564086914
New cuda time without quantization: 11.918686866760254
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.971166610717773
New cuda time without quantization: 18.752588272094727
torch.Size([524288, 768]) torch.float16
New cuda time: 18.80826759338379
New cuda time without quantization: 12.073406219482422
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.149406433105469
New cuda time without quantization: 17.990032196044922
New cuda time without quantization: 446.342529296875
torch.Size([524288, 768]) torch.float16
New cuda time: 446.4358215332031
New cuda time without quantization: 11.991082191467285
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.088521957397461
New cuda time without quantization: 11.907241821289062
torch.Size([524288, 768]) torch.float16
New cuda time: 11.993481636047363
New cuda time without quantization: 11.985801696777344
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.24420166015625
New cuda time without quantization: 15.748214721679688
torch.Size([524288, 768]) torch.float16
New cuda time: 15.836215019226074
New cuda time without quantization: 18.498943328857422
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.56342315673828
New cuda time without quantization: 16.411096572875977
torch.Size([524288, 768]) torch.float16
New cuda time: 16.504697799682617
New cuda time without quantization: 12.103561401367188
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.180841445922852
New cuda time without quantization: 15.811574935913086
torch.Size([524288, 768]) torch.float16
New cuda time: 15.899575233459473
New cuda time without quantization: 17.56917953491211
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.709659576416016
New cuda time without quantization: 16.09285545349121
torch.Size([524288, 768]) torch.float16
New cuda time: 16.186296463012695
New cuda time without quantization: 13.014603614807129
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 13.09012508392334
New cuda time without quantization: 11.762920379638672
torch.Size([524288, 768]) torch.float16
New cuda time: 11.849320411682129
New cuda time without quantization: 18.286144256591797
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.341344833374023
New cuda time without quantization: 11.83572006225586
torch.Size([524288, 768]) torch.float16
New cuda time: 11.940681457519531
New cuda time without quantization: 18.266143798828125
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.32262420654297
New cuda time without quantization: 12.0907621383667
torch.Size([524288, 768]) torch.float16
New cuda time: 12.174121856689453
New cuda time without quantization: 12.075560569763184
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.152681350708008
New cuda time without quantization: 12.114921569824219
torch.Size([524288, 768]) torch.float16
New cuda time: 12.172362327575684
New cuda time without quantization: 17.883102416992188
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.007261276245117
New cuda time without quantization: 16.697017669677734
torch.Size([524288, 768]) torch.float16
New cuda time: 16.753498077392578
New cuda time without quantization: 11.983080863952637
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.05924129486084
New cuda time without quantization: 12.097481727600098
torch.Size([524288, 768]) torch.float16
New cuda time: 12.20804214477539
New cuda time without quantization: 18.54582405090332
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.60358428955078
New cuda time without quantization: 12.74820327758789
torch.Size([524288, 768]) torch.float16
New cuda time: 12.80388355255127
New cuda time without quantization: 11.961641311645508
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.020681381225586
New cuda time without quantization: 12.1803617477417
torch.Size([524288, 768]) torch.float16
New cuda time: 12.238282203674316
New cuda time without quantization: 18.1192626953125
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.175901412963867
New cuda time without quantization: 11.828840255737305
torch.Size([524288, 768]) torch.float16
New cuda time: 11.902600288391113
New cuda time without quantization: 18.1805419921875
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.237503051757812
New cuda time without quantization: 12.115562438964844
torch.Size([524288, 768]) torch.float16
New cuda time: 12.173802375793457
New cuda time without quantization: 18.382944107055664
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 28.24521827697754
New cuda time without quantization: 11.833319664001465
torch.Size([524288, 768]) torch.float16
New cuda time: 11.887880325317383
New cuda time without quantization: 12.36068344116211
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.504523277282715
New cuda time without quantization: 18.023103713989258
torch.Size([524288, 768]) torch.float16
New cuda time: 18.0795841217041
New cuda time without quantization: 12.055880546569824
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.13956069946289
New cuda time without quantization: 20.11094856262207
torch.Size([524288, 768]) torch.float16
New cuda time: 20.166950225830078
New cuda time without quantization: 19.247907638549805
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 19.304548263549805
New cuda time without quantization: 12.178281784057617
torch.Size([524288, 768]) torch.float16
New cuda time: 12.237321853637695
New cuda time without quantization: 16.14005470275879
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.299575805664062
New cuda time without quantization: 12.074762344360352
torch.Size([524288, 768]) torch.float16
New cuda time: 12.132521629333496
New cuda time without quantization: 12.320201873779297
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.374762535095215
New cuda time without quantization: 26.55689239501953
torch.Size([524288, 768]) torch.float16
New cuda time: 26.637691497802734
New cuda time without quantization: 12.031241416931152
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.088200569152832
New cuda time without quantization: 18.27686309814453
torch.Size([524288, 768]) torch.float16
New cuda time: 18.337663650512695
New cuda time without quantization: 18.707744598388672
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.767423629760742
New cuda time without quantization: 11.917160987854004
torch.Size([524288, 768]) torch.float16
New cuda time: 11.988680839538574
New cuda time without quantization: 12.500202178955078
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.55716323852539
New cuda time without quantization: 18.85638427734375
torch.Size([524288, 768]) torch.float16
New cuda time: 18.910144805908203
New cuda time without quantization: 12.041160583496094
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.200040817260742
New cuda time without quantization: 18.543903350830078
torch.Size([524288, 768]) torch.float16
New cuda time: 18.635744094848633
New cuda time without quantization: 12.30692195892334
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.361322402954102
New cuda time without quantization: 18.414783477783203
torch.Size([524288, 768]) torch.float16
New cuda time: 18.50774383544922
New cuda time without quantization: 11.969321250915527
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.045321464538574
New cuda time without quantization: 18.127744674682617
torch.Size([524288, 768]) torch.float16
New cuda time: 18.187744140625
New cuda time without quantization: 12.623562812805176
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.680362701416016
New cuda time without quantization: 27.793376922607422
torch.Size([524288, 768]) torch.float16
New cuda time: 27.927616119384766
New cuda time without quantization: 12.039401054382324
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.096040725708008
New cuda time without quantization: 18.029024124145508
torch.Size([524288, 768]) torch.float16
New cuda time: 18.084543228149414
New cuda time without quantization: 12.554763793945312
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.608683586120605
New cuda time without quantization: 11.922921180725098
torch.Size([524288, 768]) torch.float16
New cuda time: 11.99652099609375
New cuda time without quantization: 18.774303436279297
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.828704833984375
New cuda time without quantization: New cuda time without quantization: 4206.6669921875
torch.Size([524288, 768]) torch.float16
New cuda time: 4206.77490234375
New cuda time without quantization: 24.43721580505371
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 24.58233642578125
New cuda time without quantization: 132.4749298095703
torch.Size([524288, 768]) torch.float16
New cuda time: 132.7653350830078
New cuda time without quantization: 17.107107162475586
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.185508728027344
New cuda time without quantization: 11.683884620666504
torch.Size([524288, 768]) torch.float16
New cuda time: 11.759405136108398
New cuda time without quantization: 11.985486030578613
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.20596694946289
New cuda time without quantization: 11.747085571289062
torch.Size([524288, 768]) torch.float16
New cuda time: 11.828845977783203
New cuda time without quantization: 16.070781707763672
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.17862319946289
New cuda time without quantization: 11.745485305786133
torch.Size([524288, 768]) torch.float16
New cuda time: 11.798126220703125
New cuda time without quantization: 11.925166130065918
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.049487113952637
New cuda time without quantization: 11.836525917053223
torch.Size([524288, 768]) torch.float16
New cuda time: 11.894447326660156
New cuda time without quantization: 16.588863372802734
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.713184356689453
New cuda time without quantization: 13.526612281799316
torch.Size([524288, 768]) torch.float16
New cuda time: 13.604533195495605
New cuda time without quantization: 11.940526008605957
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.07764720916748
New cuda time without quantization: 22.878650665283203
torch.Size([524288, 768]) torch.float16
New cuda time: 22.968730926513672
New cuda time without quantization: 11.986125946044922
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.06628704071045
New cuda time without quantization: 11.947406768798828
torch.Size([524288, 768]) torch.float16
New cuda time: 12.030126571655273
New cuda time without quantization: 16.06342315673828
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.137182235717773
New cuda time without quantization: 12.110608100891113
torch.Size([524288, 768]) torch.float16
New cuda time: 12.175087928771973
New cuda time without quantization: 16.529184341430664
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.65046501159668
New cuda time without quantization: 11.893807411193848
torch.Size([524288, 768]) torch.float16
New cuda time: 11.950926780700684
New cuda time without quantization: 14.66181755065918
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 14.822298049926758
New cuda time without quantization: 12.041486740112305
torch.Size([524288, 768]) torch.float16
New cuda time: 12.130287170410156
New cuda time without quantization: 12.139567375183105
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.2400484085083
New cuda time without quantization: 11.675886154174805
torch.Size([524288, 768]) torch.float16
New cuda time: 11.729486465454102
New cuda time without quantization: 13.579253196716309
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 13.72197437286377
New cuda time without quantization: 11.927726745605469
torch.Size([524288, 768]) torch.float16
New cuda time: 11.986287117004395
New cuda time without quantization: 12.012845993041992
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.08804702758789
New cuda time without quantization: 21.748245239257812
torch.Size([524288, 768]) torch.float16
New cuda time: 21.804885864257812
New cuda time without quantization: 11.973166465759277
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.101487159729004
New cuda time without quantization: 11.767565727233887
torch.Size([524288, 768]) torch.float16
New cuda time: 11.823406219482422
New cuda time without quantization: 19.089994430541992
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 19.16999626159668
New cuda time without quantization: 20.704402923583984
torch.Size([524288, 768]) torch.float16
New cuda time: 20.76104164123535
New cuda time without quantization: 12.522768020629883
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.647249221801758
New cuda time without quantization: 11.833645820617676
torch.Size([524288, 768]) torch.float16
New cuda time: 11.90932559967041
New cuda time without quantization: 23.775772094726562
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 23.836732864379883
New cuda time without quantization: 12.894610404968262
torch.Size([524288, 768]) torch.float16
New cuda time: 12.95637035369873
New cuda time without quantization: 12.006766319274902
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.091246604919434
New cuda time without quantization: 11.937006950378418
torch.Size([524288, 768]) torch.float16
New cuda time: 11.994606971740723
New cuda time without quantization: 26.945865631103516
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 27.01882553100586
New cuda time without quantization: 11.767086029052734
torch.Size([524288, 768]) torch.float16
New cuda time: 11.841165542602539
New cuda time without quantization: 12.339568138122559
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.39556884765625
New cuda time without quantization: 20.082639694213867
torch.Size([524288, 768]) torch.float16
New cuda time: 20.159759521484375
New cuda time without quantization: 12.15684700012207
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.297967910766602
New cuda time without quantization: 11.830286979675293
torch.Size([524288, 768]) torch.float16
New cuda time: 12.008207321166992
New cuda time without quantization: 18.22087287902832
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.353191375732422
New cuda time without quantization: 14.5494966506958
torch.Size([524288, 768]) torch.float16
New cuda time: 14.64549732208252
New cuda time without quantization: 12.291406631469727
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.347408294677734
New cuda time without quantization: 11.857006072998047
torch.Size([524288, 768]) torch.float16
New cuda time: 11.909806251525879
New cuda time without quantization: 23.84601402282715
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 23.968734741210938
New cuda time without quantization: 11.900365829467773
torch.Size([524288, 768]) torch.float16
New cuda time: 11.971726417541504
New cuda time without quantization: 12.132206916809082
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.18948745727539
New cuda time without quantization: 11.946287155151367
torch.Size([524288, 768]) torch.float16
New cuda time: 12.022127151489258
New cuda time without quantization: 22.70328712463379
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.774648666381836
New cuda time without quantization: 11.979247093200684
torch.Size([524288, 768]) torch.float16
New cuda time: 12.060687065124512
New cuda time without quantization: 12.370927810668945
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.42676830291748
New cuda time without quantization: 21.14968490600586
torch.Size([524288, 768]) torch.float16
New cuda time: 21.219284057617188
New cuda time without quantization: 12.103246688842773
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.155567169189453
New cuda time without quantization: 11.880846977233887
torch.Size([524288, 768]) torch.float16
New cuda time: 11.961326599121094
New cuda time without quantization: 12.343567848205566
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.48948860168457
New cuda time without quantization: 11.904526710510254
torch.Size([524288, 768]) torch.float16
New cuda time: 11.976846694946289
New cuda time without quantization: 18.54471206665039
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.600231170654297
New cuda time without quantization: New cuda time without quantization: 4678.8076171875
torch.Size([524288, 768]) torch.float16
New cuda time: 4678.92041015625
New cuda time without quantization: 24.218446731567383
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 24.350126266479492
New cuda time without quantization: 144.67245483398438
torch.Size([524288, 768]) torch.float16
New cuda time: 144.7623748779297
New cuda time without quantization: 22.385324478149414
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.5312442779541
New cuda time without quantization: 15.98563003540039
torch.Size([524288, 768]) torch.float16
New cuda time: 16.061790466308594
New cuda time without quantization: 18.12275505065918
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.184356689453125
New cuda time without quantization: 16.375871658325195
torch.Size([524288, 768]) torch.float16
New cuda time: 16.463550567626953
New cuda time without quantization: 21.344039916992188
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.40723991394043
New cuda time without quantization: 16.08946990966797
torch.Size([524288, 768]) torch.float16
New cuda time: 16.148670196533203
New cuda time without quantization: 17.14851188659668
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.27859115600586
New cuda time without quantization: 15.949790954589844
torch.Size([524288, 768]) torch.float16
New cuda time: 16.016511917114258
New cuda time without quantization: 20.893800735473633
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 20.94883918762207
New cuda time without quantization: 13.933945655822754
torch.Size([524288, 768]) torch.float16
New cuda time: 14.027066230773926
New cuda time without quantization: 17.67219352722168
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.73235321044922
New cuda time without quantization: 23.047243118286133
torch.Size([524288, 768]) torch.float16
New cuda time: 23.135723114013672
New cuda time without quantization: 17.91619110107422
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.97011375427246
New cuda time without quantization: 12.066742897033691
torch.Size([524288, 768]) torch.float16
New cuda time: 12.156502723693848
New cuda time without quantization: 15.217947959899902
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 15.291707992553711
New cuda time without quantization: 12.11650276184082
torch.Size([524288, 768]) torch.float16
New cuda time: 12.1721830368042
New cuda time without quantization: 18.319076538085938
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.439075469970703
New cuda time without quantization: 16.305150985717773
torch.Size([524288, 768]) torch.float16
New cuda time: 16.360990524291992
New cuda time without quantization: 20.73780059814453
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 20.8062801361084
New cuda time without quantization: 11.993782043457031
torch.Size([524288, 768]) torch.float16
New cuda time: 12.057782173156738
New cuda time without quantization: 18.36851692199707
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.443876266479492
New cuda time without quantization: 12.150262832641602
torch.Size([524288, 768]) torch.float16
New cuda time: 12.205142974853516
New cuda time without quantization: 19.44835662841797
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 19.505475997924805
New cuda time without quantization: 12.075543403625488
torch.Size([524288, 768]) torch.float16
New cuda time: 12.136822700500488
New cuda time without quantization: 17.63763427734375
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.699234008789062
New cuda time without quantization: 21.928842544555664
torch.Size([524288, 768]) torch.float16
New cuda time: 21.98708152770996
New cuda time without quantization: 17.7027530670166
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.830434799194336
New cuda time without quantization: 12.081462860107422
torch.Size([524288, 768]) torch.float16
New cuda time: 12.138262748718262
New cuda time without quantization: 18.613956451416016
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.67779541015625
New cuda time without quantization: 20.90995979309082
torch.Size([524288, 768]) torch.float16
New cuda time: 20.97252082824707
New cuda time without quantization: 11.938423156738281
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.076183319091797
New cuda time without quantization: 17.72995376586914
torch.Size([524288, 768]) torch.float16
New cuda time: 17.784513473510742
New cuda time without quantization: 23.724525451660156
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 23.784366607666016
New cuda time without quantization: 19.840198516845703
torch.Size([524288, 768]) torch.float16
New cuda time: 19.895397186279297
New cuda time without quantization: 18.936676025390625
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 19.004676818847656
New cuda time without quantization: 11.961942672729492
torch.Size([524288, 768]) torch.float16
New cuda time: 12.018902778625488
New cuda time without quantization: 21.740360260009766
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.793001174926758
New cuda time without quantization: 16.823232650756836
torch.Size([524288, 768]) torch.float16
New cuda time: 16.88003158569336
New cuda time without quantization: 11.951863288879395
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.006743431091309
New cuda time without quantization: 21.532520294189453
torch.Size([524288, 768]) torch.float16
New cuda time: 21.593639373779297
New cuda time without quantization: 16.855871200561523
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.937471389770508
New cuda time without quantization: 17.861953735351562
torch.Size([524288, 768]) torch.float16
New cuda time: 17.91779327392578
New cuda time without quantization: 18.268033981323242
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.329313278198242
New cuda time without quantization: 20.942119598388672
torch.Size([524288, 768]) torch.float16
New cuda time: 20.999399185180664
New cuda time without quantization: 11.918902397155762
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.977301597595215
New cuda time without quantization: 18.8083553314209
torch.Size([524288, 768]) torch.float16
New cuda time: 18.860515594482422
New cuda time without quantization: 23.820205688476562
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 23.877166748046875
New cuda time without quantization: 18.422435760498047
torch.Size([524288, 768]) torch.float16
New cuda time: 18.47891616821289
New cuda time without quantization: 11.887381553649902
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.944981575012207
New cuda time without quantization: 18.294755935668945
torch.Size([524288, 768]) torch.float16
New cuda time: 18.35747528076172
New cuda time without quantization: 22.31508445739746
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.38820457458496
New cuda time without quantization: 18.28275489807129
torch.Size([524288, 768]) torch.float16
New cuda time: 18.352516174316406
New cuda time without quantization: 11.976343154907227
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.032182693481445
New cuda time without quantization: 18.35779571533203
torch.Size([524288, 768]) torch.float16
New cuda time: 18.45267677307129
New cuda time without quantization: 20.861000061035156
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 20.923080444335938
New cuda time without quantization: 17.760351181030273
torch.Size([524288, 768]) torch.float16
New cuda time: 17.81923484802246
New cuda time without quantization: 12.13874340057373
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.281943321228027
New cuda time without quantization: 19.103235244750977
torch.Size([524288, 768]) torch.float16
New cuda time: 19.15971565246582
New cuda time without quantization: 18.173795700073242
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.232675552368164
New cuda time without quantization: 18.54067611694336
11.893647193908691
torch.Size([524288, 768]) torch.float16
New cuda time: 12.064046859741211
New cuda time without quantization: 12.104846954345703
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.160046577453613
New cuda time without quantization: 11.936046600341797
torch.Size([524288, 768]) torch.float16
New cuda time: 12.040206909179688
New cuda time without quantization: 12.207086563110352
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.26740837097168
New cuda time without quantization: 18.345672607421875
torch.Size([524288, 768]) torch.float16
New cuda time: 18.422632217407227
New cuda time without quantization: 12.346927642822266
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.40436840057373
New cuda time without quantization: 12.061166763305664
torch.Size([524288, 768]) torch.float16
New cuda time: 12.145807266235352
New cuda time without quantization: 12.074767112731934
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.131887435913086
New cuda time without quantization: 12.032366752624512
torch.Size([524288, 768]) torch.float16
New cuda time: 12.088847160339355
New cuda time without quantization: 12.019725799560547
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.148527145385742
New cuda time without quantization: 11.826926231384277
torch.Size([524288, 768]) torch.float16
New cuda time: 11.88084602355957
New cuda time without quantization: 12.075886726379395
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.13620662689209
New cuda time without quantization: 15.381020545959473
torch.Size([524288, 768]) torch.float16
New cuda time: 15.439261436462402
New cuda time without quantization: 11.872526168823242
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.942767143249512
New cuda time without quantization: 11.893807411193848
torch.Size([524288, 768]) torch.float16
New cuda time: 11.991086959838867
New cuda time without quantization: 11.9238862991333
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.025167465209961
New cuda time without quantization: 16.933828353881836
torch.Size([524288, 768]) torch.float16
New cuda time: 16.99574851989746
New cuda time without quantization: 12.697488784790039
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.979729652404785
New cuda time without quantization: 11.690606117248535
torch.Size([524288, 768]) torch.float16
New cuda time: 11.74820613861084
New cuda time without quantization: 12.456048965454102
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.51684856414795
New cuda time without quantization: 14.89557933807373
torch.Size([524288, 768]) torch.float16
New cuda time: 14.970779418945312
New cuda time without quantization: 12.107406616210938
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.169807434082031
New cuda time without quantization: 11.725324630737305
torch.Size([524288, 768]) torch.float16
New cuda time: 11.793805122375488
New cuda time without quantization: 12.213647842407227
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.276687622070312
New cuda time without quantization: 18.761993408203125
torch.Size([524288, 768]) torch.float16
New cuda time: 18.819433212280273
New cuda time without quantization: 21.560083389282227
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.621044158935547
New cuda time without quantization: 12.050447463989258
torch.Size([524288, 768]) torch.float16
New cuda time: 12.144207954406738
New cuda time without quantization: 12.249326705932617
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.30900764465332
New cuda time without quantization: 11.879406929016113
torch.Size([524288, 768]) torch.float16
New cuda time: 11.951566696166992
New cuda time without quantization: 12.40340805053711
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.57348918914795
New cuda time without quantization: 12.067566871643066
torch.Size([524288, 768]) torch.float16
New cuda time: 12.122767448425293
New cuda time without quantization: 21.916086196899414
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.979768753051758
New cuda time without quantization: 11.893486022949219
torch.Size([524288, 768]) torch.float16
New cuda time: 11.969005584716797
New cuda time without quantization: 17.503267288208008
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.58310890197754
New cuda time without quantization: 12.120367050170898
torch.Size([524288, 768]) torch.float16
New cuda time: 12.182766914367676
New cuda time without quantization: 12.177806854248047
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.332048416137695
New cuda time without quantization: 21.4250431060791
torch.Size([524288, 768]) torch.float16
New cuda time: 21.482484817504883
New cuda time without quantization: 11.905165672302246
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.963565826416016
New cuda time without quantization: 12.063247680664062
torch.Size([524288, 768]) torch.float16
New cuda time: 12.165488243103027
New cuda time without quantization: 12.087407112121582
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.271246910095215
New cuda time without quantization: 11.752366065979004
torch.Size([524288, 768]) torch.float16
New cuda time: 11.811245918273926
New cuda time without quantization: 32.06476974487305
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 32.17420959472656
New cuda time without quantization: 11.867566108703613
torch.Size([524288, 768]) torch.float16
New cuda time: 11.919886589050293
New cuda time without quantization: 12.478768348693848
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.53844928741455
New cuda time without quantization: 11.873485565185547
torch.Size([524288, 768]) torch.float16
New cuda time: 12.01252555847168
New cuda time without quantization: 12.137646675109863
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.19716739654541
New cuda time without quantization: 32.04508590698242
torch.Size([524288, 768]) torch.float16
New cuda time: 32.18364715576172
New cuda time without quantization: 12.130288124084473
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.187408447265625
New cuda time without quantization: 12.01652717590332
torch.Size([524288, 768]) torch.float16
New cuda time: 12.111886978149414
New cuda time without quantization: 12.090766906738281
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.389328002929688
New cuda time without quantization: 11.876526832580566
torch.Size([524288, 768]) torch.float16
New cuda time: 11.960846900939941
New cuda time without quantization: 12.032686233520508
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.157007217407227
New cuda time without quantization: 11.8693265914917
torch.Size([524288, 768]) torch.float16
New cuda time: 11.925806999206543
New cuda time without quantization: 12.39716911315918
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.45396900177002
New cuda time without quantization: 29.762678146362305
torch.Size([524288, 768]) torch.float16
New cuda time: 29.828277587890625
New cuda time without quantization: 12.44020938873291
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.496688842773438
New cuda time without quantization: 11.990447044372559
torch.Size([524288, 768]) torch.float16
New cuda time: 12.054126739501953
New cuda time without quantization: 12.277647972106934
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.337488174438477
New cuda time without quantization: 18.689353942871094
torch.Size([524288, 768]) torch.float16
New cuda time: 18.749513626098633
New cuda time without quantization: 11.908367156982422
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.96420669555664
New cuda time without quantization: 12.071727752685547
torch.Size([524288, 768]) torch.float16
New cuda time: 12.143888473510742
New cuda time without quantization: 11.967086791992188
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.058127403259277
New cuda time without quantization: 11.869486808776855
torch.Size([524288, 768]) torch.float16
New cuda time: 18.688356399536133
New cuda time without quantization: 11.907221794128418
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.961462020874023
New cuda time without quantization: 18.417476654052734
torch.Size([524288, 768]) torch.float16
New cuda time: 18.475236892700195
New cuda time without quantization: 11.900821685791016
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.95730209350586
New cuda time without quantization: 18.531396865844727
torch.Size([524288, 768]) torch.float16
New cuda time: 18.599716186523438
New cuda time without quantization: 12.025142669677734
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.086103439331055
New cuda time without quantization: 12.002263069152832
torch.Size([524288, 768]) torch.float16
New cuda time: 12.062582969665527
New cuda time without quantization: 17.785953521728516
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.841474533081055
New cuda time without quantization: 12.051862716674805
torch.Size([524288, 768]) torch.float16
New cuda time: 12.144662857055664
New cuda time without quantization: 18.448196411132812
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.551076889038086
New cuda time without quantization: 12.280022621154785
torch.Size([524288, 768]) torch.float16
New cuda time: 12.335062980651855
New cuda time without quantization: 18.016834259033203
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.07123565673828
New cuda time without quantization: 15.446109771728516
torch.Size([524288, 768]) torch.float16
New cuda time: 15.505470275878906
New cuda time without quantization: 16.32611083984375
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.381790161132812
New cuda time without quantization: 12.007702827453613
torch.Size([524288, 768]) torch.float16
New cuda time: 12.094742774963379
New cuda time without quantization: 14.66850757598877
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 14.728828430175781
New cuda time without quantization: 16.961151123046875
torch.Size([524288, 768]) torch.float16
New cuda time: 17.019071578979492
New cuda time without quantization: 12.3915433883667
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.449302673339844
New cuda time without quantization: 12.086902618408203
torch.Size([524288, 768]) torch.float16
New cuda time: 12.144502639770508
New cuda time without quantization: 11.985623359680176
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.044822692871094
New cuda time without quantization: 14.686267852783203
torch.Size([524288, 768]) torch.float16
New cuda time: 14.753948211669922
New cuda time without quantization: 11.82738208770752
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.881462097167969
New cuda time without quantization: 17.030912399291992
torch.Size([524288, 768]) torch.float16
New cuda time: 17.08563232421875
New cuda time without quantization: 11.986103057861328
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.039543151855469
New cuda time without quantization: 18.839555740356445
torch.Size([524288, 768]) torch.float16
New cuda time: 18.895715713500977
New cuda time without quantization: 12.023222923278809
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.104183197021484
New cuda time without quantization: 12.096822738647461
torch.Size([524288, 768]) torch.float16
New cuda time: 12.220823287963867
New cuda time without quantization: 11.884502410888672
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.039382934570312
New cuda time without quantization: 11.991703033447266
torch.Size([524288, 768]) torch.float16
New cuda time: 12.050422668457031
New cuda time without quantization: 12.086583137512207
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.141942977905273
New cuda time without quantization: 12.053142547607422
torch.Size([524288, 768]) torch.float16
New cuda time: 12.111063003540039
New cuda time without quantization: 12.193782806396484
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.404982566833496
New cuda time without quantization: 17.15795135498047
torch.Size([524288, 768]) torch.float16
New cuda time: 17.22163200378418
New cuda time without quantization: 17.071712493896484
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.12611198425293
New cuda time without quantization: 12.562743186950684
torch.Size([524288, 768]) torch.float16
New cuda time: 12.620984077453613
New cuda time without quantization: 12.072182655334473
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.127862930297852
New cuda time without quantization: 11.88418197631836
torch.Size([524288, 768]) torch.float16
New cuda time: 12.116662979125977
New cuda time without quantization: 13.276664733886719
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 13.338424682617188
New cuda time without quantization: 12.047863006591797
torch.Size([524288, 768]) torch.float16
New cuda time: 12.172662734985352
New cuda time without quantization: 21.36724090576172
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.421480178833008
New cuda time without quantization: 12.040501594543457
torch.Size([524288, 768]) torch.float16
New cuda time: 12.094742774963379
New cuda time without quantization: 23.022924423217773
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 23.134443283081055
New cuda time without quantization: 12.209142684936523
torch.Size([524288, 768]) torch.float16
New cuda time: 12.26098346710205
New cuda time without quantization: 11.998263359069824
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.053783416748047
New cuda time without quantization: 22.587404251098633
torch.Size([524288, 768]) torch.float16
New cuda time: 22.646604537963867
New cuda time without quantization: 12.103543281555176
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.23874282836914
New cuda time without quantization: 22.175561904907227
torch.Size([524288, 768]) torch.float16
New cuda time: 22.286922454833984
New cuda time without quantization: 12.130422592163086
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.18802261352539
New cuda time without quantization: 11.99250316619873
torch.Size([524288, 768]) torch.float16
New cuda time: 12.056343078613281
New cuda time without quantization: 22.066282272338867
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.129802703857422
New cuda time without quantization: 12.062102317810059
torch.Size([524288, 768]) torch.float16
New cuda time: 12.14914321899414
New cuda time without quantization: 12.884504318237305
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 13.053464889526367
New cuda time without quantization: 11.968663215637207
torch.Size([524288, 768]) torch.float16
New cuda time: 12.029943466186523
New cuda time without quantization: 12.133942604064941
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.19122314453125
New cuda time without quantization: 29.72693634033203
torch.Size([524288, 768]) torch.float16
New cuda time: 29.782936096191406
New cuda time without quantization: 11.984183311462402
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.038743019104004
New cuda time without quantization: 11.948343276977539
torch.Size([524288, 768]) torch.float16
New cuda time: 12.049622535705566
New cuda time without quantization: 11.981463432312012
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.034262657165527
New cuda time without quantization: 18.592355728149414
torch.Size([524288, 768]) torch.float16
New cuda time: 18.645795822143555
New cuda time without quantization: 15.252188682556152
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 15.307868957519531
New cuda time without quantization: 12.003863334655762
torch.Size([524288, 768]) torch.float16
New cuda time: 12.078582763671875
New cuda time without quantization: 36.62519073486328
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 36.68743133544922
New cuda time without quantization: 12.090103149414062
torch.Size([524288, 768]) 18.375263214111328
torch.Size([524288, 768]) torch.float16
New cuda time: 18.521503448486328
New cuda time without quantization: 12.175721168518066
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.234122276306152
New cuda time without quantization: 18.63222312927246
torch.Size([524288, 768]) torch.float16
New cuda time: 18.690624237060547
New cuda time without quantization: 12.213801383972168
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.270121574401855
New cuda time without quantization: 18.55414390563965
torch.Size([524288, 768]) torch.float16
New cuda time: 18.611743927001953
New cuda time without quantization: 12.718282699584961
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.778122901916504
New cuda time without quantization: 12.271722793579102
torch.Size([524288, 768]) torch.float16
New cuda time: 12.362122535705566
New cuda time without quantization: 18.34934425354004
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.406784057617188
New cuda time without quantization: 12.029321670532227
torch.Size([524288, 768]) torch.float16
New cuda time: 12.088682174682617
New cuda time without quantization: 18.70342445373535
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.855104446411133
New cuda time without quantization: 12.597482681274414
torch.Size([524288, 768]) torch.float16
New cuda time: 12.653162956237793
New cuda time without quantization: 18.193662643432617
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.248064041137695
New cuda time without quantization: 11.781800270080566
torch.Size([524288, 768]) torch.float16
New cuda time: 11.910441398620605
New cuda time without quantization: 16.500537872314453
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.561656951904297
New cuda time without quantization: 12.11316204071045
torch.Size([524288, 768]) torch.float16
New cuda time: 12.20548152923584
New cuda time without quantization: 14.90453052520752
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 14.962611198425293
New cuda time without quantization: 17.39621925354004
torch.Size([524288, 768]) torch.float16
New cuda time: 17.6069393157959
New cuda time without quantization: 12.4728422164917
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.623562812805176
New cuda time without quantization: 12.214921951293945
torch.Size([524288, 768]) torch.float16
New cuda time: 12.270442008972168
New cuda time without quantization: 12.652202606201172
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.711402893066406
New cuda time without quantization: 14.588050842285156
torch.Size([524288, 768]) torch.float16
New cuda time: 14.643731117248535
New cuda time without quantization: 12.505002975463867
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.595723152160645
New cuda time without quantization: 16.469497680664062
torch.Size([524288, 768]) torch.float16
New cuda time: 16.56789779663086
New cuda time without quantization: 12.457322120666504
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.515722274780273
New cuda time without quantization: 18.862625122070312
torch.Size([524288, 768]) torch.float16
New cuda time: 18.92166519165039
New cuda time without quantization: 21.588876724243164
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.648876190185547
New cuda time without quantization: 12.216201782226562
torch.Size([524288, 768]) torch.float16
New cuda time: 12.301642417907715
New cuda time without quantization: 12.474763870239258
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.528204917907715
New cuda time without quantization: 12.168042182922363
torch.Size([524288, 768]) torch.float16
New cuda time: 12.22612190246582
New cuda time without quantization: 12.572043418884277
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.730124473571777
New cuda time without quantization: 12.071401596069336
torch.Size([524288, 768]) torch.float16
New cuda time: 12.126602172851562
New cuda time without quantization: 21.80327606201172
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.859596252441406
New cuda time without quantization: 17.916702270507812
torch.Size([524288, 768]) torch.float16
New cuda time: 17.969022750854492
New cuda time without quantization: 18.055261611938477
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.117822647094727
New cuda time without quantization: 12.724203109741211
torch.Size([524288, 768]) torch.float16
New cuda time: 12.781164169311523
New cuda time without quantization: 12.247241973876953
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.302122116088867
New cuda time without quantization: 21.694156646728516
torch.Size([524288, 768]) torch.float16
New cuda time: 21.75447654724121
New cuda time without quantization: 14.080207824707031
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 14.141327857971191
New cuda time without quantization: 12.163561820983887
torch.Size([524288, 768]) torch.float16
New cuda time: 12.222922325134277
New cuda time without quantization: 21.851116180419922
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.906795501708984
New cuda time without quantization: 12.343722343444824
torch.Size([524288, 768]) torch.float16
New cuda time: 12.40084171295166
New cuda time without quantization: 21.088232040405273
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.15287208557129
New cuda time without quantization: 23.1671199798584
torch.Size([524288, 768]) torch.float16
New cuda time: 23.21976089477539
New cuda time without quantization: 12.688203811645508
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.746443748474121
New cuda time without quantization: 22.62424087524414
torch.Size([524288, 768]) torch.float16
New cuda time: 22.680240631103516
New cuda time without quantization: 12.535082817077637
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.58996295928955
New cuda time without quantization: 22.18807601928711
torch.Size([524288, 768]) torch.float16
New cuda time: 22.247276306152344
New cuda time without quantization: 22.877519607543945
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.933839797973633
New cuda time without quantization: 12.23044204711914
torch.Size([524288, 768]) torch.float16
New cuda time: 12.285161972045898
New cuda time without quantization: 22.474477767944336
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.62599754333496
New cuda time without quantization: 12.388361930847168
torch.Size([524288, 768]) torch.float16
New cuda time: 12.473003387451172
New cuda time without quantization: 19.64934730529785
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 19.710468292236328
New cuda time without quantization: 12.097481727600098
torch.Size([524288, 768]) torch.float16
New cuda time: 12.158441543579102
New cuda time without quantization: 12.60948371887207
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.663884162902832
New cuda time without quantization: 11.922440528869629
torch.Size([524288, 768]) torch.float16
New cuda time: 12.092680931091309
New cuda time without quantization: 12.163561820983887
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.22340202331543
New cuda time without quantization: 12.048521995544434
torch.Size([524288, 768]) torch.float16
New cuda time: 12.110761642456055
New cuda time without quantization: 12.525643348693848
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.579723358154297
New cuda time without quantization: 21.5259952545166
torch.Size([524288, 768]) torch.float16
New cuda time: 21.59047508239746
New cuda time without quantization: 13.364846229553223
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 13.422765731811523
New cuda time without quantization: 12.09188175201416
torch.Size([524288, 768]) torch.float16
New cuda time: 12.149002075195312
New cuda time without quantization: 37.481571197509766
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 37.54365158081055
New cuda time without quantization: 12.12948226928711
torch.Size([524288, 768])torch.Size([524288, 768]) torch.float16
New cuda time: 18.129230499267578
New cuda time without quantization: 12.09036636352539
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.143325805664062
New cuda time without quantization: 18.158672332763672
torch.Size([524288, 768]) torch.float16
New cuda time: 18.215307235717773
New cuda time without quantization: 12.069886207580566
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.127805709838867
New cuda time without quantization: 18.348751068115234
torch.Size([524288, 768]) torch.float16
New cuda time: 18.403467178344727
New cuda time without quantization: 12.059005737304688
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.112606048583984
New cuda time without quantization: 11.943488121032715
torch.Size([524288, 768]) torch.float16
New cuda time: 11.99820613861084
New cuda time without quantization: 12.04140567779541
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.108125686645508
New cuda time without quantization: 11.809568405151367
torch.Size([524288, 768]) torch.float16
New cuda time: 11.886205673217773
New cuda time without quantization: 18.443628311157227
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.576587677001953
New cuda time without quantization: 11.96252727508545
torch.Size([524288, 768]) torch.float16
New cuda time: 12.015966415405273
New cuda time without quantization: 17.834829330444336
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.954669952392578
New cuda time without quantization: 15.447478294372559
torch.Size([524288, 768]) torch.float16
New cuda time: 15.504276275634766
New cuda time without quantization: 16.021554946899414
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.076435089111328
New cuda time without quantization: 11.914048194885254
torch.Size([524288, 768]) torch.float16
New cuda time: 11.9993257522583
New cuda time without quantization: 14.824278831481934
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 14.879158973693848
New cuda time without quantization: 11.674846649169922
torch.Size([524288, 768]) torch.float16
New cuda time: 11.856447219848633
New cuda time without quantization: 11.836286544799805
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.966046333312988
New cuda time without quantization: 11.971648216247559
torch.Size([524288, 768]) torch.float16
New cuda time: 12.031805992126465
New cuda time without quantization: 12.044925689697266
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.099486351013184
New cuda time without quantization: 14.58108139038086
torch.Size([524288, 768]) torch.float16
New cuda time: 14.637879371643066
New cuda time without quantization: 12.139805793762207
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.195646286010742
New cuda time without quantization: 16.198354721069336
torch.Size([524288, 768]) torch.float16
New cuda time: 16.254514694213867
New cuda time without quantization: 11.83100700378418
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.886366844177246
New cuda time without quantization: 18.749387741088867
torch.Size([524288, 768]) torch.float16
New cuda time: 18.82634735107422
New cuda time without quantization: 21.158981323242188
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.2205810546875
New cuda time without quantization: 11.907807350158691
torch.Size([524288, 768]) torch.float16
New cuda time: 11.98924732208252
New cuda time without quantization: 12.22364616394043
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.276605606079102
New cuda time without quantization: 11.965248107910156
torch.Size([524288, 768]) torch.float16
New cuda time: 12.021406173706055
New cuda time without quantization: 12.080925941467285
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.135966300964355
New cuda time without quantization: 11.938207626342773
torch.Size([524288, 768]) torch.float16
New cuda time: 11.99228572845459
New cuda time without quantization: 21.358179092407227
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.413379669189453
New cuda time without quantization: 17.709392547607422
torch.Size([524288, 768]) torch.float16
New cuda time: 17.762351989746094
New cuda time without quantization: 12.135326385498047
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.222366333007812
New cuda time without quantization: 11.673566818237305
torch.Size([524288, 768]) torch.float16
New cuda time: 11.728126525878906
New cuda time without quantization: 11.839966773986816
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.89388656616211
New cuda time without quantization: 21.348583221435547
torch.Size([524288, 768]) torch.float16
New cuda time: 21.40601921081543
New cuda time without quantization: 13.548602104187012
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 13.608282089233398
New cuda time without quantization: 11.946847915649414
torch.Size([524288, 768]) torch.float16
New cuda time: 12.031485557556152
New cuda time without quantization: 21.527780532836914
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.580900192260742
New cuda time without quantization: 12.027325630187988
torch.Size([524288, 768]) torch.float16
New cuda time: 12.079166412353516
New cuda time without quantization: 22.568098068237305
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 22.63929557800293
New cuda time without quantization: 15.17243766784668
torch.Size([524288, 768]) torch.float16
New cuda time: 15.226838111877441
New cuda time without quantization: 12.15212631225586
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.20732593536377
New cuda time without quantization: 22.494979858398438
torch.Size([524288, 768]) torch.float16
New cuda time: 22.55241584777832
New cuda time without quantization: 11.992767333984375
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.04876708984375
New cuda time without quantization: 21.95513916015625
torch.Size([524288, 768]) torch.float16
New cuda time: 22.023300170898438
New cuda time without quantization: 20.854984283447266
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 20.914823532104492
New cuda time without quantization: 11.923967361450195
torch.Size([524288, 768]) torch.float16
New cuda time: 11.987485885620117
New cuda time without quantization: 16.508434295654297
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 16.620914459228516
New cuda time without quantization: 12.037407875061035
torch.Size([524288, 768]) torch.float16
New cuda time: 12.11884593963623
New cuda time without quantization: 19.295787811279297
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 19.35546875
New cuda time without quantization: 11.950847625732422
torch.Size([524288, 768]) torch.float16
New cuda time: 12.009566307067871
New cuda time without quantization: 12.09788703918457
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.264606475830078
New cuda time without quantization: 29.52952003479004
torch.Size([524288, 768]) torch.float16
New cuda time: 29.589040756225586
New cuda time without quantization: 12.018366813659668
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.078685760498047
New cuda time without quantization: 11.811328887939453
torch.Size([524288, 768]) torch.float16
New cuda time: 11.870206832885742
New cuda time without quantization: 11.931647300720215
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.987167358398438
New cuda time without quantization: 13.97196102142334
torch.Size([524288, 768]) torch.float16
New cuda time: 14.03148078918457
New cuda time without quantization: 12.999963760375977
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 13.055803298950195
New cuda time without quantization: 11.927807807922363
torch.Size([524288, 768]) torch.float16
New cuda time: 11.984445571899414
New cuda time without quantization: 37.020538330078125
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 37.08789825439453
New cuda time without quantization: 11.933406829833984
torch.Size([524288, 768]) torch.float16
 torch.float16
New cuda time: 12.274601936340332
New cuda time without quantization: 66.08023071289062
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 66.1538314819336
New cuda time without quantization: 12.182442665100098
torch.Size([524288, 768]) torch.float16
New cuda time: 12.235722541809082
New cuda time without quantization: 18.455263137817383
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 18.50934410095215
New cuda time without quantization: 18.5064640045166
torch.Size([524288, 768]) torch.float16
New cuda time: 18.572864532470703
New cuda time without quantization: 12.039080619812012
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.096040725708008
New cuda time without quantization: 17.91846466064453
torch.Size([524288, 768]) torch.float16
New cuda time: 17.98054313659668
New cuda time without quantization: 12.559883117675781
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.614282608032227
2024-07-12 03:41:35 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
torch.float16
New cuda time: 12.22834300994873
New cuda time without quantization: 65.55292510986328
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 65.62092590332031
New cuda time without quantization: 12.16594409942627
torch.Size([524288, 768]) torch.float16
New cuda time: 12.21778392791748
New cuda time without quantization: 17.556034088134766
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.611553192138672
New cuda time without quantization: 16.6760311126709
torch.Size([524288, 768]) torch.float16
New cuda time: 16.73107147216797
New cuda time without quantization: 13.361945152282715
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 13.417625427246094
New cuda time without quantization: 18.069316864013672
torch.Size([524288, 768]) torch.float16
New cuda time: 18.13459587097168
New cuda time without quantization: 11.90146255493164
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 11.955862998962402
2024-07-12 03:41:35 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 12.02828598022461
New cuda time without quantization: 65.51262664794922
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 65.58094024658203
New cuda time without quantization: 12.015487670898438
torch.Size([524288, 768]) torch.float16
New cuda time: 12.069567680358887
New cuda time without quantization: 21.781700134277344
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 21.930660247802734
New cuda time without quantization: 13.79532241821289
torch.Size([524288, 768]) torch.float16
New cuda time: 13.846362113952637
New cuda time without quantization: 11.976607322692871
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.033726692199707
New cuda time without quantization: 17.648591995239258
torch.Size([524288, 768]) torch.float16
New cuda time: 17.706031799316406
New cuda time without quantization: 12.13676643371582
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.20300579071045
2024-07-12 03:41:35 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
torch.Size([524288, 768]) torch.float16
New cuda time: 12.02580738067627
New cuda time without quantization: 12.014607429504395
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.209967613220215
New cuda time without quantization: 11.692365646362305
torch.Size([524288, 768]) torch.float16
New cuda time: 11.760846138000488
New cuda time without quantization: 16.964868545532227
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 17.129667282104492
New cuda time without quantization: 13.697334289550781
torch.Size([524288, 768]) torch.float16
New cuda time: 13.753653526306152
New cuda time without quantization: 12.176848411560059
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.23572826385498
New cuda time without quantization: 11.941166877746582
torch.Size([524288, 768]) torch.float16
New cuda time: 12.022287368774414
New cuda time without quantization: 12.310288429260254
torch.Size([4, 128, 1024, 768]) torch.float16
New cuda time: 12.366288185119629
2024-07-12 03:41:35 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-12 03:41:35 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:41:35 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:41:35 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:41:35 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:41:35 | INFO | fairseq_cli.eval_lm | Evaluated 899,369 tokens in 35.5s (25333.39 tokens/s)
2024-07-12 03:41:35 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9221, Perplexity: 7.58
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
