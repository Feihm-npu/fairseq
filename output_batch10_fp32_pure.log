2024-07-12 03:26:03 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15142
2024-07-12 03:26:03 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15142
2024-07-12 03:26:03 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15142
2024-07-12 03:26:03 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15142
2024-07-12 03:26:03 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 1
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-12 03:26:04 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 2
2024-07-12 03:26:04 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 3
2024-07-12 03:26:04 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.05}", 'results_path': None, 'is_moe': True}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15142', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 10, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': 10, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 10}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | model	None
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 10, 'batch_size_valid': 10, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-12 03:26:05 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-12 03:26:05 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-12 03:26:05 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-12 03:26:05 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-12 03:26:07 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-12 03:26:11 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:26:13 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:26:16 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:26:19 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:26:21 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:26:24 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:26:26 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-12 03:26:40 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-12 03:26:49 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-12 03:26:55 | INFO | fairseq_cli.eval_lm | load time: 49.68 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
New cuda time without quantization: 9106.5849609375
torch.Size([524288, 768]) torch.float32
New cuda time: 9106.9208984375
New cuda time without quantization: 24.531288146972656
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.781208038330078
New cuda time without quantization: 316.6833801269531
torch.Size([524288, 768]) torch.float32
New cuda time: 316.83538818359375
New cuda time without quantization: 42.20143127441406
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 42.33551025390625
New cuda time without quantization: 39.420143127441406
torch.Size([524288, 768]) torch.float32
New cuda time: 39.67166519165039
New cuda time without quantization: 23.801523208618164
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.94296646118164
New cuda time without quantization: 32.80571746826172
torch.Size([524288, 768]) torch.float32
New cuda time: 32.90907669067383
New cuda time without quantization: 41.22910690307617
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 41.468631744384766
New cuda time without quantization: 31.20795249938965
torch.Size([524288, 768]) torch.float32
New cuda time: 31.26139259338379
New cuda time without quantization: 24.115928649902344
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.278968811035156
New cuda time without quantization: 29.59050750732422
torch.Size([524288, 768]) torch.float32
New cuda time: 29.66282844543457
New cuda time without quantization: 38.07453536987305
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 38.15101623535156
New cuda time without quantization: 23.67512321472168
torch.Size([524288, 768]) torch.float32
New cuda time: 23.753524780273438
New cuda time without quantization: 33.720279693603516
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.907325744628906
New cuda time without quantization: 32.08267593383789
torch.Size([524288, 768]) torch.float32
New cuda time: 32.16203689575195
New cuda time without quantization: 35.1514892578125
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 35.31148910522461
New cuda time without quantization: 25.525211334228516
torch.Size([524288, 768]) torch.float32
New cuda time: 25.614971160888672
New cuda time without quantization: 24.660888671875
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.7319278717041
New cuda time without quantization: 56.20036315917969
torch.Size([524288, 768]) torch.float32
New cuda time: 56.263084411621094
New cuda time without quantization: 23.74056625366211
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.876726150512695
New cuda time without quantization: 49.298255920410156
torch.Size([524288, 768]) torch.float32
New cuda time: 49.36737823486328
New cuda time without quantization: 23.830005645751953
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.982168197631836
New cuda time without quantization: 23.894485473632812
torch.Size([524288, 768]) torch.float32
New cuda time: 23.981685638427734
New cuda time without quantization: 41.538551330566406
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 41.623191833496094
New cuda time without quantization: 41.1555061340332
torch.Size([524288, 768]) torch.float32
New cuda time: 41.3043098449707
New cuda time without quantization: 23.966646194458008
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.137527465820312
New cuda time without quantization: 23.871925354003906
torch.Size([524288, 768]) torch.float32
New cuda time: 23.9296875
New cuda time without quantization: 25.417531967163086
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 35.24076843261719
New cuda time without quantization: 33.07419967651367
torch.Size([524288, 768]) torch.float32
New cuda time: 33.12699890136719
New cuda time without quantization: 23.833526611328125
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.995126724243164
New cuda time without quantization: 23.54552459716797
torch.Size([524288, 768]) torch.float32
New cuda time: 23.630964279174805
New cuda time without quantization: 25.214012145996094
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.323291778564453
New cuda time without quantization: 35.530208587646484
torch.Size([524288, 768]) torch.float32
New cuda time: 35.64556884765625
New cuda time without quantization: 23.87848663330078
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.960887908935547
New cuda time without quantization: 23.913206100463867
torch.Size([524288, 768]) torch.float32
New cuda time: 23.968406677246094
New cuda time without quantization: 33.92748260498047
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 34.11100387573242
New cuda time without quantization: 43.916481018066406
torch.Size([524288, 768]) torch.float32
New cuda time: 43.992801666259766
New cuda time without quantization: 25.885534286499023
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.02057456970215
New cuda time without quantization: 24.099767684936523
torch.Size([524288, 768]) torch.float32
New cuda time: 24.15176773071289
New cuda time without quantization: 23.82664680480957
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.958328247070312
New cuda time without quantization: 24.232248306274414
torch.Size([524288, 768]) torch.float32
New cuda time: 24.286487579345703
New cuda time without quantization: 25.559131622314453
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.620731353759766
New cuda time without quantization: 24.17816734313965
torch.Size([524288, 768]) torch.float32
New cuda time: 24.243928909301758
New cuda time without quantization: 25.56281280517578
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.626331329345703
New cuda time without quantization: 26.606016159057617
torch.Size([524288, 768]) torch.float32
New cuda time: 26.75993537902832
New cuda time without quantization: 25.111772537231445
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.25689125061035
New cuda time without quantization: 24.26264762878418
torch.Size([524288, 768]) torch.float32
New cuda time: 24.31560707092285
New cuda time without quantization: 24.78169059753418
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.872089385986328
New cuda time without quantization: 28.649864196777344
torch.Size([524288, 768]) torch.float32
New cuda time: 28.703784942626953
New cuda time without quantization: 28.008102416992188
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 28.1165828704834
New cuda time without quantization: 26.10505485534668
torch.Size([524288, 768]) torch.float32
New cuda time: 26.157535552978516
New cuda time without quantization: 26.275455474853516
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.39401626586914
New cuda time without quantization: 24.11528778076172
torch.Size([524288, 768]) torch.float32
New cuda time: 24.18792724609375
New cuda time without quantization: 25.945693969726562
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.00745391845703
New cuda time without quantization: 24.20728874206543
torch.Size([524288, 768]) torch.float32
New cuda time: 24.26344871520996
New cuda time without quantization: 28.26954460144043
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 28.331464767456055
New cuda time without quantization: 25.059452056884766
torch.Size([524288, 768]) torch.float32
New cuda time: 25.12569236755371
New cuda time without quantization: 25.97529411315918
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.03929328918457
New cuda time without quantization: 24.353208541870117
torch.Size([524288, 768]) torch.float32
New cuda time: 24.40888786315918
New cuda time without quantization: 24.760089874267578
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.822969436645508
New cuda time without quantization: 26.223295211791992
torch.Size([524288, 768]) torch.float32
New cuda time: 26.2860164642334
New cuda time without quantization: 25.989694595336914
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.095136642456055
New cuda time without quantization: 24.12872886657715
torch.Size([524288, 768]) New cuda time without quantization: 5032.31298828125
torch.Size([524288, 768]) torch.float32
New cuda time: 5032.623046875
New cuda time without quantization: 23.720735549926758
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.979936599731445
New cuda time without quantization: 354.3489990234375
torch.Size([524288, 768]) torch.float32
New cuda time: 354.65203857421875
New cuda time without quantization: 49.912506103515625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 49.9993896484375
New cuda time without quantization: 31.806156158447266
torch.Size([524288, 768]) torch.float32
New cuda time: 31.891435623168945
New cuda time without quantization: 38.723575592041016
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 38.79733657836914
New cuda time without quantization: 23.60921859741211
torch.Size([524288, 768]) torch.float32
New cuda time: 23.729215621948242
New cuda time without quantization: 41.630611419677734
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 41.689170837402344
New cuda time without quantization: 29.872880935668945
torch.Size([524288, 768]) torch.float32
New cuda time: 30.097999572753906
New cuda time without quantization: 32.23735427856445
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.365196228027344
New cuda time without quantization: 39.0440559387207
torch.Size([524288, 768]) torch.float32
New cuda time: 39.157657623291016
New cuda time without quantization: 32.980712890625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.04343032836914
New cuda time without quantization: 39.50629425048828
torch.Size([524288, 768]) torch.float32
New cuda time: 39.63925552368164
New cuda time without quantization: 40.87029266357422
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 40.93989181518555
New cuda time without quantization: 23.66729736328125
torch.Size([524288, 768]) torch.float32
New cuda time: 23.876895904541016
New cuda time without quantization: 41.22597122192383
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 41.28517150878906
New cuda time without quantization: 23.488258361816406
torch.Size([524288, 768]) torch.float32
New cuda time: 23.58793830871582
New cuda time without quantization: 32.87831115722656
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.9447135925293
New cuda time without quantization: 55.902095794677734
torch.Size([524288, 768]) torch.float32
New cuda time: 55.97937774658203
New cuda time without quantization: 32.28551483154297
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.39191436767578
New cuda time without quantization: 39.838134765625
torch.Size([524288, 768]) torch.float32
New cuda time: 39.89429473876953
New cuda time without quantization: 31.09303855895996
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.157197952270508
New cuda time without quantization: 23.626497268676758
torch.Size([524288, 768]) torch.float32
New cuda time: 23.72537612915039
New cuda time without quantization: 33.403751373291016
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.69719314575195
New cuda time without quantization: 39.4365348815918
torch.Size([524288, 768]) torch.float32
New cuda time: 39.49429702758789
New cuda time without quantization: 32.47367477416992
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.60023498535156
New cuda time without quantization: 23.852415084838867
torch.Size([524288, 768]) torch.float32
New cuda time: 23.90937614440918
New cuda time without quantization: 33.019752502441406
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.196231842041016
New cuda time without quantization: 33.14247131347656
torch.Size([524288, 768]) torch.float32
New cuda time: 33.196231842041016
New cuda time without quantization: 24.27337646484375
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.405536651611328
New cuda time without quantization: 32.095115661621094
torch.Size([524288, 768]) torch.float32
New cuda time: 32.156394958496094
New cuda time without quantization: 23.727136611938477
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.806495666503906
New cuda time without quantization: 32.3699951171875
torch.Size([524288, 768]) torch.float32
New cuda time: 32.43095779418945
New cuda time without quantization: 26.47064971923828
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.635929107666016
New cuda time without quantization: 23.48969841003418
torch.Size([524288, 768]) torch.float32
New cuda time: 23.545377731323242
New cuda time without quantization: 41.931888580322266
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 41.990447998046875
New cuda time without quantization: 34.535911560058594
torch.Size([524288, 768]) torch.float32
New cuda time: 34.594146728515625
New cuda time without quantization: 23.795135498046875
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.953216552734375
New cuda time without quantization: 23.54041862487793
torch.Size([524288, 768]) torch.float32
New cuda time: 23.626497268676758
New cuda time without quantization: 29.694801330566406
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.825361251831055
New cuda time without quantization: 23.804096221923828
torch.Size([524288, 768]) torch.float32
New cuda time: 23.89017677307129
New cuda time without quantization: 24.291296005249023
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.346176147460938
New cuda time without quantization: 23.5933780670166
torch.Size([524288, 768]) torch.float32
New cuda time: 23.653697967529297
New cuda time without quantization: 23.941375732421875
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.072416305541992
New cuda time without quantization: 25.735931396484375
torch.Size([524288, 768]) torch.float32
New cuda time: 25.787771224975586
New cuda time without quantization: 24.686336517333984
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.756736755371094
New cuda time without quantization: 23.519777297973633
torch.Size([524288, 768]) torch.float32
New cuda time: 23.57417869567871
New cuda time without quantization: 24.59609603881836
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.66441535949707
New cuda time without quantization: 28.73448371887207
torch.Size([524288, 768]) torch.float32
New cuda time: 28.79000473022461
New cuda time without quantization: 23.809375762939453
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.97305679321289
New cuda time without quantization: 25.347454071044922
torch.Size([524288, 768]) torch.float32
New cuda time: 25.39977264404297
New cuda time without quantization: 24.10825538635254
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.335615158081055
New cuda time without quantization: 23.42681884765625
torch.Size([524288, 768]) torch.float32
New cuda time: 23.478017807006836
New cuda time without quantization: 24.624576568603516
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.681055068969727
New cuda time without quantization: 23.61577796936035
torch.Size([524288, 768]) torch.float32
New cuda time: 23.703298568725586
New cuda time without quantization: 26.82328987121582
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.882488250732422
New cuda time without quantization: 24.39913558959961
torch.Size([524288, 768]) torch.float32
New cuda time: 24.470016479492188
New cuda time without quantization: 24.459936141967773
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.523935317993164
New cuda time without quantization: 23.757057189941406
torch.Size([524288, 768]) torch.float32
New cuda time: 23.81433868408203
New cuda time without quantization: 24.4965763092041
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.5578556060791
New cuda time without quantization: 24.314016342163086
torch.Size([524288, 768]) torch.float32
New cuda time: 24.374656677246094
New cuda time without quantization: 24.003616333007812
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.12041664123535
New cuda time without quantization: 23.644258499145508
torch.Size([524288, 768]) New cuda time without quantization: 3988.124267578125
torch.Size([524288, 768]) torch.float32
New cuda time: 3988.415283203125
New cuda time without quantization: 33.60118865966797
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.71542739868164
New cuda time without quantization: 369.6313171386719
torch.Size([524288, 768]) torch.float32
New cuda time: 369.88348388671875
New cuda time without quantization: 40.775604248046875
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 40.85768508911133
New cuda time without quantization: 31.922943115234375
torch.Size([524288, 768]) torch.float32
New cuda time: 32.007904052734375
New cuda time without quantization: 29.254779815673828
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.313020706176758
New cuda time without quantization: 32.90022659301758
torch.Size([524288, 768]) torch.float32
New cuda time: 32.98358917236328
New cuda time without quantization: 34.78743362426758
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 34.86871337890625
New cuda time without quantization: 37.49383544921875
torch.Size([524288, 768]) torch.float32
New cuda time: 37.5475959777832
New cuda time without quantization: 23.789487838745117
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.930767059326172
New cuda time without quantization: 33.04374694824219
torch.Size([524288, 768]) torch.float32
New cuda time: 33.09830856323242
New cuda time without quantization: 30.096221923828125
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.16598129272461
New cuda time without quantization: 50.793704986572266
torch.Size([524288, 768]) torch.float32
New cuda time: 50.87562561035156
New cuda time without quantization: 33.014469146728516
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.10774612426758
New cuda time without quantization: 31.84422492980957
torch.Size([524288, 768]) torch.float32
New cuda time: 31.920223236083984
New cuda time without quantization: 33.41702651977539
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.5259895324707
New cuda time without quantization: 33.09334945678711
torch.Size([524288, 768]) torch.float32
New cuda time: 33.16518783569336
New cuda time without quantization: 23.73588752746582
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.828367233276367
New cuda time without quantization: 32.734466552734375
torch.Size([524288, 768]) torch.float32
New cuda time: 32.789188385009766
New cuda time without quantization: 47.015777587890625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 47.14441680908203
New cuda time without quantization: 41.43944549560547
torch.Size([524288, 768]) torch.float32
New cuda time: 41.49528503417969
New cuda time without quantization: 30.395742416381836
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.58710479736328
New cuda time without quantization: 23.62500762939453
torch.Size([524288, 768]) torch.float32
New cuda time: 23.679248809814453
New cuda time without quantization: 51.14602279663086
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 51.350982666015625
New cuda time without quantization: 32.13510513305664
torch.Size([524288, 768]) torch.float32
New cuda time: 32.20918655395508
New cuda time without quantization: 32.55382537841797
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.68838882446289
New cuda time without quantization: 23.457168579101562
torch.Size([524288, 768]) torch.float32
New cuda time: 23.506288528442383
New cuda time without quantization: 43.17048645019531
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 43.31448745727539
New cuda time without quantization: 33.35862731933594
torch.Size([524288, 768]) torch.float32
New cuda time: 33.410789489746094
New cuda time without quantization: 32.16422653198242
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.273826599121094
New cuda time without quantization: 24.670291900634766
torch.Size([524288, 768]) torch.float32
New cuda time: 24.764692306518555
New cuda time without quantization: 33.64006805419922
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.70950698852539
New cuda time without quantization: 35.27287292480469
torch.Size([524288, 768]) torch.float32
New cuda time: 35.48967361450195
New cuda time without quantization: 31.3035831451416
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.372543334960938
New cuda time without quantization: 23.64628791809082
torch.Size([524288, 768]) torch.float32
New cuda time: 23.70212745666504
New cuda time without quantization: 32.869346618652344
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.96070861816406
New cuda time without quantization: 40.445682525634766
torch.Size([524288, 768]) torch.float32
New cuda time: 40.520084381103516
New cuda time without quantization: 36.41047668457031
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 36.47223663330078
New cuda time without quantization: 24.089967727661133
torch.Size([524288, 768]) torch.float32
New cuda time: 24.147727966308594
New cuda time without quantization: 29.8082218170166
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.93958282470703
New cuda time without quantization: 23.88484764099121
torch.Size([524288, 768]) torch.float32
New cuda time: 23.942127227783203
New cuda time without quantization: 24.545011520385742
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.608051300048828
New cuda time without quantization: 23.613807678222656
torch.Size([524288, 768]) torch.float32
New cuda time: 23.673648834228516
New cuda time without quantization: 24.70005226135254
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.76517105102539
New cuda time without quantization: 25.882932662963867
torch.Size([524288, 768]) torch.float32
New cuda time: 25.9390926361084
New cuda time without quantization: 24.11764907836914
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.18773078918457
New cuda time without quantization: 23.861488342285156
torch.Size([524288, 768]) torch.float32
New cuda time: 23.932048797607422
New cuda time without quantization: 28.529499053955078
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 28.715900421142578
New cuda time without quantization: 23.608688354492188
torch.Size([524288, 768]) torch.float32
New cuda time: 23.670127868652344
New cuda time without quantization: 26.48133659362793
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.5430965423584
New cuda time without quantization: 26.085813522338867
torch.Size([524288, 768]) torch.float32
New cuda time: 26.249174118041992
New cuda time without quantization: 24.453012466430664
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.591251373291016
New cuda time without quantization: 23.754127502441406
torch.Size([524288, 768]) torch.float32
New cuda time: 23.812847137451172
New cuda time without quantization: 24.42629051208496
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.533010482788086
New cuda time without quantization: 23.662607192993164
torch.Size([524288, 768]) torch.float32
New cuda time: 23.719568252563477
New cuda time without quantization: 27.63221549987793
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 27.69589614868164
New cuda time without quantization: 24.55908966064453
torch.Size([524288, 768]) torch.float32
New cuda time: 24.652210235595703
New cuda time without quantization: 24.088048934936523
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.145647048950195
New cuda time without quantization: 23.89124870300293
torch.Size([524288, 768]) torch.float32
New cuda time: 23.956687927246094
New cuda time without quantization: 24.789012908935547
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.856212615966797
New cuda time without quantization: 24.244850158691406
torch.Size([524288, 768]) torch.float32
New cuda time: 24.308530807495117
New cuda time without quantization: 24.950611114501953
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.0168514251709
New cuda time without quantization: 23.893327713012695
New cuda time without quantization: 928.5462036132812
torch.Size([524288, 768]) torch.float32
New cuda time: 928.8727416992188
New cuda time without quantization: 32.3033332824707
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.41933059692383
New cuda time without quantization: 32.87117385864258
torch.Size([524288, 768]) torch.float32
New cuda time: 32.943172454833984
New cuda time without quantization: 23.96521759033203
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.287460327148438
New cuda time without quantization: 31.010526657104492
torch.Size([524288, 768]) torch.float32
New cuda time: 31.095645904541016
New cuda time without quantization: 30.35084342956543
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.414844512939453
New cuda time without quantization: 25.46602439880371
torch.Size([524288, 768]) torch.float32
New cuda time: 25.55018424987793
New cuda time without quantization: 29.850200653076172
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.1082820892334
New cuda time without quantization: 23.598175048828125
torch.Size([524288, 768]) torch.float32
New cuda time: 23.654495239257812
New cuda time without quantization: 31.55788803100586
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.679807662963867
New cuda time without quantization: 31.274368286132812
torch.Size([524288, 768]) torch.float32
New cuda time: 31.3286075592041
New cuda time without quantization: 47.338592529296875
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 47.41875076293945
New cuda time without quantization: 31.15804672241211
torch.Size([524288, 768]) torch.float32
New cuda time: 31.235647201538086
New cuda time without quantization: 40.2992057800293
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 40.360965728759766
New cuda time without quantization: 32.720130920410156
torch.Size([524288, 768]) torch.float32
New cuda time: 32.80061340332031
New cuda time without quantization: 23.80681610107422
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.885215759277344
New cuda time without quantization: 32.469093322753906
torch.Size([524288, 768]) torch.float32
New cuda time: 32.548770904541016
New cuda time without quantization: 32.26061248779297
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.323333740234375
New cuda time without quantization: 32.67885208129883
torch.Size([524288, 768]) torch.float32
New cuda time: 32.7318115234375
New cuda time without quantization: 54.96566390991211
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 55.068382263183594
New cuda time without quantization: 31.29532814025879
torch.Size([524288, 768]) torch.float32
New cuda time: 31.459327697753906
New cuda time without quantization: 30.17388343811035
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.2334041595459
New cuda time without quantization: 24.159303665161133
torch.Size([524288, 768]) torch.float32
New cuda time: 24.25178337097168
New cuda time without quantization: 41.229766845703125
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 41.28944778442383
New cuda time without quantization: 31.67308807373047
torch.Size([524288, 768]) torch.float32
New cuda time: 31.73084831237793
New cuda time without quantization: 30.94316864013672
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.002687454223633
New cuda time without quantization: 24.01897621154785
torch.Size([524288, 768]) torch.float32
New cuda time: 24.072416305541992
New cuda time without quantization: 32.321250915527344
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.37997055053711
New cuda time without quantization: 42.7516975402832
torch.Size([524288, 768]) torch.float32
New cuda time: 42.82465744018555
New cuda time without quantization: 31.48908805847168
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.60188865661621
New cuda time without quantization: 31.549087524414062
torch.Size([524288, 768]) torch.float32
New cuda time: 31.605247497558594
New cuda time without quantization: 33.04541778564453
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.10557556152344
New cuda time without quantization: 33.11213684082031
torch.Size([524288, 768]) torch.float32
New cuda time: 33.16493606567383
New cuda time without quantization: 33.11005783081055
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.17853546142578
New cuda time without quantization: 23.798175811767578
torch.Size([524288, 768]) torch.float32
New cuda time: 23.859615325927734
New cuda time without quantization: 41.226566314697266
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 41.2857666015625
New cuda time without quantization: 33.62909698486328
torch.Size([524288, 768]) torch.float32
New cuda time: 33.68445587158203
New cuda time without quantization: 42.26177215576172
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 42.32337188720703
New cuda time without quantization: 23.637535095214844
torch.Size([524288, 768]) torch.float32
New cuda time: 23.68921661376953
New cuda time without quantization: 29.360599517822266
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.421560287475586
New cuda time without quantization: 23.38489532470703
torch.Size([524288, 768]) torch.float32
New cuda time: 23.441055297851562
New cuda time without quantization: 23.620895385742188
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.693056106567383
New cuda time without quantization: 23.462495803833008
torch.Size([524288, 768]) torch.float32
New cuda time: 23.531295776367188
New cuda time without quantization: 23.718175888061523
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.77529525756836
New cuda time without quantization: 25.649063110351562
torch.Size([524288, 768]) torch.float32
New cuda time: 25.703624725341797
New cuda time without quantization: 23.82761573791504
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.894817352294922
New cuda time without quantization: 23.59529685974121
torch.Size([524288, 768]) torch.float32
New cuda time: 23.64873504638672
New cuda time without quantization: 27.27547264099121
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 27.33451271057129
New cuda time without quantization: 24.446819305419922
torch.Size([524288, 768]) torch.float32
New cuda time: 24.504899978637695
New cuda time without quantization: 25.179304122924805
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.295303344726562
New cuda time without quantization: 23.26569366455078
torch.Size([524288, 768]) torch.float32
New cuda time: 23.319936752319336
New cuda time without quantization: 23.54761505126953
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.649215698242188
New cuda time without quantization: 23.551776885986328
torch.Size([524288, 768]) torch.float32
New cuda time: 23.60361671447754
New cuda time without quantization: 23.669696807861328
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.728736877441406
New cuda time without quantization: 23.496095657348633
torch.Size([524288, 768]) torch.float32
New cuda time: 23.551776885986328
New cuda time without quantization: 23.74985694885254
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.081859588623047
New cuda time without quantization: 23.48441505432129
torch.Size([524288, 768]) torch.float32
New cuda time: 23.577695846557617
New cuda time without quantization: 24.0506591796875
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.115459442138672
New cuda time without quantization: 23.610496520996094
torch.Size([524288, 768]) torch.float32
New cuda time: 23.6680965423584
New cuda time without quantization: 23.866817474365234
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.064897537231445
New cuda time without quantization: 23.30713653564453
torch.Size([524288, 768]) torch.float32
New cuda time: 23.3621768951416
New cuda time without quantization: 23.49737548828125
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.556095123291016
New cuda time without quantization: 23.90297508239746
torch.Size([524288, 768]) torch.float32
New cuda time: 24.04777717590332
New cuda time without quantization: 23.54761505126953
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.661535263061523
New cuda time without quantization: 23.343135833740234
torch.Size([524288, 768]) torch.float32
New cuda time: 23.396575927734375
New cuda time without quantization: 23.567455291748047
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.632415771484375
New cuda time without quantization: 28.27579689025879
torch.Size([524288, 768]) torch.float32
New cuda time: 28.329715728759766
New cuda time without quantization: 26.221548080444336
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.318828582763672
New cuda time without quantization: 23.479455947875977
torch.Size([524288, 768]) torch.float32
New cuda time: 23.537216186523438
New cuda time without quantization: 24.01177978515625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.07513999938965
New cuda time without quantization: 25.404743194580078
torch.Size([524288, 768]) torch.float32
New cuda time: 25.467464447021484
New cuda time without quantization: 31.46460723876953
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.5238094329834
New cuda time without quantization: 23.78169822692871
torch.Size([524288, 768]) torch.float32
New cuda time: 23.84073829650879
New cuda time without quantization: 29.887163162231445
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.954204559326172
New cuda time without quantization: 33.902061462402344
torch.Size([524288, 768]) torch.float32
New cuda time: 33.957420349121094
New cuda time without quantization: 29.85756492614746
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.966203689575195
New cuda time without quantization: 23.46441650390625
torch.Size([524288, 768]) torch.float32
New cuda time: 23.51705551147461
New cuda time without quantization: 29.1458797454834
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.212440490722656
New cuda time without quantization: 31.9444522857666
torch.Size([524288, 768]) torch.float32
New cuda time: 31.99677276611328
New cuda time without quantization: 31.196287155151367
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.257728576660156
New cuda time without quantization: 23.973377227783203
torch.Size([524288, 768]) torch.float32
New cuda time: 24.026018142700195
New cuda time without quantization: 29.595640182495117
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.663482666015625
New cuda time without quantization: 32.25277328491211
torch.Size([524288, 768]) torch.float32
New cuda time: 32.3095703125
New cuda time without quantization: 31.80173110961914
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.86205291748047
New cuda time without quantization: 23.916257858276367
torch.Size([524288, 768]) torch.float32
New cuda time: 23.9754581451416
New cuda time without quantization: 30.43116569519043
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.498046875
New cuda time without quantization: 31.74957275390625
torch.Size([524288, 768]) torch.float32
New cuda time: 31.84349250793457
New cuda time without quantization: 29.76988410949707
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.83324432373047
New cuda time without quantization: 23.420896530151367
torch.Size([524288, 768]) torch.float32
New cuda time: 23.503135681152344
New cuda time without quantization: 29.74668312072754
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.813404083251953
New cuda time without quantization: 31.59453010559082
torch.Size([524288, 768]) torch.float32
New cuda time: 31.649250030517578
New cuda time without quantization: 30.847328186035156
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.908607482910156
New cuda time without quantization: 34.615665435791016
torch.Size([524288, 768]) torch.float32
New cuda time: 34.680145263671875
New cuda time without quantization: 30.255163192749023
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.320446014404297
New cuda time without quantization: 32.65069580078125
torch.Size([524288, 768]) torch.float32
New cuda time: 32.7102165222168
New cuda time without quantization: 31.69773292541504
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.768131256103516
New cuda time without quantization: 32.8234977722168
torch.Size([524288, 768]) torch.float32
New cuda time: 32.878055572509766
New cuda time without quantization: 32.71357727050781
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.82941436767578
New cuda time without quantization: 30.760448455810547
torch.Size([524288, 768]) torch.float32
New cuda time: 30.813087463378906
New cuda time without quantization: 28.208595275878906
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 28.321718215942383
New cuda time without quantization: 31.94573211669922
torch.Size([524288, 768]) torch.float32
New cuda time: 32.03725051879883
New cuda time without quantization: 30.099163055419922
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.15708351135254
New cuda time without quantization: 32.46653366088867
torch.Size([524288, 768]) torch.float32
New cuda time: 32.5252571105957
New cuda time without quantization: 28.513879776000977
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 28.593719482421875
New cuda time without quantization: 23.586177825927734
torch.Size([524288, 768]) torch.float32
New cuda time: 23.641698837280273
New cuda time without quantization: 31.723491668701172
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.782211303710938
New cuda time without quantization: 31.240449905395508
torch.Size([524288, 768]) torch.float32
New cuda time: 31.30525016784668
New cuda time without quantization: 32.0850944519043
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.143653869628906
New cuda time without quantization: 33.858699798583984
torch.Size([524288, 768]) torch.float32
New cuda time: 33.91421890258789
New cuda time without quantization: 39.3264045715332
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 39.395843505859375
New cuda time without quantization: 23.70473861694336
torch.Size([524288, 768]) torch.float32
New cuda time: 23.758338928222656
New cuda time without quantization: 32.150054931640625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.27085494995117
New cuda time without quantization: 33.05613708496094
torch.Size([524288, 768]) torch.float32
New cuda time: 33.13789749145508
New cuda time without quantization: 33.010379791259766
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.07517623901367
New cuda time without quantization: 32.61917495727539
torch.Size([524288, 768]) torch.float32
New cuda time: 32.674537658691406
New cuda time without quantization: 30.35308837890625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.414527893066406
New cuda time without quantization: 31.97965431213379
torch.Size([524288, 768]) torch.float32
New cuda time: 32.04701232910156
New cuda time without quantization: 38.71903991699219
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 38.77568054199219
New cuda time without quantization: 25.988908767700195
torch.Size([524288, 768]) torch.float32
New cuda time: 26.042827606201172
New cuda time without quantization: 31.732772827148438
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.794532775878906
New cuda time without quantization: 31.125410079956055
torch.Size([524288, 768]) torch.float32
New cuda time: 31.181411743164062
New cuda time without quantization: 32.15149688720703
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.269256591796875
New cuda time without quantization: 23.638500213623047
torch.Size([524288, 768]) torch.float32
New cuda time: 23.692739486694336
New cuda time without quantization: 31.894052505493164
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.01677322387695
New cuda time without quantization: 31.892932891845703
torch.Size([524288, 768]) torch.float32
New cuda time: 31.974851608276367
torch.float32
New cuda time: 24.278648376464844
New cuda time without quantization: 27.01593780517578
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 27.07817840576172
New cuda time without quantization: 24.157367706298828
torch.Size([524288, 768]) torch.float32
New cuda time: 24.209848403930664
New cuda time without quantization: 25.819293975830078
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.882173538208008
New cuda time without quantization: 23.486324310302734
torch.Size([524288, 768]) torch.float32
New cuda time: 23.549524307250977
New cuda time without quantization: 27.692419052124023
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 27.754980087280273
New cuda time without quantization: 24.420087814331055
torch.Size([524288, 768]) torch.float32
New cuda time: 24.47528839111328
New cuda time without quantization: 25.828733444213867
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.890974044799805
New cuda time without quantization: 23.480724334716797
torch.Size([524288, 768]) torch.float32
New cuda time: 23.575124740600586
New cuda time without quantization: 23.893367767333984
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.07976722717285
New cuda time without quantization: 23.982168197631836
torch.Size([524288, 768]) torch.float32
New cuda time: 24.117687225341797
New cuda time without quantization: 26.252897262573242
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.313859939575195
New cuda time without quantization: 23.544246673583984
torch.Size([524288, 768]) torch.float32
New cuda time: 23.603925704956055
New cuda time without quantization: 23.860088348388672
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.03000831604004
New cuda time without quantization: 23.863128662109375
torch.Size([524288, 768]) torch.float32
New cuda time: 23.93880844116211
New cuda time without quantization: 23.885208129882812
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.968408584594727
New cuda time without quantization: 23.706165313720703
torch.Size([524288, 768]) torch.float32
New cuda time: 23.77000617980957
New cuda time without quantization: 24.088727951049805
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.249528884887695
New cuda time without quantization: 24.083768844604492
torch.Size([524288, 768]) torch.float32
New cuda time: 24.138328552246094
New cuda time without quantization: 23.878007888793945
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.965368270874023
New cuda time without quantization: 23.61192512512207
torch.Size([524288, 768]) torch.float32
New cuda time: 23.68824577331543
New cuda time without quantization: 23.890487670898438
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.980247497558594
New cuda time without quantization: 24.599769592285156
torch.Size([524288, 768]) torch.float32
New cuda time: 24.65144920349121
New cuda time without quantization: 23.746488571166992
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.96824836730957
New cuda time without quantization: 23.548086166381836
torch.Size([524288, 768]) torch.float32
New cuda time: 23.627445220947266
New cuda time without quantization: 23.798648834228516
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.93832778930664
New cuda time without quantization: 23.944087982177734
torch.Size([524288, 768]) torch.float32
New cuda time: 24.01896858215332
New cuda time without quantization: 23.882648468017578
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.02168846130371
New cuda time without quantization: 23.63864517211914
torch.Size([524288, 768]) torch.float32
New cuda time: 23.714168548583984
New cuda time without quantization: 24.06568717956543
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.21192741394043
New cuda time without quantization: 34.152122497558594
torch.Size([524288, 768]) torch.float32
New cuda time: 34.208763122558594
New cuda time without quantization: 23.86520767211914
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.064247131347656
New cuda time without quantization: 23.65016746520996
torch.Size([524288, 768]) torch.float32
New cuda time: 23.72536849975586
New cuda time without quantization: 23.986328125
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.095767974853516
New cuda time without quantization: 34.64332962036133
torch.Size([524288, 768]) torch.float32
New cuda time: 34.71468734741211
New cuda time without quantization: 41.95503234863281
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 42.066871643066406
New cuda time without quantization: 23.707128524780273
torch.Size([524288, 768]) torch.float32
New cuda time: 23.762487411499023
New cuda time without quantization: 23.992727279663086
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.064727783203125
New cuda time without quantization: 31.49739646911621
torch.Size([524288, 768]) torch.float32
New cuda time: 31.61179542541504
New cuda time without quantization: 24.022808074951172
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.086488723754883
New cuda time without quantization: 23.75096893310547
torch.Size([524288, 768]) torch.float32
New cuda time: 23.851768493652344
New cuda time without quantization: 23.73592758178711
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.806007385253906
New cuda time without quantization: 24.118488311767578
torch.Size([524288, 768]) torch.float32
New cuda time: 24.17144775390625
New cuda time without quantization: 25.12137222290039
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.20937156677246
New cuda time without quantization: 23.585525512695312
torch.Size([524288, 768]) torch.float32
New cuda time: 23.723127365112305
New cuda time without quantization: 23.875768661499023
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.95416831970215
New cuda time without quantization: 45.07472610473633
torch.Size([524288, 768]) torch.float32
New cuda time: 45.24688720703125
New cuda time without quantization: 23.905527114868164
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.063447952270508
New cuda time without quantization: 23.949687957763672
torch.Size([524288, 768]) torch.float32
New cuda time: 24.009687423706055
New cuda time without quantization: 26.49081802368164
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.65753746032715
New cuda time without quantization: 34.0727653503418
torch.Size([524288, 768]) torch.float32
New cuda time: 34.19772720336914
New cuda time without quantization: 43.856483459472656
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 43.9248046875
New cuda time without quantization: 24.180248260498047
torch.Size([524288, 768]) torch.float32
New cuda time: 24.233688354492188
New cuda time without quantization: 23.828088760375977
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.9152889251709
New cuda time without quantization: 41.0519905090332
torch.Size([524288, 768]) torch.float32
New cuda time: 41.1215934753418
New cuda time without quantization: 35.41917037963867
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 35.5212516784668
New cuda time without quantization: 23.865047454833984
torch.Size([524288, 768]) torch.float32
New cuda time: 23.917848587036133
New cuda time without quantization: 23.609527587890625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.689847946166992
New cuda time without quantization: 23.350805282592773
torch.Size([524288, 768]) torch.float32
New cuda time: 23.426485061645508
New cuda time without quantization: 25.864736557006836
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.96121597290039
New cuda time without quantization: 24.12616729736328
torch.Size([524288, 768]) torch.float32
New cuda time: 24.183767318725586
New cuda time without quantization: 25.41161346435547
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.552894592285156
New cuda time without quantization: 23.74936866760254
torch.Size([524288, 768]) torch.float32
New cuda time: 23.927288055419922
torch.Size([524288, 768]) torch.float32
New cuda time: 24.033327102661133
New cuda time without quantization: 24.640851974487305
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.785812377929688
New cuda time without quantization: 23.558927536010742
torch.Size([524288, 768]) torch.float32
New cuda time: 23.619247436523438
New cuda time without quantization: 24.48101043701172
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.542449951171875
New cuda time without quantization: 28.76214027404785
torch.Size([524288, 768]) torch.float32
New cuda time: 28.823579788208008
New cuda time without quantization: 26.95093536376953
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 27.014455795288086
New cuda time without quantization: 23.97060775756836
torch.Size([524288, 768]) torch.float32
New cuda time: 24.03188705444336
New cuda time without quantization: 24.045169830322266
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.12628936767578
New cuda time without quantization: 25.850772857666016
torch.Size([524288, 768]) torch.float32
New cuda time: 25.906612396240234
New cuda time without quantization: 32.25702667236328
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.3843879699707
New cuda time without quantization: 23.83380889892578
torch.Size([524288, 768]) torch.float32
New cuda time: 23.895408630371094
New cuda time without quantization: 34.23799133300781
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 34.30695343017578
New cuda time without quantization: 31.12486457824707
torch.Size([524288, 768]) torch.float32
New cuda time: 31.180543899536133
New cuda time without quantization: 30.917984008789062
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.047903060913086
New cuda time without quantization: 23.950607299804688
torch.Size([524288, 768]) torch.float32
New cuda time: 24.031089782714844
New cuda time without quantization: 27.750938415527344
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 27.81941795349121
New cuda time without quantization: 32.11894989013672
torch.Size([524288, 768]) torch.float32
New cuda time: 32.17414855957031
New cuda time without quantization: 32.1589469909668
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.28886795043945
New cuda time without quantization: 24.104690551757812
torch.Size([524288, 768]) torch.float32
New cuda time: 24.160850524902344
New cuda time without quantization: 29.81574249267578
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.893821716308594
New cuda time without quantization: 32.45158767700195
torch.Size([524288, 768]) torch.float32
New cuda time: 32.54166793823242
New cuda time without quantization: 32.824867248535156
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.91014862060547
New cuda time without quantization: 23.62628746032715
torch.Size([524288, 768]) torch.float32
New cuda time: 23.688688278198242
New cuda time without quantization: 31.87030792236328
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.00246810913086
New cuda time without quantization: 32.08614730834961
torch.Size([524288, 768]) torch.float32
New cuda time: 32.146629333496094
New cuda time without quantization: 30.582624435424805
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.727264404296875
New cuda time without quantization: 24.020530700683594
torch.Size([524288, 768]) torch.float32
New cuda time: 24.106769561767578
New cuda time without quantization: 27.45189666748047
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 27.520856857299805
New cuda time without quantization: 31.728225708007812
torch.Size([524288, 768]) torch.float32
New cuda time: 31.78294563293457
New cuda time without quantization: 31.83974838256836
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.89702796936035
New cuda time without quantization: 34.745670318603516
torch.Size([524288, 768]) torch.float32
New cuda time: 34.93319320678711
New cuda time without quantization: 30.114782333374023
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.175262451171875
New cuda time without quantization: 32.90214920043945
torch.Size([524288, 768]) torch.float32
New cuda time: 32.95686721801758
New cuda time without quantization: 24.03668975830078
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.23764991760254
New cuda time without quantization: 32.943267822265625
torch.Size([524288, 768]) torch.float32
New cuda time: 32.999427795410156
New cuda time without quantization: 32.022789001464844
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.101348876953125
New cuda time without quantization: 23.537328720092773
torch.Size([524288, 768]) torch.float32
New cuda time: 23.58964729309082
New cuda time without quantization: 29.211580276489258
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.331899642944336
New cuda time without quantization: 23.63876724243164
torch.Size([524288, 768]) torch.float32
New cuda time: 23.757648468017578
New cuda time without quantization: 30.91302490234375
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.9704647064209
New cuda time without quantization: 32.60422897338867
torch.Size([524288, 768]) torch.float32
New cuda time: 32.6619873046875
New cuda time without quantization: 23.755569458007812
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.837810516357422
New cuda time without quantization: 23.797489166259766
torch.Size([524288, 768]) torch.float32
New cuda time: 23.85045051574707
New cuda time without quantization: 24.066131591796875
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.161651611328125
New cuda time without quantization: 31.594945907592773
torch.Size([524288, 768]) torch.float32
New cuda time: 31.665185928344727
New cuda time without quantization: 32.909828186035156
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.96902847290039
New cuda time without quantization: 33.543113708496094
torch.Size([524288, 768]) torch.float32
New cuda time: 33.61191177368164
New cuda time without quantization: 32.17670822143555
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.304386138916016
New cuda time without quantization: 23.949649810791016
torch.Size([524288, 768]) torch.float32
New cuda time: 24.00181007385254
New cuda time without quantization: 24.9915714263916
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 25.07061195373535
New cuda time without quantization: 32.94327163696289
torch.Size([524288, 768]) torch.float32
New cuda time: 33.00550842285156
New cuda time without quantization: 33.07398986816406
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.235591888427734
New cuda time without quantization: 25.586933135986328
torch.Size([524288, 768]) torch.float32
New cuda time: 25.646133422851562
New cuda time without quantization: 31.398948669433594
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.460548400878906
New cuda time without quantization: 32.28534698486328
torch.Size([524288, 768]) torch.float32
New cuda time: 32.35974884033203
New cuda time without quantization: 32.63734817504883
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.69542694091797
New cuda time without quantization: 23.67637062072754
torch.Size([524288, 768]) torch.float32
New cuda time: 23.73093032836914
New cuda time without quantization: 24.63557243347168
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.753171920776367
New cuda time without quantization: 31.230785369873047
torch.Size([524288, 768]) torch.float32
New cuda time: 31.28838539123535
New cuda time without quantization: 24.26213264465332
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.369972229003906
New cuda time without quantization: 23.80084991455078
torch.Size([524288, 768]) torch.float32
New cuda time: 23.857330322265625
New cuda time without quantization: 32.9915885925293
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.25463104248047
New cuda time without quantization: 31.509347915649414
torch.Size([524288, 768]) torch.float32
New cuda time: 31.606788635253906
torch.float32
New cuda time: 23.78761863708496
New cuda time without quantization: 24.61369514465332
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.673856735229492
New cuda time without quantization: 23.646657943725586
torch.Size([524288, 768]) torch.float32
New cuda time: 23.731618881225586
New cuda time without quantization: 24.527456283569336
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.59017562866211
New cuda time without quantization: 28.924884796142578
torch.Size([524288, 768]) torch.float32
New cuda time: 28.9786434173584
New cuda time without quantization: 23.640737533569336
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.71097755432129
New cuda time without quantization: 23.637699127197266
torch.Size([524288, 768]) torch.float32
New cuda time: 23.693378448486328
New cuda time without quantization: 24.38025665283203
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.438335418701172
New cuda time without quantization: 25.741531372070312
torch.Size([524288, 768]) torch.float32
New cuda time: 25.82265281677246
New cuda time without quantization: 32.212554931640625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.32647705078125
New cuda time without quantization: 23.783937454223633
torch.Size([524288, 768]) torch.float32
New cuda time: 23.83705711364746
New cuda time without quantization: 31.37991714477539
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.49751853942871
New cuda time without quantization: 33.7016716003418
torch.Size([524288, 768]) torch.float32
New cuda time: 33.756553649902344
New cuda time without quantization: 30.627439498901367
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.760080337524414
New cuda time without quantization: 23.529380798339844
torch.Size([524288, 768]) torch.float32
New cuda time: 23.61210060119629
New cuda time without quantization: 30.866159439086914
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.924720764160156
New cuda time without quantization: 31.797998428344727
torch.Size([524288, 768]) torch.float32
New cuda time: 31.85287857055664
New cuda time without quantization: 31.529678344726562
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.60727882385254
New cuda time without quantization: 23.541379928588867
torch.Size([524288, 768]) torch.float32
New cuda time: 23.595300674438477
New cuda time without quantization: 30.296720504760742
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.35927963256836
New cuda time without quantization: 32.43799591064453
torch.Size([524288, 768]) torch.float32
New cuda time: 32.49239730834961
New cuda time without quantization: 32.75767517089844
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.82247543334961
New cuda time without quantization: 23.865697860717773
torch.Size([524288, 768]) torch.float32
New cuda time: 23.917858123779297
New cuda time without quantization: 31.466960906982422
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.532560348510742
New cuda time without quantization: 31.82647705078125
torch.Size([524288, 768]) torch.float32
New cuda time: 31.913997650146484
New cuda time without quantization: 30.59480094909668
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.725040435791016
New cuda time without quantization: 23.59161949157715
torch.Size([524288, 768]) torch.float32
New cuda time: 23.690340042114258
New cuda time without quantization: 31.352399826049805
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.41383934020996
New cuda time without quantization: 31.56999969482422
torch.Size([524288, 768]) torch.float32
New cuda time: 31.62343978881836
New cuda time without quantization: 31.125839233398438
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.190959930419922
New cuda time without quantization: 33.94279098510742
torch.Size([524288, 768]) torch.float32
New cuda time: 34.0002326965332
New cuda time without quantization: 31.14151954650879
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.307600021362305
New cuda time without quantization: 32.363277435302734
torch.Size([524288, 768]) torch.float32
New cuda time: 32.41975784301758
New cuda time without quantization: 32.08919906616211
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.148719787597656
New cuda time without quantization: 33.021995544433594
torch.Size([524288, 768]) torch.float32
New cuda time: 33.076717376708984
New cuda time without quantization: 32.774314880371094
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.83351516723633
New cuda time without quantization: 31.44887924194336
torch.Size([524288, 768]) torch.float32
New cuda time: 31.540239334106445
New cuda time without quantization: 30.01352310180664
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.12920379638672
New cuda time without quantization: 30.81688117980957
torch.Size([524288, 768]) torch.float32
New cuda time: 30.908239364624023
New cuda time without quantization: 31.988399505615234
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.05863952636719
New cuda time without quantization: 32.339439392089844
torch.Size([524288, 768]) torch.float32
New cuda time: 32.41975784301758
New cuda time without quantization: 30.78120231628418
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.852561950683594
New cuda time without quantization: 23.679779052734375
torch.Size([524288, 768]) torch.float32
New cuda time: 23.733219146728516
New cuda time without quantization: 31.965839385986328
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.024559020996094
New cuda time without quantization: 28.68056869506836
torch.Size([524288, 768]) torch.float32
New cuda time: 28.864248275756836
New cuda time without quantization: 32.883914947509766
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.945194244384766
New cuda time without quantization: 43.80036926269531
torch.Size([524288, 768]) torch.float32
New cuda time: 43.96388626098633
New cuda time without quantization: 30.330963134765625
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.40632438659668
New cuda time without quantization: 23.32617950439453
torch.Size([524288, 768]) torch.float32
New cuda time: 23.379779815673828
New cuda time without quantization: 23.824260711669922
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.988420486450195
New cuda time without quantization: 33.197994232177734
torch.Size([524288, 768]) torch.float32
New cuda time: 33.25015640258789
New cuda time without quantization: 42.71813201904297
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 42.844852447509766
New cuda time without quantization: 23.572900772094727
torch.Size([524288, 768]) torch.float32
New cuda time: 23.63081932067871
New cuda time without quantization: 30.567283630371094
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.63112449645996
New cuda time without quantization: 31.262962341308594
torch.Size([524288, 768]) torch.float32
New cuda time: 31.316722869873047
New cuda time without quantization: 33.097354888916016
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 33.156394958496094
New cuda time without quantization: 23.711139678955078
torch.Size([524288, 768]) torch.float32
New cuda time: 23.766340255737305
New cuda time without quantization: 24.710018157958984
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.807458877563477
New cuda time without quantization: 30.95160484313965
torch.Size([524288, 768]) torch.float32
New cuda time: 31.01048469543457
New cuda time without quantization: 24.048259735107422
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.150659561157227
New cuda time without quantization: 23.568099975585938
torch.Size([524288, 768]) torch.float32
New cuda time: 23.646020889282227
New cuda time without quantization: 31.682159423828125
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 31.7947998046875
New cuda time without quantization: 23.55978012084961
torch.Size([524288, 768]) torch.float32
New cuda time: 23.65641975402832
New cuda time without quantization: 23.896568298339844
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.09720802307129
New cuda time without quantization: 23.99960708618164
torch.Size([524288, 768]) torch.float32
New cuda time: 24.0573673248291
New cuda time without quantization: 26.06185531616211
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 26.181215286254883
New cuda time without quantization: 34.355167388916016
torch.Size([524288, 768]) torch.float32
New cuda time: 34.44348907470703
New cuda time without quantization: 32.54875946044922
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.62492370605469
New cuda time without quantization: 24.74953269958496
torch.Size([524288, 768]) torch.float32
New cuda time: 24.809371948242188
New cuda time without quantization: 23.669527053833008
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 23.761207580566406
2024-07-12 03:27:37 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time without quantization: 29.16668128967285
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 29.32492446899414
New cuda time without quantization: 23.759140014648438
torch.Size([524288, 768]) torch.float32
New cuda time: 23.815940856933594
New cuda time without quantization: 32.06621551513672
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.12925338745117
New cuda time without quantization: 32.705257415771484
torch.Size([524288, 768]) torch.float32
New cuda time: 32.75949478149414
New cuda time without quantization: 32.430057525634766
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.48797607421875
New cuda time without quantization: 31.10284996032715
torch.Size([524288, 768]) torch.float32
New cuda time: 31.16172981262207
New cuda time without quantization: 31.95885467529297
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.02365493774414
2024-07-12 03:27:37 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time without quantization: 30.4250431060791
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.61704444885254
New cuda time without quantization: 23.673860549926758
torch.Size([524288, 768]) torch.float32
New cuda time: 23.72793960571289
New cuda time without quantization: 24.268739700317383
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.475940704345703
New cuda time without quantization: 33.09431838989258
torch.Size([524288, 768]) torch.float32
New cuda time: 33.15543746948242
New cuda time without quantization: 40.384220123291016
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 40.472381591796875
New cuda time without quantization: 23.871299743652344
torch.Size([524288, 768]) torch.float32
New cuda time: 23.930500030517578
New cuda time without quantization: 32.47687911987305
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.546958923339844
2024-07-12 03:27:37 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time without quantization: 30.010784149169922
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.2490234375
New cuda time without quantization: 23.7573299407959
torch.Size([524288, 768]) torch.float32
New cuda time: 23.818130493164062
New cuda time without quantization: 24.045169830322266
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 24.105810165405273
New cuda time without quantization: 32.83734893798828
torch.Size([524288, 768]) torch.float32
New cuda time: 32.89175033569336
New cuda time without quantization: 30.802623748779297
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 30.930463790893555
New cuda time without quantization: 24.781492233276367
torch.Size([524288, 768]) torch.float32
New cuda time: 24.831571578979492
New cuda time without quantization: 32.898948669433594
torch.Size([4, 128, 1024, 768]) torch.float32
New cuda time: 32.968868255615234
2024-07-12 03:27:37 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-12 03:27:37 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:27:37 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:27:37 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:27:37 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:27:37 | INFO | fairseq_cli.eval_lm | Evaluated 899,369 tokens in 42.7s (21063.35 tokens/s)
2024-07-12 03:27:37 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9213, Perplexity: 7.58
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
