2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15679
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15679
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15679
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15679
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16574
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16574
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13248
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16574
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 2
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18500
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13248
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16574
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13248
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13248
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18500
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 3
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 3
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 2
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18500
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 3
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18500
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 1
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11869
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11869
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11869
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11555
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11695
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11695
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11555
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11869
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 2
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 3
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11695
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11747
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 1
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11555
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 0
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11747
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11555
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 2
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11695
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 3
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11747
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11747
2024-07-09 04:11:15 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 1
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18500', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 04:11:16 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 04:11:16 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 04:11:16 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 2
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 3
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 1
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 0
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 1
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 0
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11869', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 1
2024-07-09 04:11:16 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 04:11:16 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 04:11:16 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 2
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-005.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 1
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 2
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 3
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 1
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 3
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 0
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 0
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 2
2024-07-09 04:11:16 | INFO | fairseq.distributed.utils | initialized host t004-006.hpcfund as rank 0
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15679', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 04:11:16 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 04:11:16 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 04:11:16 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16574', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:16 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 04:11:17 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 04:11:17 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 04:11:17 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13248', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 04:11:17 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 04:11:17 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 04:11:17 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11747', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11695', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 4, 'moe_eval_capacity_token_fraction': 0.5}", 'results_path': None, 'is_moe': True}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11555', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 4}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': 100, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 100}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | model	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-09 04:11:17 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-09 04:11:17 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 04:11:17 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 04:11:17 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 04:11:17 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 04:11:17 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 04:11:17 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 04:11:17 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-09 04:11:17 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-09 04:11:17 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 4, Stitching experts to able to load on current world size.
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 04:11:20 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=8
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=9
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=10
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=11
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=12
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=13
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=14
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 04:11:21 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=15
2024-07-09 04:11:43 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 04:11:45 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 04:11:45 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 04:11:45 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 04:11:46 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 04:11:46 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 04:11:47 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 04:11:47 | INFO | fairseq_cli.eval_lm | num. model params: 3,725,230,080
2024-07-09 04:12:03 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 04:12:04 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 04:12:04 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 04:12:04 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 04:12:05 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 04:12:05 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 04:12:06 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-09 04:12:08 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
W0709 04:13:40.258395 140366678542144 torch/multiprocessing/spawn.py:145] Terminating process 579826 via signal SIGTERM
W0709 04:13:40.265307 140366678542144 torch/multiprocessing/spawn.py:145] Terminating process 579833 via signal SIGTERM
W0709 04:13:40.265730 140366678542144 torch/multiprocessing/spawn.py:145] Terminating process 579836 via signal SIGTERM
2024-07-09 04:13:42 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:13:43 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:13:43 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 169, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGKILL
2024-07-09 04:13:44 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
srun: error: t004-006: task 7: Exited with exit code 1
2024-07-09 04:13:51 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:13:53 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:13:54 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-09 04:14:05 | INFO | fairseq_cli.eval_lm | load time: 169.58 seconds
2024-07-09 04:14:07 | INFO | fairseq_cli.eval_lm | load time: 170.21 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:14:08 | INFO | fairseq_cli.eval_lm | load time: 171.95 seconds
2024-07-09 04:14:09 | INFO | fairseq_cli.eval_lm | load time: 172.18 seconds
2024-07-09 04:14:16 | INFO | fairseq_cli.eval_lm | load time: 178.76 seconds
2024-07-09 04:14:16 | INFO | fairseq_cli.eval_lm | load time: 179.42 seconds
2024-07-09 04:14:18 | INFO | fairseq_cli.eval_lm | load time: 181.34 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
W0709 04:14:36.192240 140636021135168 torch/multiprocessing/spawn.py:145] Terminating process 139763 via signal SIGTERM
W0709 04:14:36.236644 140636021135168 torch/multiprocessing/spawn.py:145] Terminating process 139766 via signal SIGTERM
W0709 04:14:36.236780 140636021135168 torch/multiprocessing/spawn.py:145] Terminating process 139769 via signal SIGTERM
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Exception ignored in: <function PlasmaArray.__del__ at 0x7fcc1c8b70d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 204, in top2gating
    return l_aux, combine_weights.to(orig_dtype), dispatch_mask, metadata
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 2.00 GiB. GPU  has a total capacity of 63.98 GiB of which 1.23 GiB is free. Of the allocated memory 20.10 GiB is allocated by PyTorch, and 713.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Exception ignored in: <function PlasmaArray.__del__ at 0x7f9fbfc220d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Exception ignored in: <function PlasmaArray.__del__ at 0x7fb4658380d0>
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/data/plasma_utils.py", line 90, in __del__
    if self._server is not None:
AttributeError: 'PlasmaArray' object has no attribute '_server'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib64/python3.9/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
W0709 04:14:39.323311 139916819867456 torch/multiprocessing/spawn.py:145] Terminating process 139770 via signal SIGTERM
W0709 04:14:39.378206 139916819867456 torch/multiprocessing/spawn.py:145] Terminating process 139774 via signal SIGTERM
W0709 04:14:39.378345 139916819867456 torch/multiprocessing/spawn.py:145] Terminating process 139776 via signal SIGTERM
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 193, in top2gating
    combine1_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 958.00 MiB is free. Of the allocated memory 7.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 34 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
srun: error: t004-005: task 3: Exited with exit code 1
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:14:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1495.051513671875, gpu time: 1489.6831398010254
2024-07-09 04:14:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.15283203125, gpu time: 33.85500526428223
2024-07-09 04:14:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.777099609375, gpu time: 34.2415657043457
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-07-09 04:14:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.51025390625, gpu time: 36.33980178833008
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:14:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.622802734375, gpu time: 36.40956115722656
2024-07-09 04:14:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1726.830322265625, gpu time: 1721.331075668335
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 37 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
srun: error: t004-005: task 2: Exited with exit code 1
2024-07-09 04:14:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.74853515625, gpu time: 63.16071701049805
2024-07-09 04:14:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.13623046875, gpu time: 100.3376522064209
2024-07-09 04:14:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.6826171875, gpu time: 46.25973701477051
W0709 04:14:44.783751 140446847911744 torch/multiprocessing/spawn.py:145] Terminating process 139758 via signal SIGTERM
W0709 04:14:44.851924 140446847911744 torch/multiprocessing/spawn.py:145] Terminating process 139759 via signal SIGTERM
W0709 04:14:44.852996 140446847911744 torch/multiprocessing/spawn.py:145] Terminating process 139760 via signal SIGTERM
2024-07-09 04:14:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1497.617919921875, gpu time: 1530.5307788848877
2024-07-09 04:14:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.55810546875, gpu time: 69.84696769714355
2024-07-09 04:14:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.859375, gpu time: 320.53368186950684
2024-07-09 04:14:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.64013671875, gpu time: 69.60296821594238
2024-07-09 04:14:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.649658203125, gpu time: 78.5311164855957
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 197, in top2gating
    combine2_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 3.46 GiB is free. Of the allocated memory 11.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2024-07-09 04:14:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.858154296875, gpu time: 233.71020317077637
2024-07-09 04:14:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.10107421875, gpu time: 70.22456550598145
2024-07-09 04:14:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 0.740234375, gpu time: 49.84182167053223
2024-07-09 04:14:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.865478515625, gpu time: 162.15710830688477
2024-07-09 04:14:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1727.81787109375, gpu time: 1777.7228260040283
2024-07-09 04:14:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1499.554931640625, gpu time: 1566.2083415985107
2024-07-09 04:14:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.632080078125, gpu time: 114.3708610534668
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:14:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.537841796875, gpu time: 104.02997207641602
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
2024-07-09 04:14:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.419921875, gpu time: 103.79084968566895
2024-07-09 04:14:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.680419921875, gpu time: 109.71828651428223
2024-07-09 04:14:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.56640625, gpu time: 355.6401252746582
2024-07-09 04:14:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.357666015625, gpu time: 116.78147315979004
2024-07-09 04:14:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.478515625, gpu time: 268.07824325561523
2024-07-09 04:14:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.013427734375, gpu time: 111.59604263305664
2024-07-09 04:14:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1.453125, gpu time: 91.3637924194336
2024-07-09 04:14:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.186279296875, gpu time: 197.32843017578125
2024-07-09 04:14:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1728.56298828125, gpu time: 1811.924467086792
2024-07-09 04:14:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1500.398193359375, gpu time: 1614.3322925567627
2024-07-09 04:14:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.25927734375, gpu time: 165.08436393737793
2024-07-09 04:14:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.187744140625, gpu time: 156.00223922729492
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 37 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 04:14:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.0478515625, gpu time: 137.95648956298828
srun: error: t004-005: task 1: Exited with exit code 1
2024-07-09 04:14:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.733642578125, gpu time: 156.4761562347412
2024-07-09 04:14:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.262451171875, gpu time: 393.9616107940674
2024-07-09 04:14:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.554443359375, gpu time: 167.23341941833496
2024-07-09 04:14:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.11669921875, gpu time: 309.06821060180664
W0709 04:14:48.869178 140438924502848 torch/multiprocessing/spawn.py:145] Terminating process 579829 via signal SIGTERM
W0709 04:14:48.921611 140438924502848 torch/multiprocessing/spawn.py:145] Terminating process 579832 via signal SIGTERM
W0709 04:14:48.921735 140438924502848 torch/multiprocessing/spawn.py:145] Terminating process 579835 via signal SIGTERM
2024-07-09 04:14:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.280517578125, gpu time: 156.6643123626709
2024-07-09 04:14:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.082275390625, gpu time: 133.6676845550537
2024-07-09 04:14:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.535888671875, gpu time: 235.16230964660645
2024-07-09 04:14:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1729.228759765625, gpu time: 1863.6843700408936
2024-07-09 04:14:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.865966796875, gpu time: 204.19865036010742
2024-07-09 04:14:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1502.970947265625, gpu time: 1758.4780597686768
2024-07-09 04:14:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.659423828125, gpu time: 172.6646900177002
2024-07-09 04:14:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.85498046875, gpu time: 199.86731147766113
2024-07-09 04:14:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.88427734375, gpu time: 428.5182914733887
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 197, in top2gating
    combine2_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU 

2024-07-09 04:14:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.642822265625, gpu time: 209.4512996673584
2024-07-09 04:14:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.7587890625, gpu time: 343.48121070861816
2024-07-09 04:14:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.1982421875, gpu time: 224.61879920959473
2024-07-09 04:14:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 2.712890625, gpu time: 176.75861740112305
2024-07-09 04:14:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.433349609375, gpu time: 212.1341724395752
2024-07-09 04:14:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1729.9677734375, gpu time: 1898.211130142212
2024-07-09 04:14:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.630859375, gpu time: 281.0531406402588
2024-07-09 04:14:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.495849609375, gpu time: 238.70029067993164
2024-07-09 04:14:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1504.38720703125, gpu time: 1800.1247329711914
2024-07-09 04:14:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.26904296875, gpu time: 210.86905670166016
2024-07-09 04:14:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.628662109375, gpu time: 236.04375076293945
2024-07-09 04:14:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.506591796875, gpu time: 462.8053722381592
2024-07-09 04:14:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.03564453125, gpu time: 249.90917587280273
2024-07-09 04:14:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.3837890625, gpu time: 377.5604496002197
2024-07-09 04:14:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.186767578125, gpu time: 261.6137981414795
2024-07-09 04:14:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.34814453125, gpu time: 210.9501781463623
W0709 04:14:51.978092 140270101489472 torch/multiprocessing/spawn.py:145] Terminating process 579823 via signal SIGTERM
W0709 04:14:52.030754 140270101489472 torch/multiprocessing/spawn.py:145] Terminating process 579828 via signal SIGTERM
W0709 04:14:52.031074 140270101489472 torch/multiprocessing/spawn.py:145] Terminating process 579831 via signal SIGTERM
2024-07-09 04:14:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.178466796875, gpu time: 249.87636947631836
2024-07-09 04:14:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1730.72705078125, gpu time: 1932.3378887176514
2024-07-09 04:14:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.79736328125, gpu time: 315.87246322631836
2024-07-09 04:14:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.107177734375, gpu time: 279.2653007507324
2024-07-09 04:14:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1505.16357421875, gpu time: 1834.4451732635498
2024-07-09 04:14:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.8818359375, gpu time: 245.62029647827148
Traceback (most recent call last):
  File "/usr/lib64/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib64/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 458, in <module>
    cli_main()
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 454, in cli_main
    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 351, in call_main
    torch.multiprocessing.spawn(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py", line 335, in distributed_main
    main(cfg, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 437, in main
    results, rr, end_time = eval_dataset(cfg, eval_split, task, models, start_time)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 322, in eval_dataset
    results = eval_lm(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq_cli/eval_lm.py", line 132, in eval_lm
    hypos = scorer.generate(models, sample)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/sequence_scorer.py", line 68, in generate
    decoder_out = model(**net_input)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/fairseq_model.py", line 508, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 930, in forward
    x, extra = self.extract_features(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 955, in extract_features
    return self.extract_features_scriptable(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/models/transformer.py", line 1016, in extract_features_scriptable
    x, layer_attn, _, l_aux_i = layer(
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py", line 168, in _checkpointed_forward
    return original_forward(module, *args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/transformer_layer.py", line 568, in forward
    x, l_aux = self.moe_layer(x)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/moe_layer.py", line 253, in forward
    l_aux, combine_weights, dispatch_mask, self.metadata = self.gate(reshaped_input, reshaped_input_padding_mask)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 247, in forward
    return top2gating(
  File "/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/modules/moe/top2gate.py", line 197, in top2gating
    combine2_sec = torch.bmm(
torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 4.00 GiB. GPU  has a total capacity of 63.98 GiB of which 2.84 GiB is free. Of the allocated memory 11.11 GiB is allocated by PyTorch, and 705.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2024-07-09 04:14:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.81982421875, gpu time: 270.4553928375244
2024-07-09 04:14:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.1337890625, gpu time: 520.3627223968506
2024-07-09 04:14:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.063232421875, gpu time: 286.08001708984375
2024-07-09 04:14:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.009765625, gpu time: 428.1667537689209
2024-07-09 04:14:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.6142578125, gpu time: 297.2942371368408
srun: error: t004-006: task 5: Exited with exit code 1
2024-07-09 04:14:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 3.966064453125, gpu time: 253.4455909729004
2024-07-09 04:14:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.540771484375, gpu time: 285.0760097503662
2024-07-09 04:14:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1731.47705078125, gpu time: 1966.3379287719727
2024-07-09 04:14:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.017333984375, gpu time: 359.78857231140137
2024-07-09 04:14:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.73876953125, gpu time: 323.03815269470215
2024-07-09 04:14:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1506.11328125, gpu time: 1884.1731185913086
2024-07-09 04:14:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.498291015625, gpu time: 286.28098487854004
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 15 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 04:14:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.632080078125, gpu time: 314.5027046203613
2024-07-09 04:14:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.872802734375, gpu time: 570.1066246032715
2024-07-09 04:14:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.117431640625, gpu time: 319.9238166809082
2024-07-09 04:14:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.635498046875, gpu time: 473.80904960632324
2024-07-09 04:14:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.092529296875, gpu time: 331.0221996307373
srun: error: t004-006: task 4: Exited with exit code 1
2024-07-09 04:14:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 4.595703125, gpu time: 298.5026054382324
2024-07-09 04:14:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.103759765625, gpu time: 319.1281318664551
2024-07-09 04:14:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1732.146484375, gpu time: 2017.007272720337
2024-07-09 04:14:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.943603515625, gpu time: 393.6666145324707
2024-07-09 04:14:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.38232421875, gpu time: 358.55723762512207
2024-07-09 04:14:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1507.51123046875, gpu time: 1918.163480758667
2024-07-09 04:14:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.11865234375, gpu time: 333.598482131958
2024-07-09 04:14:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.60009765625, gpu time: 348.52186393737793
2024-07-09 04:14:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.5078125, gpu time: 621.8578872680664
2024-07-09 04:14:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.12646484375, gpu time: 353.8732166290283
2024-07-09 04:14:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.258544921875, gpu time: 525.7137546539307
2024-07-09 04:14:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.307861328125, gpu time: 370.7357540130615
2024-07-09 04:14:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.226318359375, gpu time: 347.2380256652832
2024-07-09 04:14:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.13671875, gpu time: 366.2543201446533
2024-07-09 04:14:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1732.8056640625, gpu time: 2054.1253967285156
2024-07-09 04:14:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.614990234375, gpu time: 427.46641731262207
2024-07-09 04:14:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.99365234375, gpu time: 404.0646514892578
2024-07-09 04:14:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1508.5361328125, gpu time: 1952.028242111206
2024-07-09 04:14:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.74462890625, gpu time: 385.69310569763184
2024-07-09 04:14:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.17333984375, gpu time: 392.8950939178467
2024-07-09 04:14:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.140380859375, gpu time: 665.4998626708984
2024-07-09 04:14:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.386474609375, gpu time: 388.4742965698242
/usr/lib64/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 37 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2024-07-09 04:14:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.9462890625, gpu time: 588.7203922271729
2024-07-09 04:14:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.718017578125, gpu time: 407.7363529205322
2024-07-09 04:14:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 5.912841796875, gpu time: 393.84064292907715
2024-07-09 04:14:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.34326171875, gpu time: 418.363862991333
2024-07-09 04:14:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1733.532470703125, gpu time: 2096.4264087677
2024-07-09 04:14:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.769775390625, gpu time: 488.9389877319336
2024-07-09 04:14:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.61376953125, gpu time: 452.1216697692871
2024-07-09 04:14:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1510.05859375, gpu time: 1997.5787544250488
2024-07-09 04:14:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.369384765625, gpu time: 426.4331569671631
2024-07-09 04:14:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.270263671875, gpu time: 431.46337127685547
2024-07-09 04:14:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.75732421875, gpu time: 707.5482349395752
2024-07-09 04:14:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.203369140625, gpu time: 423.00545501708984
2024-07-09 04:14:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.576171875, gpu time: 629.2462005615234
2024-07-09 04:14:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.795654296875, gpu time: 442.87439155578613
2024-07-09 04:14:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.552978515625, gpu time: 435.51109313964844
2024-07-09 04:14:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.36083984375, gpu time: 452.27342414855957
2024-07-09 04:14:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1734.253662109375, gpu time: 2152.298957824707
2024-07-09 04:15:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.4931640625, gpu time: 522.5888690948486
2024-07-09 04:15:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.2490234375, gpu time: 493.1079578399658
2024-07-09 04:15:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1511.16357421875, gpu time: 2041.4230270385742
2024-07-09 04:15:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 6.998291015625, gpu time: 467.22168731689453
2024-07-09 04:15:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.423583984375, gpu time: 474.7081241607666
2024-07-09 04:15:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.389892578125, gpu time: 748.8606052398682
2024-07-09 04:15:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.89501953125, gpu time: 461.46973037719727
2024-07-09 04:15:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.1982421875, gpu time: 671.0435333251953
2024-07-09 04:15:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.447998046875, gpu time: 476.8274745941162
2024-07-09 04:15:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.18115234375, gpu time: 484.31707191467285
2024-07-09 04:15:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.297119140625, gpu time: 490.0181827545166
2024-07-09 04:15:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1734.9765625, gpu time: 2193.683967590332
2024-07-09 04:15:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.826904296875, gpu time: 564.1521854400635
2024-07-09 04:15:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1512.595947265625, gpu time: 2080.7855434417725
2024-07-09 04:15:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.8759765625, gpu time: 534.9873714447021
2024-07-09 04:15:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.0576171875, gpu time: 513.9792804718018
2024-07-09 04:15:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.70068359375, gpu time: 510.27549934387207
2024-07-09 04:15:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.78466796875, gpu time: 504.9303226470947
2024-07-09 04:15:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.01904296875, gpu time: 788.5512142181396
2024-07-09 04:15:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.157958984375, gpu time: 517.7359085083008
2024-07-09 04:15:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.811279296875, gpu time: 719.1048717498779
2024-07-09 04:15:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.201904296875, gpu time: 529.8178176879883
2024-07-09 04:15:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 7.8798828125, gpu time: 526.2147235870361
2024-07-09 04:15:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.145263671875, gpu time: 611.7471694946289
2024-07-09 04:15:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1735.715576171875, gpu time: 2242.2288303375244
2024-07-09 04:15:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1513.336181640625, gpu time: 2117.043264389038
2024-07-09 04:15:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.498291015625, gpu time: 576.0125408172607
2024-07-09 04:15:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.17529296875, gpu time: 555.131233215332
2024-07-09 04:15:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.321044921875, gpu time: 551.0614700317383
2024-07-09 04:15:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.8623046875, gpu time: 549.5977935791016
2024-07-09 04:15:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.645751953125, gpu time: 843.4010429382324
2024-07-09 04:15:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.62451171875, gpu time: 557.6201839447021
2024-07-09 04:15:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.447021484375, gpu time: 771.4015769958496
2024-07-09 04:15:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.86328125, gpu time: 570.1340923309326
2024-07-09 04:15:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.51171875, gpu time: 585.1138362884521
2024-07-09 04:15:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.88916015625, gpu time: 651.4597644805908
2024-07-09 04:15:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1736.380615234375, gpu time: 2287.218647003174
2024-07-09 04:15:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.136962890625, gpu time: 616.571310043335
2024-07-09 04:15:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1516.415771484375, gpu time: 2225.1777057647705
2024-07-09 04:15:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 8.945068359375, gpu time: 601.8023357391357
2024-07-09 04:15:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.258544921875, gpu time: 886.4294166564941
2024-07-09 04:15:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.498291015625, gpu time: 667.8389472961426
2024-07-09 04:15:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.07763671875, gpu time: 812.2176265716553
2024-07-09 04:15:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.953857421875, gpu time: 583.4391956329346
2024-07-09 04:15:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.145263671875, gpu time: 623.1031646728516
2024-07-09 04:15:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1737.0869140625, gpu time: 2321.39900970459
2024-07-09 04:15:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.36083984375, gpu time: 737.5607891082764
2024-07-09 04:15:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.768310546875, gpu time: 655.472318649292
2024-07-09 04:15:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.031494140625, gpu time: 679.5128498077393
2024-07-09 04:15:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.562744140625, gpu time: 644.6299095153809
2024-07-09 04:15:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.76708984375, gpu time: 685.4467678070068
2024-07-09 04:15:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.88916015625, gpu time: 920.7222557067871
2024-07-09 04:15:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1517.635498046875, gpu time: 2270.4659748077393
2024-07-09 04:15:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.699462890625, gpu time: 853.7535190582275
2024-07-09 04:15:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.591552734375, gpu time: 709.2198619842529
2024-07-09 04:15:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 9.7666015625, gpu time: 657.9814453125
2024-07-09 04:15:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.144775390625, gpu time: 619.4041156768799
2024-07-09 04:15:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1737.764404296875, gpu time: 2360.5950603485107
2024-07-09 04:15:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.814208984375, gpu time: 791.0160884857178
2024-07-09 04:15:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.529052734375, gpu time: 689.6061210632324
2024-07-09 04:15:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.29736328125, gpu time: 715.2835292816162
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.3291015625, gpu time: 682.0184364318848
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.080810546875, gpu time: 719.3432064056396
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.64794921875, gpu time: 954.8773365020752
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1518.39404296875, gpu time: 2310.9681701660156
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.323486328125, gpu time: 889.6660423278809
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.549560546875, gpu time: 743.1475028991699
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 10.401611328125, gpu time: 696.3910942077637
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.0126953125, gpu time: 655.9576740264893
2024-07-09 04:15:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1738.394287109375, gpu time: 2396.6728649139404
2024-07-09 04:15:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.903076171875, gpu time: 825.0592498779297
2024-07-09 04:15:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.1416015625, gpu time: 726.4416885375977
2024-07-09 04:15:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.070068359375, gpu time: 754.5930881500244
2024-07-09 04:15:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.0908203125, gpu time: 718.8373622894287
2024-07-09 04:15:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.2119140625, gpu time: 753.3828468322754
2024-07-09 04:15:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.27685546875, gpu time: 989.3175411224365
2024-07-09 04:15:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1519.20068359375, gpu time: 2352.592761993408
2024-07-09 04:15:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.9462890625, gpu time: 923.7803249359131
2024-07-09 04:15:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.03369140625, gpu time: 730.520097732544
2024-07-09 04:15:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.199951171875, gpu time: 798.257682800293
2024-07-09 04:15:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1739.093994140625, gpu time: 2437.3185176849365
2024-07-09 04:15:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.572021484375, gpu time: 689.8605155944824
2024-07-09 04:15:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.756591796875, gpu time: 760.5879707336426
2024-07-09 04:15:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.079345703125, gpu time: 858.7859287261963
2024-07-09 04:15:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.718505859375, gpu time: 753.0855674743652
2024-07-09 04:15:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.984130859375, gpu time: 788.6044082641602
2024-07-09 04:15:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.886474609375, gpu time: 1023.518705368042
2024-07-09 04:15:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.13623046875, gpu time: 787.1754455566406
2024-07-09 04:15:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.572509765625, gpu time: 958.5277309417725
2024-07-09 04:15:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1520.6474609375, gpu time: 2397.818311691284
2024-07-09 04:15:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 11.646240234375, gpu time: 764.7492618560791
2024-07-09 04:15:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.251953125, gpu time: 832.1667652130127
2024-07-09 04:15:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1739.76025390625, gpu time: 2471.577283859253
2024-07-09 04:15:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.386474609375, gpu time: 723.5686378479004
2024-07-09 04:15:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.385986328125, gpu time: 797.7177791595459
2024-07-09 04:15:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.84716796875, gpu time: 892.8263702392578
2024-07-09 04:15:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.335205078125, gpu time: 787.2334499359131
2024-07-09 04:15:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.1162109375, gpu time: 831.6709213256836
2024-07-09 04:15:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.510986328125, gpu time: 1075.6269359588623
2024-07-09 04:15:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.68310546875, gpu time: 826.6557216644287
2024-07-09 04:15:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.18896484375, gpu time: 1004.8189907073975
2024-07-09 04:15:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1522.22509765625, gpu time: 2437.6515464782715
2024-07-09 04:15:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.26708984375, gpu time: 808.4485187530518
2024-07-09 04:15:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.0341796875, gpu time: 871.661283493042
2024-07-09 04:15:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1740.42724609375, gpu time: 2513.0144577026367
2024-07-09 04:15:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.49169921875, gpu time: 764.001392364502
2024-07-09 04:15:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.993896484375, gpu time: 839.8520736694336
2024-07-09 04:15:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.693603515625, gpu time: 938.6444034576416
2024-07-09 04:15:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.95166015625, gpu time: 829.854944229126
2024-07-09 04:15:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.3974609375, gpu time: 876.0537548065186
2024-07-09 04:15:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.198486328125, gpu time: 1128.3074836730957
2024-07-09 04:15:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.010986328125, gpu time: 869.7127952575684
2024-07-09 04:15:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.813720703125, gpu time: 1094.2664680480957
2024-07-09 04:15:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1524.376708984375, gpu time: 2488.8258895874023
2024-07-09 04:15:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 12.896240234375, gpu time: 850.5490531921387
2024-07-09 04:15:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.05517578125, gpu time: 918.6725902557373
2024-07-09 04:15:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1741.11474609375, gpu time: 2566.591806411743
2024-07-09 04:15:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.462158203125, gpu time: 803.9608688354492
2024-07-09 04:15:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.632080078125, gpu time: 886.8038177490234
2024-07-09 04:15:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.253662109375, gpu time: 983.8542747497559
2024-07-09 04:15:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.578369140625, gpu time: 872.1791572570801
2024-07-09 04:15:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.277099609375, gpu time: 928.7874603271484
2024-07-09 04:15:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.820068359375, gpu time: 1170.519380569458
2024-07-09 04:15:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.1025390625, gpu time: 915.2500267028809
2024-07-09 04:15:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.431884765625, gpu time: 1136.8606052398682
2024-07-09 04:15:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1525.478271484375, gpu time: 2528.284086227417
2024-07-09 04:15:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 13.528564453125, gpu time: 901.9624004364014
2024-07-09 04:15:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.252685546875, gpu time: 958.9275856018066
2024-07-09 04:15:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1741.78515625, gpu time: 2609.3465824127197
2024-07-09 04:15:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.375, gpu time: 851.2540969848633
2024-07-09 04:15:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.24951171875, gpu time: 929.3595542907715
2024-07-09 04:15:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.4833984375, gpu time: 1024.3814296722412
2024-07-09 04:15:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.197265625, gpu time: 915.002254486084
2024-07-09 04:15:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.7177734375, gpu time: 962.9034214019775
2024-07-09 04:15:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.439453125, gpu time: 1213.4163990020752
2024-07-09 04:15:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.0498046875, gpu time: 952.9610252380371
2024-07-09 04:15:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.05712890625, gpu time: 1188.2560348510742
2024-07-09 04:15:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1526.676513671875, gpu time: 2568.2746047973633
2024-07-09 04:15:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.15576171875, gpu time: 953.3471088409424
2024-07-09 04:15:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.313232421875, gpu time: 999.5224189758301
2024-07-09 04:15:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1742.42724609375, gpu time: 2649.7749557495117
2024-07-09 04:15:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.49267578125, gpu time: 891.6241321563721
2024-07-09 04:15:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.888427734375, gpu time: 970.1831302642822
2024-07-09 04:15:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.70654296875, gpu time: 1066.1914653778076
2024-07-09 04:15:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.82177734375, gpu time: 971.760570526123
2024-07-09 04:15:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.414794921875, gpu time: 1005.0675354003906
2024-07-09 04:15:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.056640625, gpu time: 1266.2895889282227
2024-07-09 04:15:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.0908203125, gpu time: 992.164981842041
2024-07-09 04:15:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.68310546875, gpu time: 1231.523775100708
2024-07-09 04:15:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1527.423828125, gpu time: 2623.381908416748
2024-07-09 04:15:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 14.775390625, gpu time: 1005.8935775756836
2024-07-09 04:15:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.0771484375, gpu time: 1058.6829948425293
2024-07-09 04:15:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1743.09326171875, gpu time: 2700.687662124634
2024-07-09 04:15:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.5869140625, gpu time: 950.7211875915527
2024-07-09 04:15:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.49951171875, gpu time: 1013.2438297271729
2024-07-09 04:15:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.39794921875, gpu time: 1100.0715866088867
2024-07-09 04:15:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.437744140625, gpu time: 1015.5804710388184
2024-07-09 04:15:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.12646484375, gpu time: 1060.6231536865234
2024-07-09 04:15:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.695068359375, gpu time: 1360.6071605682373
2024-07-09 04:15:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.066650390625, gpu time: 1037.0982151031494
2024-07-09 04:15:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.322265625, gpu time: 1273.8790340423584
2024-07-09 04:15:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1528.64208984375, gpu time: 2660.5913105010986
2024-07-09 04:15:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 15.39794921875, gpu time: 1130.362392425537
2024-07-09 04:15:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.241943359375, gpu time: 1099.8467903137207
2024-07-09 04:15:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.639404296875, gpu time: 991.2321853637695
2024-07-09 04:15:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1743.810302734375, gpu time: 2818.0223808288574
2024-07-09 04:15:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.72607421875, gpu time: 1133.9577884674072
2024-07-09 04:15:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.125, gpu time: 1126.1454238891602
2024-07-09 04:15:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.217529296875, gpu time: 1106.141025543213
2024-07-09 04:15:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.0517578125, gpu time: 1060.6512508392334
2024-07-09 04:15:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.03173828125, gpu time: 1087.4300022125244
2024-07-09 04:15:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.33447265625, gpu time: 1477.8542022705078
2024-07-09 04:15:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1529.755615234375, gpu time: 2756.5550537109375
2024-07-09 04:15:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.955322265625, gpu time: 1386.1907062530518
2024-07-09 04:15:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.80908203125, gpu time: 1133.7521953582764
2024-07-09 04:15:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.284423828125, gpu time: 1026.8511867523193
2024-07-09 04:15:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.02880859375, gpu time: 1244.2524700164795
2024-07-09 04:15:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.729248046875, gpu time: 1169.7494316101074
2024-07-09 04:15:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1744.49072265625, gpu time: 2861.034439086914
2024-07-09 04:15:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.544189453125, gpu time: 1146.279384613037
2024-07-09 04:15:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.756103515625, gpu time: 1248.9491157531738
2024-07-09 04:15:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.896240234375, gpu time: 1121.2906036376953
2024-07-09 04:15:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.68017578125, gpu time: 1158.931869506836
2024-07-09 04:15:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1530.537109375, gpu time: 2795.738851547241
2024-07-09 04:15:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.9541015625, gpu time: 1520.6075420379639
2024-07-09 04:15:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.672119140625, gpu time: 1175.739351272583
2024-07-09 04:15:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.575927734375, gpu time: 1505.4950370788574
2024-07-09 04:15:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.13232421875, gpu time: 1067.018663406372
2024-07-09 04:15:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.36865234375, gpu time: 1203.747636795044
2024-07-09 04:15:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 16.642822265625, gpu time: 1374.1294574737549
2024-07-09 04:15:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.975830078125, gpu time: 1190.8854217529297
2024-07-09 04:15:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1745.157470703125, gpu time: 2967.3507499694824
2024-07-09 04:15:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.655029296875, gpu time: 1155.3185691833496
2024-07-09 04:15:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.373046875, gpu time: 1291.7021350860596
2024-07-09 04:15:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1531.453369140625, gpu time: 2835.224090576172
2024-07-09 04:15:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.30126953125, gpu time: 1276.6813125610352
2024-07-09 04:15:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.874755859375, gpu time: 1212.510353088379
2024-07-09 04:15:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.585693359375, gpu time: 1588.5377178192139
2024-07-09 04:15:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.795654296875, gpu time: 1106.2373447418213
2024-07-09 04:15:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.1259765625, gpu time: 1242.4923973083496
2024-07-09 04:15:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.19775390625, gpu time: 1596.4534091949463
2024-07-09 04:15:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.73193359375, gpu time: 1224.6943454742432
2024-07-09 04:15:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.263427734375, gpu time: 1484.4003314971924
2024-07-09 04:15:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.953125, gpu time: 1196.4802856445312
2024-07-09 04:15:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1745.86328125, gpu time: 3086.085159301758
2024-07-09 04:15:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1532.82373046875, gpu time: 2880.5298042297363
2024-07-09 04:15:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.988525390625, gpu time: 1332.6607513427734
2024-07-09 04:15:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.826416015625, gpu time: 1250.3611946105957
2024-07-09 04:15:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.511962890625, gpu time: 1145.109785079956
2024-07-09 04:15:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.9150390625, gpu time: 1394.7707633972168
2024-07-09 04:15:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.7861328125, gpu time: 1286.9144306182861
2024-07-09 04:15:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.201171875, gpu time: 1715.198055267334
2024-07-09 04:15:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.6943359375, gpu time: 1269.1123790740967
2024-07-09 04:15:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.832763671875, gpu time: 1716.2921409606934
2024-07-09 04:15:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.820068359375, gpu time: 1237.6844024658203
2024-07-09 04:15:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 17.890625, gpu time: 1526.4235916137695
2024-07-09 04:15:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1533.7158203125, gpu time: 2920.096643447876
2024-07-09 04:15:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1746.484130859375, gpu time: 3203.3978061676025
2024-07-09 04:15:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.630859375, gpu time: 1290.1509132385254
2024-07-09 04:15:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.3603515625, gpu time: 1185.3660621643066
2024-07-09 04:15:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.61669921875, gpu time: 1452.747808456421
2024-07-09 04:15:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.439453125, gpu time: 1325.7225513458252
2024-07-09 04:15:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.54833984375, gpu time: 1511.2576580047607
2024-07-09 04:15:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.646484375, gpu time: 1311.4417743682861
2024-07-09 04:15:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.8408203125, gpu time: 1800.135456085205
2024-07-09 04:15:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.3916015625, gpu time: 1278.4656391143799
2024-07-09 04:15:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1534.869384765625, gpu time: 2965.422676086426
2024-07-09 04:15:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.44677734375, gpu time: 1899.7376899719238
2024-07-09 04:15:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.272705078125, gpu time: 1334.8435077667236
2024-07-09 04:15:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 18.523193359375, gpu time: 1637.7095127105713
2024-07-09 04:15:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.022216796875, gpu time: 1225.544261932373
2024-07-09 04:15:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1747.20263671875, gpu time: 3316.1219635009766
2024-07-09 04:15:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.1962890625, gpu time: 1364.6706714630127
2024-07-09 04:15:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.726806640625, gpu time: 1351.7639751434326
2024-07-09 04:15:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.244384765625, gpu time: 1570.1057395935059
2024-07-09 04:15:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.335693359375, gpu time: 1318.2111988067627
2024-07-09 04:15:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.16748046875, gpu time: 1631.1178302764893
2024-07-09 04:15:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1536.22021484375, gpu time: 3056.0973072052
2024-07-09 04:15:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.462890625, gpu time: 1843.272954940796
2024-07-09 04:15:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.074462890625, gpu time: 1969.8827514648438
2024-07-09 04:15:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.617919921875, gpu time: 1527.904275894165
2024-07-09 04:15:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.14697265625, gpu time: 1680.0890922546387
2024-07-09 04:15:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.34326171875, gpu time: 1297.5867557525635
2024-07-09 04:15:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1747.932373046875, gpu time: 3350.5700149536133
2024-07-09 04:15:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.258056640625, gpu time: 1409.121187210083
2024-07-09 04:15:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.871826171875, gpu time: 1618.8411693572998
2024-07-09 04:15:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.025390625, gpu time: 1395.6333713531494
2024-07-09 04:15:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.791748046875, gpu time: 1672.146047592163
2024-07-09 04:15:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.31494140625, gpu time: 1356.036922454834
2024-07-09 04:15:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.0849609375, gpu time: 1883.8192520141602
2024-07-09 04:15:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1537.746826171875, gpu time: 3099.841583251953
2024-07-09 04:15:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.697509765625, gpu time: 2013.4916152954102
2024-07-09 04:15:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.872314453125, gpu time: 1566.2365608215332
2024-07-09 04:15:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 19.7705078125, gpu time: 1714.4262619018555
2024-07-09 04:15:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.328857421875, gpu time: 1331.3464050292969
2024-07-09 04:15:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1748.728759765625, gpu time: 3397.0300827026367
2024-07-09 04:15:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.946533203125, gpu time: 1449.2193870544434
2024-07-09 04:15:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.508544921875, gpu time: 1652.9493789672852
2024-07-09 04:15:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.8017578125, gpu time: 1429.2461395263672
2024-07-09 04:15:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.42626953125, gpu time: 1754.3808898925781
2024-07-09 04:15:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.9765625, gpu time: 1390.3100109100342
2024-07-09 04:15:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.699462890625, gpu time: 1927.6906776428223
2024-07-09 04:15:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1539.141357421875, gpu time: 3142.7514629364014
2024-07-09 04:15:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.226318359375, gpu time: 1606.5627613067627
2024-07-09 04:15:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.33251953125, gpu time: 2124.051782608032
2024-07-09 04:15:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.28759765625, gpu time: 1371.2036457061768
2024-07-09 04:15:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 20.400146484375, gpu time: 1787.5300521850586
2024-07-09 04:15:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.6064453125, gpu time: 1482.869436264038
2024-07-09 04:15:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1749.35546875, gpu time: 3438.368221282959
2024-07-09 04:15:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.304443359375, gpu time: 1465.6453037261963
2024-07-09 04:15:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.135986328125, gpu time: 1693.733600616455
2024-07-09 04:15:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.632080078125, gpu time: 1435.4738063812256
2024-07-09 04:15:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.03466796875, gpu time: 1797.5150337219238
2024-07-09 04:15:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1540.36474609375, gpu time: 3176.6722297668457
2024-07-09 04:15:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.309814453125, gpu time: 1964.9048118591309
2024-07-09 04:15:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.879150390625, gpu time: 1645.869285583496
2024-07-09 04:15:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.9521484375, gpu time: 2167.733766555786
2024-07-09 04:15:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.442138671875, gpu time: 1405.039134979248
2024-07-09 04:15:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.0263671875, gpu time: 1829.0787506103516
2024-07-09 04:15:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.64697265625, gpu time: 1516.5879650115967
2024-07-09 04:15:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1750.012939453125, gpu time: 3472.6209087371826
2024-07-09 04:15:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.44091796875, gpu time: 1505.731185913086
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.74169921875, gpu time: 1728.1450119018555
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.433349609375, gpu time: 1469.2209739685059
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.6689453125, gpu time: 1840.4165382385254
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1541.4521484375, gpu time: 3215.72483253479
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.00244140625, gpu time: 1998.7530193328857
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.299072265625, gpu time: 1679.4417343139648
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.720703125, gpu time: 2201.8696575164795
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.013427734375, gpu time: 1446.9040546417236
2024-07-09 04:15:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 21.6337890625, gpu time: 1871.7888927459717
2024-07-09 04:15:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.56982421875, gpu time: 1550.5133724212646
2024-07-09 04:15:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1750.71484375, gpu time: 3508.788003921509
2024-07-09 04:15:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.416748046875, gpu time: 1539.448595046997
2024-07-09 04:15:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.354736328125, gpu time: 1763.0425071716309
2024-07-09 04:15:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.27197265625, gpu time: 1505.8398170471191
2024-07-09 04:15:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.275634765625, gpu time: 1874.4605884552002
2024-07-09 04:15:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1542.8662109375, gpu time: 3249.9232006073
2024-07-09 04:15:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.787841796875, gpu time: 2041.8674850463867
2024-07-09 04:15:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.952392578125, gpu time: 1716.0540180206299
2024-07-09 04:15:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.36181640625, gpu time: 2239.083791732788
2024-07-09 04:15:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.082763671875, gpu time: 1487.0747394561768
2024-07-09 04:15:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.252685546875, gpu time: 1906.2033424377441
2024-07-09 04:15:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.64990234375, gpu time: 1584.1814994812012
2024-07-09 04:15:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1751.43505859375, gpu time: 3549.4602241516113
2024-07-09 04:15:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.811767578125, gpu time: 1573.10520362854
2024-07-09 04:15:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.9765625, gpu time: 1797.3255977630615
2024-07-09 04:15:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.3671875, gpu time: 1539.4589862823486
2024-07-09 04:15:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.889892578125, gpu time: 1908.6353569030762
2024-07-09 04:15:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1544.49755859375, gpu time: 3283.862850189209
2024-07-09 04:15:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.40283203125, gpu time: 2085.105630874634
2024-07-09 04:15:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.86767578125, gpu time: 1754.8322219848633
2024-07-09 04:15:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.860595703125, gpu time: 2273.5248050689697
2024-07-09 04:15:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.771728515625, gpu time: 1521.0988674163818
2024-07-09 04:15:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 22.87060546875, gpu time: 1940.4352340698242
2024-07-09 04:15:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.285888671875, gpu time: 1619.9613056182861
2024-07-09 04:15:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1752.125244140625, gpu time: 3583.791795730591
2024-07-09 04:15:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.46533203125, gpu time: 1615.347246170044
2024-07-09 04:15:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.587890625, gpu time: 1841.7805442810059
2024-07-09 04:15:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.262939453125, gpu time: 1579.6111106872559
2024-07-09 04:15:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.505859375, gpu time: 1946.478775024414
2024-07-09 04:15:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1548.896240234375, gpu time: 3326.532573699951
2024-07-09 04:15:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.038818359375, gpu time: 2119.5192832946777
2024-07-09 04:15:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.82470703125, gpu time: 1788.6021099090576
2024-07-09 04:15:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.4765625, gpu time: 2314.3104667663574
2024-07-09 04:15:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.52099609375, gpu time: 1560.6713123321533
2024-07-09 04:15:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 23.4990234375, gpu time: 1974.446964263916
2024-07-09 04:15:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1752.934326171875, gpu time: 3617.996967315674
2024-07-09 04:15:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.97802734375, gpu time: 1676.5186939239502
2024-07-09 04:15:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.212158203125, gpu time: 1884.5886116027832
2024-07-09 04:15:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.1318359375, gpu time: 1651.2945728302002
2024-07-09 04:15:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.12255859375, gpu time: 1980.707628250122
2024-07-09 04:15:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.176513671875, gpu time: 1633.5537815093994
2024-07-09 04:15:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.6650390625, gpu time: 2153.680295944214
2024-07-09 04:15:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1550.704833984375, gpu time: 3366.5861377716064
2024-07-09 04:15:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.094482421875, gpu time: 2348.4145183563232
2024-07-09 04:15:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.474609375, gpu time: 1847.027177810669
2024-07-09 04:15:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.128173828125, gpu time: 2020.8350372314453
2024-07-09 04:15:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.1708984375, gpu time: 1618.5960597991943
2024-07-09 04:15:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1753.905029296875, gpu time: 3652.364381790161
2024-07-09 04:15:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.009033203125, gpu time: 1716.2143383026123
2024-07-09 04:15:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.90478515625, gpu time: 1919.0222644805908
2024-07-09 04:15:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.809326171875, gpu time: 1690.5347003936768
2024-07-09 04:15:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.7568359375, gpu time: 2023.8459358215332
2024-07-09 04:15:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.984375, gpu time: 1674.5006256103516
2024-07-09 04:15:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.28076171875, gpu time: 2187.76003074646
2024-07-09 04:15:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1552.1181640625, gpu time: 3411.2361793518066
2024-07-09 04:15:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.757568359375, gpu time: 2382.8675327301025
2024-07-09 04:15:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.55908203125, gpu time: 1891.3468189239502
2024-07-09 04:15:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 24.737548828125, gpu time: 2064.5103073120117
2024-07-09 04:15:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.824951171875, gpu time: 1656.4749069213867
2024-07-09 04:15:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1754.585205078125, gpu time: 3686.543956756592
2024-07-09 04:15:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.58447265625, gpu time: 1755.4197425842285
2024-07-09 04:15:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.521484375, gpu time: 1956.7381610870361
2024-07-09 04:15:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.47802734375, gpu time: 1729.1201076507568
2024-07-09 04:15:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.3681640625, gpu time: 2074.1220169067383
2024-07-09 04:15:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.3310546875, gpu time: 1718.6383457183838
2024-07-09 04:15:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.969970703125, gpu time: 2221.9412021636963
2024-07-09 04:15:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1552.85546875, gpu time: 3450.811664581299
2024-07-09 04:15:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.39306640625, gpu time: 2432.8394508361816
2024-07-09 04:15:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.5146484375, gpu time: 1939.2912578582764
2024-07-09 04:15:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.3681640625, gpu time: 2102.5338859558105
2024-07-09 04:15:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.677001953125, gpu time: 1704.645586013794
2024-07-09 04:15:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1755.323974609375, gpu time: 3735.057792663574
2024-07-09 04:15:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.5283203125, gpu time: 1795.8131484985352
2024-07-09 04:15:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.14013671875, gpu time: 1999.8372688293457
2024-07-09 04:15:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.33447265625, gpu time: 1773.222469329834
2024-07-09 04:15:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.992919921875, gpu time: 2108.7270317077637
2024-07-09 04:15:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.566650390625, gpu time: 1760.5651893615723
2024-07-09 04:15:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.576171875, gpu time: 2264.207508087158
2024-07-09 04:15:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1554.156494140625, gpu time: 3491.1983489990234
2024-07-09 04:15:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.012939453125, gpu time: 2478.079523086548
2024-07-09 04:15:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.985595703125, gpu time: 1983.772819519043
2024-07-09 04:15:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 25.998046875, gpu time: 2145.7441940307617
2024-07-09 04:15:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.347412109375, gpu time: 1742.8377151489258
2024-07-09 04:15:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1756.0302734375, gpu time: 3779.2929039001465
2024-07-09 04:15:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.71240234375, gpu time: 1834.1766357421875
2024-07-09 04:15:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.772705078125, gpu time: 2033.9424457550049
2024-07-09 04:15:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.142822265625, gpu time: 1819.4960289001465
2024-07-09 04:15:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.6044921875, gpu time: 2151.4615020751953
2024-07-09 04:15:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.599609375, gpu time: 1800.2253170013428
2024-07-09 04:15:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.20263671875, gpu time: 2315.073028564453
2024-07-09 04:15:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1555.53466796875, gpu time: 3531.459274291992
2024-07-09 04:15:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.6220703125, gpu time: 2519.79799079895
2024-07-09 04:15:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.75439453125, gpu time: 2024.4355030059814
2024-07-09 04:15:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 26.62841796875, gpu time: 2189.048101425171
2024-07-09 04:15:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.216064453125, gpu time: 1788.7688751220703
2024-07-09 04:15:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1756.7763671875, gpu time: 3813.534559249878
2024-07-09 04:15:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.39599609375, gpu time: 1939.5387897491455
2024-07-09 04:15:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.3935546875, gpu time: 2077.6165981292725
2024-07-09 04:15:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.01318359375, gpu time: 1867.3417491912842
2024-07-09 04:15:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.32421875, gpu time: 2194.575330734253
2024-07-09 04:15:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.5966796875, gpu time: 1839.660322189331
2024-07-09 04:15:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.838134765625, gpu time: 2357.3889350891113
2024-07-09 04:15:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1556.267822265625, gpu time: 3571.476203918457
2024-07-09 04:15:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.368896484375, gpu time: 2566.8195037841797
2024-07-09 04:15:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.6904296875, gpu time: 2069.6612281799316
2024-07-09 04:15:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.2529296875, gpu time: 2223.5310382843018
2024-07-09 04:15:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.06201171875, gpu time: 1828.1051635742188
2024-07-09 04:15:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1757.44921875, gpu time: 3849.207416534424
2024-07-09 04:15:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.864013671875, gpu time: 1984.2419548034668
2024-07-09 04:15:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.0048828125, gpu time: 2126.98099899292
2024-07-09 04:15:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.72802734375, gpu time: 1906.7021980285645
2024-07-09 04:15:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.9267578125, gpu time: 2229.0771484375
2024-07-09 04:15:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.130126953125, gpu time: 1880.7063694000244
2024-07-09 04:15:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.55810546875, gpu time: 2400.3042030334473
2024-07-09 04:15:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1556.9912109375, gpu time: 3618.011205673218
2024-07-09 04:15:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.012939453125, gpu time: 2601.2645206451416
2024-07-09 04:15:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.328857421875, gpu time: 2110.6043949127197
2024-07-09 04:15:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 27.876708984375, gpu time: 2258.0555725097656
2024-07-09 04:15:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.140869140625, gpu time: 1869.4662475585938
2024-07-09 04:15:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1758.29541015625, gpu time: 3892.2038078308105
2024-07-09 04:15:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.53759765625, gpu time: 2023.6388854980469
2024-07-09 04:15:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.633544921875, gpu time: 2169.929552078247
2024-07-09 04:15:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.861083984375, gpu time: 1947.7066459655762
2024-07-09 04:15:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.593994140625, gpu time: 2277.392587661743
2024-07-09 04:15:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.877685546875, gpu time: 1926.8266563415527
2024-07-09 04:15:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.1953125, gpu time: 2441.961549758911
2024-07-09 04:15:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1557.9521484375, gpu time: 3658.998374938965
2024-07-09 04:15:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.63818359375, gpu time: 2643.9220294952393
2024-07-09 04:15:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.295654296875, gpu time: 2150.275245666504
2024-07-09 04:15:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 28.5, gpu time: 2303.009246826172
2024-07-09 04:15:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.343994140625, gpu time: 1903.1427021026611
2024-07-09 04:15:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1759.020751953125, gpu time: 3932.6870765686035
2024-07-09 04:15:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.181640625, gpu time: 2062.100296020508
2024-07-09 04:15:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.34765625, gpu time: 2211.978099822998
2024-07-09 04:15:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.83154296875, gpu time: 1981.4216594696045
2024-07-09 04:15:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.209716796875, gpu time: 2320.6449794769287
2024-07-09 04:15:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.09326171875, gpu time: 1966.852066040039
2024-07-09 04:15:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.8935546875, gpu time: 2482.3913764953613
2024-07-09 04:15:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1558.6962890625, gpu time: 3693.624111175537
2024-07-09 04:15:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.257080078125, gpu time: 2678.6798458099365
2024-07-09 04:15:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.933837890625, gpu time: 2184.6627407073975
2024-07-09 04:15:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.116943359375, gpu time: 2364.168388366699
2024-07-09 04:15:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.3798828125, gpu time: 1943.8617153167725
2024-07-09 04:15:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1759.733642578125, gpu time: 3975.1754665374756
2024-07-09 04:15:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.484130859375, gpu time: 2096.0399532318115
2024-07-09 04:15:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.96923828125, gpu time: 2273.377883911133
2024-07-09 04:15:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.66015625, gpu time: 2021.6536312103271
2024-07-09 04:15:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.83251953125, gpu time: 2363.6613693237305
2024-07-09 04:15:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.8681640625, gpu time: 2007.961317062378
2024-07-09 04:15:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.517822265625, gpu time: 2529.3058547973633
2024-07-09 04:15:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1559.856689453125, gpu time: 3728.744884490967
2024-07-09 04:15:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.878173828125, gpu time: 2713.0131816864014
2024-07-09 04:15:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.168212890625, gpu time: 2225.043354034424
2024-07-09 04:15:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 29.735595703125, gpu time: 2405.7130966186523
2024-07-09 04:15:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.035888671875, gpu time: 1985.3402462005615
2024-07-09 04:15:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1760.402587890625, gpu time: 4027.9040336608887
2024-07-09 04:15:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.21435546875, gpu time: 2136.7756061553955
2024-07-09 04:15:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.6484375, gpu time: 2314.6961936950684
2024-07-09 04:15:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.8203125, gpu time: 2061.3278427124023
2024-07-09 04:15:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.448486328125, gpu time: 2404.995838165283
2024-07-09 04:15:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.167724609375, gpu time: 2054.3430461883545
2024-07-09 04:15:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.139404296875, gpu time: 2584.8824253082275
2024-07-09 04:15:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1561.309326171875, gpu time: 3774.883731842041
2024-07-09 04:15:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.526611328125, gpu time: 2752.482208251953
2024-07-09 04:15:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.96630859375, gpu time: 2265.1170864105225
2024-07-09 04:15:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.347412109375, gpu time: 2448.5976486206055
2024-07-09 04:15:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.471923828125, gpu time: 2019.0696620941162
2024-07-09 04:15:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1761.143310546875, gpu time: 4068.0881023406982
2024-07-09 04:15:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.884521484375, gpu time: 2176.5366973876953
2024-07-09 04:15:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.281982421875, gpu time: 2370.5337257385254
2024-07-09 04:15:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.67236328125, gpu time: 2102.1604537963867
2024-07-09 04:15:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.066650390625, gpu time: 2439.2592544555664
2024-07-09 04:15:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.578125, gpu time: 2092.743978500366
2024-07-09 04:15:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.7705078125, gpu time: 2625.868734359741
2024-07-09 04:16:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1562.03369140625, gpu time: 3814.6051445007324
2024-07-09 04:16:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.13818359375, gpu time: 2795.7533206939697
2024-07-09 04:16:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.61328125, gpu time: 2303.165859222412
2024-07-09 04:16:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 30.95947265625, gpu time: 2489.215955734253
2024-07-09 04:16:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.69482421875, gpu time: 2054.147077560425
2024-07-09 04:16:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1761.84765625, gpu time: 4109.591691970825
2024-07-09 04:16:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.082763671875, gpu time: 2218.7843494415283
2024-07-09 04:16:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.900634765625, gpu time: 2404.844181060791
2024-07-09 04:16:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.544677734375, gpu time: 2145.813861846924
2024-07-09 04:16:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.67431640625, gpu time: 2478.914041519165
2024-07-09 04:16:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.429443359375, gpu time: 2136.192907333374
2024-07-09 04:16:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.376953125, gpu time: 2671.179370880127
2024-07-09 04:16:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1563.069091796875, gpu time: 3859.2667121887207
2024-07-09 04:16:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.745849609375, gpu time: 2835.814348220825
2024-07-09 04:16:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.268310546875, gpu time: 2343.955591201782
2024-07-09 04:16:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 31.5712890625, gpu time: 2533.1555519104004
2024-07-09 04:16:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.345703125, gpu time: 2097.4006481170654
2024-07-09 04:16:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1762.509765625, gpu time: 4143.784069061279
2024-07-09 04:16:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.75439453125, gpu time: 2265.3990383148193
2024-07-09 04:16:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.531005859375, gpu time: 2447.1215324401855
2024-07-09 04:16:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.7001953125, gpu time: 2186.198793411255
2024-07-09 04:16:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.3017578125, gpu time: 2520.510753631592
2024-07-09 04:16:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.155029296875, gpu time: 2184.123115539551
2024-07-09 04:16:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.99267578125, gpu time: 2711.562801361084
2024-07-09 04:16:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1564.132568359375, gpu time: 3900.043004989624
2024-07-09 04:16:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.353271484375, gpu time: 2876.626895904541
2024-07-09 04:16:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.141357421875, gpu time: 2387.6248416900635
2024-07-09 04:16:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.18310546875, gpu time: 2567.9012088775635
2024-07-09 04:16:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.4609375, gpu time: 2136.0404624938965
2024-07-09 04:16:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1763.173828125, gpu time: 4184.324935913086
2024-07-09 04:16:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.4375, gpu time: 2305.9130897521973
2024-07-09 04:16:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.146240234375, gpu time: 2494.6369762420654
2024-07-09 04:16:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.373779296875, gpu time: 2228.1533241271973
2024-07-09 04:16:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.92529296875, gpu time: 2560.7333850860596
2024-07-09 04:16:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.8212890625, gpu time: 2232.149642944336
2024-07-09 04:16:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.6044921875, gpu time: 2753.0486335754395
2024-07-09 04:16:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1564.900634765625, gpu time: 3940.6253757476807
2024-07-09 04:16:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.9755859375, gpu time: 2911.419593811035
2024-07-09 04:16:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.131103515625, gpu time: 2427.0089721679688
2024-07-09 04:16:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 32.796142578125, gpu time: 2607.887517929077
2024-07-09 04:16:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.106201171875, gpu time: 2177.7717933654785
2024-07-09 04:16:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1763.884765625, gpu time: 4221.498760223389
2024-07-09 04:16:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.2197265625, gpu time: 2346.2703437805176
2024-07-09 04:16:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.76513671875, gpu time: 2533.327121734619
2024-07-09 04:16:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.594970703125, gpu time: 2269.142255783081
2024-07-09 04:16:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.54248046875, gpu time: 2595.5371227264404
2024-07-09 04:16:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.48193359375, gpu time: 2271.7097759246826
2024-07-09 04:16:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.21533203125, gpu time: 2787.300531387329
2024-07-09 04:16:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1565.6591796875, gpu time: 3981.500228881836
2024-07-09 04:16:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.592529296875, gpu time: 2952.7662258148193
2024-07-09 04:16:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.068603515625, gpu time: 2461.1507091522217
2024-07-09 04:16:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 33.43017578125, gpu time: 2642.395896911621
2024-07-09 04:16:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.8544921875, gpu time: 2225.783121109009
2024-07-09 04:16:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1764.548828125, gpu time: 4263.7684326171875
2024-07-09 04:16:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.606201171875, gpu time: 2386.2760791778564
2024-07-09 04:16:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.383544921875, gpu time: 2567.2322998046875
2024-07-09 04:16:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.26806640625, gpu time: 2308.7462310791016
2024-07-09 04:16:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.14990234375, gpu time: 2629.74054145813
2024-07-09 04:16:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.352294921875, gpu time: 2311.201591491699
2024-07-09 04:16:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.893310546875, gpu time: 2828.5263652801514
2024-07-09 04:16:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1568.066162109375, gpu time: 4020.8386058807373
2024-07-09 04:16:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.20947265625, gpu time: 2987.2507705688477
2024-07-09 04:16:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.833251953125, gpu time: 2501.196765899658
2024-07-09 04:16:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.040283203125, gpu time: 2690.8137435913086
2024-07-09 04:16:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.76611328125, gpu time: 2260.1546173095703
2024-07-09 04:16:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1765.16015625, gpu time: 4297.635690689087
2024-07-09 04:16:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.303955078125, gpu time: 2420.0005378723145
2024-07-09 04:16:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.213134765625, gpu time: 2601.6131591796875
2024-07-09 04:16:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.225830078125, gpu time: 2354.8884449005127
2024-07-09 04:16:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.783935546875, gpu time: 2670.766212463379
2024-07-09 04:16:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.29052734375, gpu time: 2349.2318058013916
2024-07-09 04:16:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.73046875, gpu time: 2862.7080268859863
2024-07-09 04:16:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1568.80859375, gpu time: 4056.073461532593
2024-07-09 04:16:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.870361328125, gpu time: 3027.6615600585938
2024-07-09 04:16:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.069580078125, gpu time: 2534.8836250305176
2024-07-09 04:16:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 34.79052734375, gpu time: 2725.363883972168
2024-07-09 04:16:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.415771484375, gpu time: 2294.6445140838623
2024-07-09 04:16:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.296630859375, gpu time: 2458.80979347229
2024-07-09 04:16:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1765.8876953125, gpu time: 4340.155927658081
2024-07-09 04:16:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.525390625, gpu time: 2397.6583404541016
2024-07-09 04:16:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.87255859375, gpu time: 2635.8807411193848
2024-07-09 04:16:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.69091796875, gpu time: 2389.804901123047
2024-07-09 04:16:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.413818359375, gpu time: 2713.079891204834
2024-07-09 04:16:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1569.820068359375, gpu time: 4092.880802154541
2024-07-09 04:16:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.337646484375, gpu time: 2899.3268127441406
2024-07-09 04:16:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.232421875, gpu time: 2570.0826454162598
2024-07-09 04:16:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.55419921875, gpu time: 3069.1681957244873
2024-07-09 04:16:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.122314453125, gpu time: 2328.4376163482666
2024-07-09 04:16:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 35.411865234375, gpu time: 2770.290044784546
2024-07-09 04:16:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.51904296875, gpu time: 2511.9016036987305
2024-07-09 04:16:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1766.611572265625, gpu time: 4374.370388031006
2024-07-09 04:16:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.222900390625, gpu time: 2436.159439086914
2024-07-09 04:16:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.503173828125, gpu time: 2688.0976371765137
2024-07-09 04:16:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.69140625, gpu time: 2443.884069442749
2024-07-09 04:16:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.02978515625, gpu time: 2750.709238052368
2024-07-09 04:16:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1570.763671875, gpu time: 4126.602863311768
2024-07-09 04:16:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.961181640625, gpu time: 2939.3144035339355
2024-07-09 04:16:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.94580078125, gpu time: 2627.915090560913
2024-07-09 04:16:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.1943359375, gpu time: 3104.1020183563232
2024-07-09 04:16:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.921630859375, gpu time: 2362.2198371887207
2024-07-09 04:16:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.02734375, gpu time: 2815.301649093628
2024-07-09 04:16:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.25634765625, gpu time: 2560.298858642578
2024-07-09 04:16:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1767.289306640625, gpu time: 4412.2710971832275
2024-07-09 04:16:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.86279296875, gpu time: 2473.4352588653564
2024-07-09 04:16:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.118896484375, gpu time: 2723.790662765503
2024-07-09 04:16:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.439453125, gpu time: 2477.5736503601074
2024-07-09 04:16:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.652587890625, gpu time: 2792.276990890503
2024-07-09 04:16:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1571.592041015625, gpu time: 4165.573720932007
2024-07-09 04:16:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.5810546875, gpu time: 2983.5916023254395
2024-07-09 04:16:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.684326171875, gpu time: 2666.7061100006104
2024-07-09 04:16:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.962646484375, gpu time: 3138.4182415008545
2024-07-09 04:16:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.873779296875, gpu time: 2406.414052963257
2024-07-09 04:16:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 36.64697265625, gpu time: 2855.2366008758545
2024-07-09 04:16:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.171142578125, gpu time: 2593.7769203186035
2024-07-09 04:16:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1768.080078125, gpu time: 4446.35692024231
2024-07-09 04:16:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.027587890625, gpu time: 2507.0658016204834
2024-07-09 04:16:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.742431640625, gpu time: 2769.452667236328
2024-07-09 04:16:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.73046875, gpu time: 2511.213632583618
2024-07-09 04:16:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.275634765625, gpu time: 2826.7840938568115
2024-07-09 04:16:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1573.39111328125, gpu time: 4200.44874382019
2024-07-09 04:16:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.220703125, gpu time: 3017.928945541382
2024-07-09 04:16:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.342041015625, gpu time: 2700.6137714385986
2024-07-09 04:16:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.579345703125, gpu time: 3182.9453620910645
2024-07-09 04:16:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.51171875, gpu time: 2447.559471130371
2024-07-09 04:16:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.269287109375, gpu time: 2897.6357192993164
2024-07-09 04:16:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.34912109375, gpu time: 2633.506820678711
2024-07-09 04:16:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1768.8115234375, gpu time: 4487.715717315674
2024-07-09 04:16:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.96630859375, gpu time: 2569.248170852661
2024-07-09 04:16:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.373046875, gpu time: 2805.829376220703
2024-07-09 04:16:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.59814453125, gpu time: 2549.3177738189697
2024-07-09 04:16:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.89501953125, gpu time: 2861.0655975341797
2024-07-09 04:16:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1574.551025390625, gpu time: 4320.688846588135
2024-07-09 04:16:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.91162109375, gpu time: 3121.298894882202
2024-07-09 04:16:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.04248046875, gpu time: 2734.4499168395996
2024-07-09 04:16:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.2138671875, gpu time: 3217.8835048675537
2024-07-09 04:16:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.283935546875, gpu time: 2490.4504890441895
2024-07-09 04:16:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 37.8837890625, gpu time: 2932.587942123413
2024-07-09 04:16:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1769.47900390625, gpu time: 4528.919952392578
2024-07-09 04:16:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.482421875, gpu time: 2748.7128410339355
2024-07-09 04:16:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.01025390625, gpu time: 2846.4180908203125
2024-07-09 04:16:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.744873046875, gpu time: 2603.1134338378906
2024-07-09 04:16:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.812255859375, gpu time: 2902.9168758392334
2024-07-09 04:16:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.406005859375, gpu time: 2658.9250888824463
2024-07-09 04:16:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.53125, gpu time: 3155.513038635254
2024-07-09 04:16:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1575.443359375, gpu time: 4361.029947280884
2024-07-09 04:16:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.837158203125, gpu time: 3251.9854888916016
2024-07-09 04:16:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.705810546875, gpu time: 2845.9178619384766
2024-07-09 04:16:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 38.69580078125, gpu time: 2975.370262145996
2024-07-09 04:16:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.031982421875, gpu time: 2529.840549468994
2024-07-09 04:16:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1770.15869140625, gpu time: 4563.056976318359
2024-07-09 04:16:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.64013671875, gpu time: 2886.8930435180664
2024-07-09 04:16:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.37548828125, gpu time: 2873.227025985718
2024-07-09 04:16:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.432861328125, gpu time: 2938.524621963501
2024-07-09 04:16:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.80126953125, gpu time: 2636.8196563720703
2024-07-09 04:16:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.158203125, gpu time: 3199.1036796569824
2024-07-09 04:16:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.155517578125, gpu time: 2692.6092319488525
2024-07-09 04:16:19 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.45751953125, gpu time: 3291.296922683716
2024-07-09 04:16:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1576.18359375, gpu time: 4480.702379226685
2024-07-09 04:16:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.30908203125, gpu time: 3009.6788063049316
2024-07-09 04:16:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.056396484375, gpu time: 2879.4223251342773
2024-07-09 04:16:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1770.892578125, gpu time: 4605.0060176849365
2024-07-09 04:16:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.926025390625, gpu time: 2636.800661087036
2024-07-09 04:16:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.254638671875, gpu time: 2928.028799057007
2024-07-09 04:16:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.07373046875, gpu time: 2912.446689605713
2024-07-09 04:16:20 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.041748046875, gpu time: 2972.849166870117
2024-07-09 04:16:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.77978515625, gpu time: 3235.9391078948975
2024-07-09 04:16:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.502197265625, gpu time: 2718.623941421509
2024-07-09 04:16:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.074951171875, gpu time: 3326.2497882843018
2024-07-09 04:16:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.058837890625, gpu time: 2737.5602493286133
2024-07-09 04:16:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 39.935546875, gpu time: 3047.1259155273438
2024-07-09 04:16:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1576.895263671875, gpu time: 4514.436763763428
2024-07-09 04:16:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1771.6376953125, gpu time: 4639.8064041137695
2024-07-09 04:16:21 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.72265625, gpu time: 2920.5178260803223
2024-07-09 04:16:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.896728515625, gpu time: 2961.9843826293945
2024-07-09 04:16:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.569580078125, gpu time: 2676.161121368408
2024-07-09 04:16:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.65869140625, gpu time: 3006.9780292510986
2024-07-09 04:16:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.059814453125, gpu time: 2950.6658725738525
2024-07-09 04:16:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.3955078125, gpu time: 3279.0966300964355
2024-07-09 04:16:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.34326171875, gpu time: 2758.879602432251
2024-07-09 04:16:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.754638671875, gpu time: 3360.9034519195557
2024-07-09 04:16:22 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.71142578125, gpu time: 2776.262632369995
2024-07-09 04:16:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 40.55517578125, gpu time: 3082.0408630371094
2024-07-09 04:16:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1577.673583984375, gpu time: 4551.894506454468
2024-07-09 04:16:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1772.29052734375, gpu time: 4683.434804916382
2024-07-09 04:16:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.037109375, gpu time: 2958.686288833618
2024-07-09 04:16:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.51611328125, gpu time: 3003.486219406128
2024-07-09 04:16:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.919921875, gpu time: 2721.847343444824
2024-07-09 04:16:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.277099609375, gpu time: 3048.5747509002686
2024-07-09 04:16:23 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.7470703125, gpu time: 2990.406177520752
2024-07-09 04:16:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.012939453125, gpu time: 3320.7891883850098
2024-07-09 04:16:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.144287109375, gpu time: 2796.990146636963
2024-07-09 04:16:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.379638671875, gpu time: 3403.59153175354
2024-07-09 04:16:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.07373046875, gpu time: 2816.131736755371
2024-07-09 04:16:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.174560546875, gpu time: 3116.523006439209
2024-07-09 04:16:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1578.41748046875, gpu time: 4594.111131668091
2024-07-09 04:16:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1773.01708984375, gpu time: 4722.060956954956
2024-07-09 04:16:24 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.876708984375, gpu time: 2993.2321949005127
2024-07-09 04:16:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.1357421875, gpu time: 3037.435724258423
2024-07-09 04:16:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.990966796875, gpu time: 2766.1778869628906
2024-07-09 04:16:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.892333984375, gpu time: 3089.906991958618
2024-07-09 04:16:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.7431640625, gpu time: 3024.0735244750977
2024-07-09 04:16:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.64453125, gpu time: 3354.9727725982666
2024-07-09 04:16:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.786865234375, gpu time: 2837.372848510742
2024-07-09 04:16:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.01025390625, gpu time: 3438.1952781677246
2024-07-09 04:16:25 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.73876953125, gpu time: 2849.992362976074
2024-07-09 04:16:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 41.791259765625, gpu time: 3152.030433654785
2024-07-09 04:16:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1579.14990234375, gpu time: 4631.83543586731
2024-07-09 04:16:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1773.667724609375, gpu time: 4756.222141265869
2024-07-09 04:16:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.56298828125, gpu time: 3033.164659500122
2024-07-09 04:16:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.76806640625, gpu time: 3074.374032974243
2024-07-09 04:16:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.227783203125, gpu time: 2799.8153114318848
2024-07-09 04:16:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.499755859375, gpu time: 3124.028335571289
2024-07-09 04:16:26 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.096435546875, gpu time: 3064.001028060913
2024-07-09 04:16:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.265625, gpu time: 3389.408037185669
2024-07-09 04:16:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.818115234375, gpu time: 2871.1214752197266
2024-07-09 04:16:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.63134765625, gpu time: 3481.5684814453125
2024-07-09 04:16:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.625732421875, gpu time: 2883.73858833313
2024-07-09 04:16:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 42.413330078125, gpu time: 3186.85498046875
2024-07-09 04:16:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1580.02978515625, gpu time: 4672.113662719727
2024-07-09 04:16:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1774.37109375, gpu time: 4795.283336639404
2024-07-09 04:16:27 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.805908203125, gpu time: 3072.3049640655518
2024-07-09 04:16:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.384765625, gpu time: 3108.624496459961
2024-07-09 04:16:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.8359375, gpu time: 2839.4684162139893
2024-07-09 04:16:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.17919921875, gpu time: 3166.8876190185547
2024-07-09 04:16:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.325439453125, gpu time: 3103.397174835205
2024-07-09 04:16:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.894287109375, gpu time: 3423.9423427581787
2024-07-09 04:16:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.5185546875, gpu time: 2908.8849811553955
2024-07-09 04:16:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.25927734375, gpu time: 3515.745183944702
2024-07-09 04:16:28 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.2822265625, gpu time: 2924.167371749878
2024-07-09 04:16:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.03466796875, gpu time: 3221.01456451416
2024-07-09 04:16:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1581.614501953125, gpu time: 4706.520849227905
2024-07-09 04:16:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1775.074951171875, gpu time: 4836.324216842651
2024-07-09 04:16:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.45458984375, gpu time: 3110.544469833374
2024-07-09 04:16:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.0068359375, gpu time: 3143.0477619171143
2024-07-09 04:16:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.476318359375, gpu time: 2879.2976818084717
2024-07-09 04:16:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.8134765625, gpu time: 3201.054244995117
2024-07-09 04:16:29 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.70263671875, gpu time: 3137.091564178467
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.50390625, gpu time: 3458.8478507995605
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.232177734375, gpu time: 3029.816303253174
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.876220703125, gpu time: 3557.1409454345703
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.337646484375, gpu time: 2970.325595855713
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 43.6494140625, gpu time: 3255.3559074401855
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1582.36376953125, gpu time: 4740.2193965911865
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1775.843017578125, gpu time: 4870.697881698608
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.80859375, gpu time: 3150.751178741455
2024-07-09 04:16:30 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.62841796875, gpu time: 3177.69407081604
2024-07-09 04:16:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 72.104248046875, gpu time: 2917.2047080993652
2024-07-09 04:16:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.43798828125, gpu time: 3235.015428543091
2024-07-09 04:16:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.34326171875, gpu time: 3170.93843460083
2024-07-09 04:16:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.177001953125, gpu time: 3493.152557373047
2024-07-09 04:16:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.08740234375, gpu time: 3063.8519744873047
2024-07-09 04:16:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.502197265625, gpu time: 3591.2658138275146
2024-07-09 04:16:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.14990234375, gpu time: 3016.251022338867
2024-07-09 04:16:31 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.27294921875, gpu time: 3293.361099243164
2024-07-09 04:16:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1583.79150390625, gpu time: 4779.560344696045
2024-07-09 04:16:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1776.53857421875, gpu time: 4911.390924453735
2024-07-09 04:16:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.505615234375, gpu time: 3184.4343700408936
2024-07-09 04:16:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.2490234375, gpu time: 3211.6891765594482
2024-07-09 04:16:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.081787109375, gpu time: 2956.487573623657
2024-07-09 04:16:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.062744140625, gpu time: 3289.348976135254
2024-07-09 04:16:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.00830078125, gpu time: 3204.9443435668945
2024-07-09 04:16:32 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.808837890625, gpu time: 3535.008321762085
2024-07-09 04:16:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.927978515625, gpu time: 3104.538040161133
2024-07-09 04:16:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.1201171875, gpu time: 3633.902379989624
2024-07-09 04:16:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.796142578125, gpu time: 3056.1982097625732
2024-07-09 04:16:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 44.885498046875, gpu time: 3336.7933464050293
2024-07-09 04:16:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1585.14697265625, gpu time: 4817.645612716675
2024-07-09 04:16:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1777.240234375, gpu time: 4945.809873580933
2024-07-09 04:16:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.267333984375, gpu time: 3224.5850791931152
2024-07-09 04:16:33 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.857177734375, gpu time: 3260.4849529266357
2024-07-09 04:16:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 73.7392578125, gpu time: 3001.342441558838
2024-07-09 04:16:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.670166015625, gpu time: 3330.9820194244385
2024-07-09 04:16:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.898193359375, gpu time: 3238.6916942596436
2024-07-09 04:16:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.439697265625, gpu time: 3576.4810428619385
2024-07-09 04:16:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.076416015625, gpu time: 3144.4570693969727
2024-07-09 04:16:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.745361328125, gpu time: 3677.334466934204
2024-07-09 04:16:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.612060546875, gpu time: 3097.555637359619
2024-07-09 04:16:34 | INFO | fairseq.modules.moe.moe_layer | cpu time: 45.5029296875, gpu time: 3371.054374694824
2024-07-09 04:16:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1586.354736328125, gpu time: 4857.023040771484
2024-07-09 04:16:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1777.967041015625, gpu time: 4989.652681350708
2024-07-09 04:16:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.950927734375, gpu time: 3269.2517852783203
2024-07-09 04:16:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.470458984375, gpu time: 3294.606143951416
2024-07-09 04:16:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 74.387451171875, gpu time: 3035.1195526123047
2024-07-09 04:16:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.295654296875, gpu time: 3381.877643585205
2024-07-09 04:16:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.92724609375, gpu time: 3272.6790447235107
2024-07-09 04:16:35 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.049560546875, gpu time: 3611.333595275879
2024-07-09 04:16:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.8876953125, gpu time: 3178.1082611083984
2024-07-09 04:16:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.5146484375, gpu time: 3718.753429412842
2024-07-09 04:16:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.351318359375, gpu time: 3134.9207496643066
2024-07-09 04:16:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.126220703125, gpu time: 3414.0301399230957
2024-07-09 04:16:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1587.197021484375, gpu time: 4896.367349624634
2024-07-09 04:16:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1778.623779296875, gpu time: 5023.579309463501
2024-07-09 04:16:36 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.70654296875, gpu time: 3302.932258605957
2024-07-09 04:16:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.22607421875, gpu time: 3343.874242782593
2024-07-09 04:16:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.10888671875, gpu time: 3069.0285053253174
2024-07-09 04:16:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.94140625, gpu time: 3416.2125930786133
2024-07-09 04:16:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.5927734375, gpu time: 3313.0646324157715
2024-07-09 04:16:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.58544921875, gpu time: 3654.0151233673096
2024-07-09 04:16:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.77734375, gpu time: 3219.705852508545
2024-07-09 04:16:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.1435546875, gpu time: 3759.862632751465
2024-07-09 04:16:37 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.089599609375, gpu time: 3176.0506591796875
2024-07-09 04:16:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 46.75341796875, gpu time: 3448.249729156494
2024-07-09 04:16:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1587.97119140625, gpu time: 4937.555820465088
2024-07-09 04:16:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1779.334228515625, gpu time: 5076.373174667358
2024-07-09 04:16:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.081787109375, gpu time: 3336.762170791626
2024-07-09 04:16:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.842529296875, gpu time: 3379.033514022827
2024-07-09 04:16:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 75.90966796875, gpu time: 3102.5720195770264
2024-07-09 04:16:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.568603515625, gpu time: 3459.828519821167
2024-07-09 04:16:38 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.271484375, gpu time: 3346.8742237091064
2024-07-09 04:16:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.202392578125, gpu time: 3706.32354927063
2024-07-09 04:16:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.42919921875, gpu time: 3253.424083709717
2024-07-09 04:16:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.775634765625, gpu time: 3802.745279312134
2024-07-09 04:16:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.742431640625, gpu time: 3213.6114501953125
2024-07-09 04:16:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.36767578125, gpu time: 3492.1749382019043
2024-07-09 04:16:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1588.7177734375, gpu time: 4971.393892288208
2024-07-09 04:16:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1780.060546875, gpu time: 5110.893726348877
2024-07-09 04:16:39 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.881103515625, gpu time: 3372.6101627349854
2024-07-09 04:16:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.543701171875, gpu time: 3419.0252780914307
2024-07-09 04:16:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 76.5556640625, gpu time: 3136.3262519836426
2024-07-09 04:16:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.1689453125, gpu time: 3503.8932514190674
2024-07-09 04:16:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.99853515625, gpu time: 3380.660457611084
2024-07-09 04:16:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.798583984375, gpu time: 3741.292579650879
2024-07-09 04:16:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.075927734375, gpu time: 3287.026636123657
2024-07-09 04:16:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.112548828125, gpu time: 3249.780881881714
2024-07-09 04:16:40 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.43310546875, gpu time: 3845.131446838379
2024-07-09 04:16:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1589.477294921875, gpu time: 5005.0690841674805
2024-07-09 04:16:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 47.98388671875, gpu time: 3532.8230209350586
2024-07-09 04:16:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.53173828125, gpu time: 3406.418315887451
2024-07-09 04:16:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1780.83447265625, gpu time: 5147.184682846069
2024-07-09 04:16:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 77.856201171875, gpu time: 3176.67360496521
2024-07-09 04:16:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.177001953125, gpu time: 3462.117364883423
2024-07-09 04:16:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.795654296875, gpu time: 3415.94061088562
2024-07-09 04:16:41 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.784912109375, gpu time: 3546.8671016693115
2024-07-09 04:16:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.380615234375, gpu time: 3323.6538276672363
2024-07-09 04:16:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.427978515625, gpu time: 3794.0118885040283
2024-07-09 04:16:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.7607421875, gpu time: 3297.5530319213867
2024-07-09 04:16:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.0556640625, gpu time: 3879.7734394073486
2024-07-09 04:16:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1590.2607421875, gpu time: 5042.354034423828
2024-07-09 04:16:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 48.603271484375, gpu time: 3574.5776691436768
2024-07-09 04:16:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.594482421875, gpu time: 3439.984869003296
2024-07-09 04:16:42 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1781.4990234375, gpu time: 5193.59229850769
2024-07-09 04:16:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 78.505859375, gpu time: 3211.902879714966
2024-07-09 04:16:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.806396484375, gpu time: 3508.8614616394043
2024-07-09 04:16:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.444091796875, gpu time: 3449.527484893799
2024-07-09 04:16:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.415771484375, gpu time: 3588.849750518799
2024-07-09 04:16:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.302001953125, gpu time: 3359.622138977051
2024-07-09 04:16:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.045654296875, gpu time: 3827.7383575439453
2024-07-09 04:16:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.6494140625, gpu time: 3333.7378273010254
2024-07-09 04:16:43 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.66845703125, gpu time: 3923.952251434326
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1591.170166015625, gpu time: 5085.523305892944
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.226806640625, gpu time: 3618.6144008636475
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.226806640625, gpu time: 3474.82550239563
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1782.68310546875, gpu time: 5235.41446685791
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.1376953125, gpu time: 3245.4820728302
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.438720703125, gpu time: 3549.6889057159424
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.2744140625, gpu time: 3498.66619682312
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.036865234375, gpu time: 3622.665819168091
2024-07-09 04:16:44 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.93505859375, gpu time: 3404.195571899414
2024-07-09 04:16:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.656005859375, gpu time: 3870.940210342407
2024-07-09 04:16:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.27197265625, gpu time: 3406.4730167388916
2024-07-09 04:16:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.278076171875, gpu time: 3962.556011199951
2024-07-09 04:16:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 49.865234375, gpu time: 3661.167127609253
2024-07-09 04:16:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1591.893798828125, gpu time: 5132.728097915649
2024-07-09 04:16:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1783.402099609375, gpu time: 5275.517110824585
2024-07-09 04:16:45 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.858642578125, gpu time: 3518.9490146636963
2024-07-09 04:16:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.058349609375, gpu time: 3592.994276046753
2024-07-09 04:16:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 79.862060546875, gpu time: 3313.4894218444824
2024-07-09 04:16:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.6640625, gpu time: 3664.339027404785
2024-07-09 04:16:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.959228515625, gpu time: 3544.7154693603516
2024-07-09 04:16:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.333984375, gpu time: 3911.8924560546875
2024-07-09 04:16:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.415283203125, gpu time: 3465.354124069214
2024-07-09 04:16:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.89306640625, gpu time: 4005.454019546509
2024-07-09 04:16:46 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.913818359375, gpu time: 3454.686288833618
2024-07-09 04:16:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 50.494873046875, gpu time: 3710.877950668335
2024-07-09 04:16:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1593.19970703125, gpu time: 5182.717529296875
2024-07-09 04:16:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1784.119140625, gpu time: 5309.720541000366
2024-07-09 04:16:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.5009765625, gpu time: 3562.418128967285
2024-07-09 04:16:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.67626953125, gpu time: 3634.845724105835
2024-07-09 04:16:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 80.498046875, gpu time: 3359.6361331939697
2024-07-09 04:16:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.287841796875, gpu time: 3716.805856704712
2024-07-09 04:16:47 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.665283203125, gpu time: 3592.546661376953
2024-07-09 04:16:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.9619140625, gpu time: 3953.1237449645996
2024-07-09 04:16:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.07373046875, gpu time: 3517.085636138916
2024-07-09 04:16:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.49853515625, gpu time: 4045.7173023223877
2024-07-09 04:16:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.25830078125, gpu time: 3499.835563659668
2024-07-09 04:16:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.11669921875, gpu time: 3745.378662109375
2024-07-09 04:16:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1593.94970703125, gpu time: 5222.864402770996
2024-07-09 04:16:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1784.833251953125, gpu time: 5358.456964492798
2024-07-09 04:16:48 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.158203125, gpu time: 3609.6557216644287
2024-07-09 04:16:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.28515625, gpu time: 3675.132049560547
2024-07-09 04:16:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 81.15380859375, gpu time: 3405.7412452697754
2024-07-09 04:16:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.914794921875, gpu time: 3758.1797046661377
2024-07-09 04:16:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.306884765625, gpu time: 3638.818494796753
2024-07-09 04:16:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.59814453125, gpu time: 3993.3311882019043
2024-07-09 04:16:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.8779296875, gpu time: 3557.015230178833
2024-07-09 04:16:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.27099609375, gpu time: 4088.184913635254
2024-07-09 04:16:49 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.94091796875, gpu time: 3539.979238510132
2024-07-09 04:16:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 51.74365234375, gpu time: 3785.831705093384
2024-07-09 04:16:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1594.693359375, gpu time: 5276.358797073364
2024-07-09 04:16:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1785.493408203125, gpu time: 5398.299608230591
2024-07-09 04:16:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.629638671875, gpu time: 3655.33571434021
2024-07-09 04:16:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.89697265625, gpu time: 3714.9980545043945
2024-07-09 04:16:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.209228515625, gpu time: 3445.2494010925293
2024-07-09 04:16:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.519775390625, gpu time: 3798.9127521514893
2024-07-09 04:16:50 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.545166015625, gpu time: 3679.4408893585205
2024-07-09 04:16:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.208251953125, gpu time: 4034.9783153533936
2024-07-09 04:16:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.7138671875, gpu time: 3598.3816242218018
2024-07-09 04:16:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.89208984375, gpu time: 4122.479064941406
2024-07-09 04:16:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.5908203125, gpu time: 3578.349313735962
2024-07-09 04:16:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.360107421875, gpu time: 3825.0820274353027
2024-07-09 04:16:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1595.4287109375, gpu time: 5317.113353729248
2024-07-09 04:16:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1786.181884765625, gpu time: 5446.678112030029
2024-07-09 04:16:51 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.3984375, gpu time: 3695.831708908081
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.5068359375, gpu time: 3761.154472351074
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 82.861572265625, gpu time: 3484.594997406006
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.138671875, gpu time: 3838.932834625244
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.2001953125, gpu time: 3713.183609008789
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.83740234375, gpu time: 4069.244466781616
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.5361328125, gpu time: 3635.2520236968994
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.510986328125, gpu time: 4171.435968399048
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.3974609375, gpu time: 3619.498752593994
2024-07-09 04:16:52 | INFO | fairseq.modules.moe.moe_layer | cpu time: 52.986328125, gpu time: 3864.0673904418945
2024-07-09 04:16:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1597.008544921875, gpu time: 5353.593832015991
2024-07-09 04:16:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1786.808837890625, gpu time: 5480.670824050903
2024-07-09 04:16:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.670166015625, gpu time: 3735.087226867676
2024-07-09 04:16:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.128662109375, gpu time: 3800.1967964172363
2024-07-09 04:16:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 83.51025390625, gpu time: 3522.069715499878
2024-07-09 04:16:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.74755859375, gpu time: 3881.0183658599854
2024-07-09 04:16:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.19873046875, gpu time: 3752.464406967163
2024-07-09 04:16:53 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.44775390625, gpu time: 4103.621658325195
2024-07-09 04:16:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.227783203125, gpu time: 3681.1725006103516
2024-07-09 04:16:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.123291015625, gpu time: 4210.887252807617
2024-07-09 04:16:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.137451171875, gpu time: 3660.0648288726807
2024-07-09 04:16:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 53.599609375, gpu time: 3898.795623779297
2024-07-09 04:16:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1597.75390625, gpu time: 5398.025190353394
2024-07-09 04:16:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1787.4697265625, gpu time: 5531.027093887329
2024-07-09 04:16:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.309814453125, gpu time: 3769.0601844787598
2024-07-09 04:16:54 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.7578125, gpu time: 3834.4520683288574
2024-07-09 04:16:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 84.55224609375, gpu time: 3563.002353668213
2024-07-09 04:16:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.3544921875, gpu time: 3915.371717453003
2024-07-09 04:16:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.885498046875, gpu time: 3792.383764266968
2024-07-09 04:16:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.09130859375, gpu time: 4143.282222747803
2024-07-09 04:16:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.925048828125, gpu time: 3720.104179382324
2024-07-09 04:16:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.736328125, gpu time: 4253.753265380859
2024-07-09 04:16:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.33642578125, gpu time: 3700.7512283325195
2024-07-09 04:16:55 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.215087890625, gpu time: 3937.687229156494
2024-07-09 04:16:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1598.472900390625, gpu time: 5447.953826904297
2024-07-09 04:16:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1788.18310546875, gpu time: 5565.674688339233
2024-07-09 04:16:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.952880859375, gpu time: 3807.7326622009277
2024-07-09 04:16:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.381103515625, gpu time: 3870.724946975708
2024-07-09 04:16:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 85.947265625, gpu time: 3602.2724323272705
2024-07-09 04:16:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.9765625, gpu time: 3955.6719646453857
2024-07-09 04:16:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.53076171875, gpu time: 3830.0839233398438
2024-07-09 04:16:56 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.707763671875, gpu time: 4178.774457931519
2024-07-09 04:16:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.951416015625, gpu time: 3766.813299179077
2024-07-09 04:16:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.36181640625, gpu time: 4294.1920738220215
2024-07-09 04:16:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.0107421875, gpu time: 3740.119068145752
2024-07-09 04:16:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 54.839111328125, gpu time: 3972.053382873535
2024-07-09 04:16:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1599.763916015625, gpu time: 5487.074787139893
2024-07-09 04:16:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1788.850830078125, gpu time: 5606.783260345459
2024-07-09 04:16:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.131591796875, gpu time: 3853.0894622802734
2024-07-09 04:16:57 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.0068359375, gpu time: 3910.2781505584717
2024-07-09 04:16:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 86.598876953125, gpu time: 3640.518991470337
2024-07-09 04:16:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.591796875, gpu time: 3989.6830768585205
2024-07-09 04:16:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.609130859375, gpu time: 3863.7581634521484
2024-07-09 04:16:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.32275390625, gpu time: 4217.694860458374
2024-07-09 04:16:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.60107421875, gpu time: 3807.947219848633
2024-07-09 04:16:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.965576171875, gpu time: 4348.708829879761
2024-07-09 04:16:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.84521484375, gpu time: 3786.260986328125
2024-07-09 04:16:58 | INFO | fairseq.modules.moe.moe_layer | cpu time: 55.45849609375, gpu time: 4006.5475368499756
2024-07-09 04:16:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1600.63427734375, gpu time: 5526.207586288452
2024-07-09 04:16:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1789.5078125, gpu time: 5648.758232116699
2024-07-09 04:16:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.996826171875, gpu time: 3891.6627407073975
2024-07-09 04:16:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.618408203125, gpu time: 3949.420316696167
2024-07-09 04:16:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.266845703125, gpu time: 3679.0461921691895
2024-07-09 04:16:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.20556640625, gpu time: 4045.3241596221924
2024-07-09 04:16:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.747802734375, gpu time: 3897.4066429138184
2024-07-09 04:16:59 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.95654296875, gpu time: 4251.533973693848
2024-07-09 04:17:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.2568359375, gpu time: 3851.9041786193848
2024-07-09 04:17:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.578857421875, gpu time: 4388.557556152344
2024-07-09 04:17:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.617919921875, gpu time: 3823.6310653686523
2024-07-09 04:17:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.075927734375, gpu time: 4049.672430038452
2024-07-09 04:17:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1601.500244140625, gpu time: 5566.155746459961
2024-07-09 04:17:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1790.20068359375, gpu time: 5691.543287277222
2024-07-09 04:17:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.657470703125, gpu time: 3931.153781890869
2024-07-09 04:17:00 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.22314453125, gpu time: 3990.453845977783
2024-07-09 04:17:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 87.909423828125, gpu time: 3722.049711227417
2024-07-09 04:17:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.81884765625, gpu time: 4081.097354888916
2024-07-09 04:17:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.188720703125, gpu time: 3934.833044052124
2024-07-09 04:17:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.582275390625, gpu time: 4292.726703643799
2024-07-09 04:17:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.908935546875, gpu time: 3891.53777885437
2024-07-09 04:17:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.197998046875, gpu time: 4433.950937271118
2024-07-09 04:17:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.269287109375, gpu time: 3871.0206661224365
2024-07-09 04:17:01 | INFO | fairseq.modules.moe.moe_layer | cpu time: 56.702880859375, gpu time: 4089.9768409729004
2024-07-09 04:17:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1602.326416015625, gpu time: 5606.6903076171875
2024-07-09 04:17:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1790.93017578125, gpu time: 5732.47745513916
2024-07-09 04:17:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.39111328125, gpu time: 3977.268341064453
2024-07-09 04:17:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.85107421875, gpu time: 4024.3313579559326
2024-07-09 04:17:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 88.560546875, gpu time: 3755.802671432495
2024-07-09 04:17:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.431884765625, gpu time: 4124.0881690979
2024-07-09 04:17:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.885009765625, gpu time: 3974.8244037628174
2024-07-09 04:17:02 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.22216796875, gpu time: 4333.882953643799
2024-07-09 04:17:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.5537109375, gpu time: 3932.1979389190674
2024-07-09 04:17:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.818359375, gpu time: 4476.2268714904785
2024-07-09 04:17:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.20751953125, gpu time: 3910.9117069244385
2024-07-09 04:17:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.329345703125, gpu time: 4131.622055053711
2024-07-09 04:17:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1603.65478515625, gpu time: 5645.372386932373
2024-07-09 04:17:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1791.59619140625, gpu time: 5773.185386657715
2024-07-09 04:17:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.372802734375, gpu time: 4023.001625061035
2024-07-09 04:17:03 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.634765625, gpu time: 4064.596887588501
2024-07-09 04:17:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 89.34619140625, gpu time: 3801.172752380371
2024-07-09 04:17:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.05126953125, gpu time: 4171.301074981689
2024-07-09 04:17:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.536376953125, gpu time: 4010.2650451660156
2024-07-09 04:17:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.986083984375, gpu time: 4374.886245727539
2024-07-09 04:17:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.439697265625, gpu time: 3977.176502227783
2024-07-09 04:17:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.439697265625, gpu time: 4518.142805099487
2024-07-09 04:17:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.954833984375, gpu time: 3949.4029083251953
2024-07-09 04:17:04 | INFO | fairseq.modules.moe.moe_layer | cpu time: 57.94580078125, gpu time: 4165.976692199707
2024-07-09 04:17:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1604.537353515625, gpu time: 5684.715749740601
2024-07-09 04:17:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1792.3125, gpu time: 5820.090450286865
2024-07-09 04:17:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.376953125, gpu time: 4057.454584121704
2024-07-09 04:17:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.25439453125, gpu time: 4098.479522705078
2024-07-09 04:17:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 90.741455078125, gpu time: 3843.685556411743
2024-07-09 04:17:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.667724609375, gpu time: 4213.700529098511
2024-07-09 04:17:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.64892578125, gpu time: 4044.0112857818604
2024-07-09 04:17:05 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.5947265625, gpu time: 4414.069372177124
2024-07-09 04:17:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.17138671875, gpu time: 4023.1043453216553
2024-07-09 04:17:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.054443359375, gpu time: 4552.786882400513
2024-07-09 04:17:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.6064453125, gpu time: 3991.273790359497
2024-07-09 04:17:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 58.6142578125, gpu time: 4213.239038467407
2024-07-09 04:17:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1605.263671875, gpu time: 5726.232873916626
2024-07-09 04:17:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1792.972900390625, gpu time: 5855.642210006714
2024-07-09 04:17:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.08984375, gpu time: 4095.316186904907
2024-07-09 04:17:06 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.88232421875, gpu time: 4139.193212509155
2024-07-09 04:17:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 91.927001953125, gpu time: 3880.397397994995
2024-07-09 04:17:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.287353515625, gpu time: 4251.2126121521
2024-07-09 04:17:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.3818359375, gpu time: 4084.567129135132
2024-07-09 04:17:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.314453125, gpu time: 4448.416652679443
2024-07-09 04:17:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.07275390625, gpu time: 4056.7893104553223
2024-07-09 04:17:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.66796875, gpu time: 4594.38233757019
2024-07-09 04:17:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 95.5693359375, gpu time: 4031.63875579834
2024-07-09 04:17:07 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.221923828125, gpu time: 4247.1058349609375
2024-07-09 04:17:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1605.952880859375, gpu time: 5769.161840438843
2024-07-09 04:17:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1793.668701171875, gpu time: 5891.763412475586
2024-07-09 04:17:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.752197265625, gpu time: 4128.836030960083
2024-07-09 04:17:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.505859375, gpu time: 4173.409290313721
2024-07-09 04:17:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 92.928955078125, gpu time: 3923.2222023010254
2024-07-09 04:17:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.89404296875, gpu time: 4285.588373184204
2024-07-09 04:17:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.0986328125, gpu time: 4118.06777381897
2024-07-09 04:17:08 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.02294921875, gpu time: 4485.09161567688
2024-07-09 04:17:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.76611328125, gpu time: 4090.3688354492188
2024-07-09 04:17:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.299072265625, gpu time: 4628.441938400269
2024-07-09 04:17:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.72802734375, gpu time: 4076.826280593872
2024-07-09 04:17:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 59.833984375, gpu time: 4281.917594909668
2024-07-09 04:17:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1607.3798828125, gpu time: 5802.905046463013
2024-07-09 04:17:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1794.33740234375, gpu time: 5927.02077293396
2024-07-09 04:17:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.47900390625, gpu time: 4166.88547706604
2024-07-09 04:17:09 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.127685546875, gpu time: 4207.730331420898
2024-07-09 04:17:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 93.576416015625, gpu time: 3956.8034858703613
2024-07-09 04:17:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.515380859375, gpu time: 4328.15887260437
2024-07-09 04:17:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.915771484375, gpu time: 4153.807140350342
2024-07-09 04:17:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.637939453125, gpu time: 4519.632335662842
2024-07-09 04:17:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 101.386474609375, gpu time: 4131.321481704712
2024-07-09 04:17:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 65.923583984375, gpu time: 4671.200916290283
2024-07-09 04:17:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.36572265625, gpu time: 4110.4354038238525
2024-07-09 04:17:10 | INFO | fairseq.modules.moe.moe_layer | cpu time: 60.466552734375, gpu time: 4316.505035400391
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1608.5556640625, gpu time: 5842.858974456787
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1794.951171875, gpu time: 5961.446292877197
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.1064453125, gpu time: 4206.8798828125
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.732177734375, gpu time: 4250.990432739258
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.19921875, gpu time: 3993.2753314971924
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.119140625, gpu time: 4371.488573074341
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 101.017822265625, gpu time: 4199.711307525635
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.34912109375, gpu time: 4554.195934295654
2024-07-09 04:17:11 | INFO | fairseq.modules.moe.moe_layer | cpu time: 102.47119140625, gpu time: 4168.6146068573
2024-07-09 04:17:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 66.554931640625, gpu time: 4720.03798866272
2024-07-09 04:17:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 97.990966796875, gpu time: 4148.049011230469
2024-07-09 04:17:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.09716796875, gpu time: 4358.772331237793
2024-07-09 04:17:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1609.2890625, gpu time: 5878.62154006958
2024-07-09 04:17:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1795.66845703125, gpu time: 5998.305097579956
2024-07-09 04:17:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.99853515625, gpu time: 4240.589809417725
2024-07-09 04:17:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.357666015625, gpu time: 4285.323472976685
2024-07-09 04:17:12 | INFO | fairseq.modules.moe.moe_layer | cpu time: 94.813232421875, gpu time: 4038.7593383789062
2024-07-09 04:17:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.7421875, gpu time: 4405.9531326293945
2024-07-09 04:17:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 101.667236328125, gpu time: 4233.606035232544
2024-07-09 04:17:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.962646484375, gpu time: 4595.484350204468
2024-07-09 04:17:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.304931640625, gpu time: 4209.657495498657
2024-07-09 04:17:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.33203125, gpu time: 4754.409908294678
2024-07-09 04:17:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 98.989013671875, gpu time: 4188.894937515259
2024-07-09 04:17:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 61.71826171875, gpu time: 4398.721223831177
2024-07-09 04:17:13 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1609.972900390625, gpu time: 5913.710187911987
2024-07-09 04:17:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1796.3486328125, gpu time: 6032.5691776275635
2024-07-09 04:17:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.62158203125, gpu time: 4288.706298828125
2024-07-09 04:17:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.03076171875, gpu time: 4319.50643157959
2024-07-09 04:17:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.085693359375, gpu time: 4140.629274368286
2024-07-09 04:17:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.349365234375, gpu time: 4443.178819656372
2024-07-09 04:17:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 102.78662109375, gpu time: 4267.754522323608
2024-07-09 04:17:14 | INFO | fairseq.modules.moe.moe_layer | cpu time: 70.716796875, gpu time: 4629.752590179443
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.936279296875, gpu time: 4248.62614440918
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 67.9501953125, gpu time: 4788.67590713501
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.332275390625, gpu time: 4433.184823989868
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 99.67529296875, gpu time: 4231.676546096802
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1797.0634765625, gpu time: 6066.889577865601
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1610.652587890625, gpu time: 5953.638996124268
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.659423828125, gpu time: 4365.433418273926
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.30224609375, gpu time: 4323.75542640686
2024-07-09 04:17:15 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.97314453125, gpu time: 4477.5793800354
2024-07-09 04:17:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 96.885986328125, gpu time: 4180.116161346436
2024-07-09 04:17:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.334716796875, gpu time: 4665.438753128052
2024-07-09 04:17:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 103.40966796875, gpu time: 4301.608768463135
2024-07-09 04:17:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 68.568115234375, gpu time: 4823.252948760986
2024-07-09 04:17:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 104.68310546875, gpu time: 4289.056232452393
2024-07-09 04:17:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 62.9482421875, gpu time: 4478.497089385986
2024-07-09 04:17:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 100.741943359375, gpu time: 4271.395112991333
2024-07-09 04:17:16 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:17:16 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:17:16 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:17:16 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:17:16 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:17:16 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:17:16 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:17:16 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:17:16 | INFO | fairseq_cli.eval_lm | Evaluated 825,641 tokens in 180.5s (4573.91 tokens/s)
2024-07-09 04:17:16 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9464, Perplexity: 7.71
2024-07-09 04:17:16 | INFO | fairseq.modules.moe.moe_layer | cpu time: 1797.774658203125, gpu time: 6100.899578094482
2024-07-09 04:17:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 64.292724609375, gpu time: 4399.735898971558
2024-07-09 04:17:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.58935546875, gpu time: 4511.8271408081055
2024-07-09 04:17:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 71.958740234375, gpu time: 4710.762378692627
2024-07-09 04:17:17 | INFO | fairseq.modules.moe.moe_layer | cpu time: 69.209228515625, gpu time: 4860.61319732666
2024-07-09 04:17:18 | INFO | fairseq.modules.moe.moe_layer | cpu time: 63.564697265625, gpu time: 4512.3411693573
2024-07-09 04:17:18 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:17:18 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:17:18 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:17:18 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-09 04:17:18 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:17:18 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:17:18 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:17:18 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-09 04:17:18 | INFO | fairseq_cli.eval_lm | Evaluated 825,641 tokens in 189.0s (4368.63 tokens/s)
2024-07-09 04:17:18 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9464, Perplexity: 7.71
