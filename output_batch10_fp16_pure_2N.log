2024-07-12 03:01:23 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://t006-001:9996
2024-07-12 03:01:23 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://t006-001:9996
2024-07-12 03:01:23 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://t006-001:9996
2024-07-12 03:01:23 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://t006-001:9996
2024-07-12 03:01:23 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 1
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 3
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 2
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://t006-001:9996
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | initialized host t006-002.hpcfund as rank 6
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://t006-001:9996
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://t006-001:9996
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | initialized host t006-002.hpcfund as rank 7
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | initialized host t006-002.hpcfund as rank 5
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://t006-001:9996
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | initialized host t006-002.hpcfund as rank 4
2024-07-12 03:01:24 | INFO | fairseq.distributed.utils | initialized host t006-001.hpcfund as rank 0
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
/work1/amd/hongmfei/moespace/SPEED-main/fairseq/fairseq/distributed/utils.py:279: UserWarning: expandable_segments not supported on this platform (Triggered internally at ../c10/hip/HIPAllocatorConfig.h:29.)
  dist.all_reduce(torch.zeros(1).cuda())
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | cfg:
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | _name	None
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | common	{'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 100, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | common_eval	{'_name': None, 'path': '/work1/amd/hongmfei/models/en_moe_lm_15b/model.pt', 'post_process': None, 'quiet': False, 'model_overrides': "{'world_size': 8, 'moe_eval_capacity_token_fraction': 0.05}", 'results_path': None, 'is_moe': True}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | distributed_training	{'_name': None, 'distributed_world_size': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://t006-001:9996', 'distributed_port': 9996, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'fully_sharded', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | dataset	{'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 10, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': 10, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | optimization	{'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | checkpoint	{'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | bmuf	{'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | generation	{'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | eval_lm	{'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 2048, 'stats_path': None, 'max_valid_steps': 10}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | interactive	{'_name': None, 'buffer_size': 0, 'input': '-'}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | model	None
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | task	{'_name': 'language_modeling', 'data': '/work1/amd/hongmfei/raw_data/data-bin/wiki/', 'sample_break_mode': 'none', 'tokens_per_sample': 2048, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_source_positions': None, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 100, 'batch_size': 10, 'batch_size_valid': 10, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | criterion	{'_name': 'cross_entropy', 'sentence_avg': True}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | optimizer	None
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | lr_scheduler	{'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | scoring	{'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | bpe	{'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | tokenizer	None
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | simul_type	None
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | ---------------------------
2024-07-12 03:01:25 | INFO | fairseq_cli.eval_lm | loading model(s) from /work1/amd/hongmfei/models/en_moe_lm_15b/model.pt
2024-07-12 03:01:25 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
2024-07-12 03:01:25 | INFO | fairseq.checkpoint_utils | load_model_ensemble_and_task is_moe=True
2024-07-12 03:01:25 | INFO | fairseq.moe_checkpoint_utils | Found total 64 expert files and current distributed world size: 8, Stitching experts to able to load on current world size.
2024-07-12 03:01:26 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=0
2024-07-12 03:01:26 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=1
2024-07-12 03:01:26 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=2
2024-07-12 03:01:26 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=3
2024-07-12 03:01:26 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=4
2024-07-12 03:01:26 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=5
2024-07-12 03:01:26 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=6
2024-07-12 03:01:26 | INFO | fairseq.moe_checkpoint_utils | found 8 local experts in expert_group_id=7
2024-07-12 03:01:27 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:01:29 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:01:30 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:01:32 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:01:33 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:01:34 | INFO | fairseq.modules.moe.moe_layer | Rank: 0
2024-07-12 03:01:35 | INFO | fairseq_cli.eval_lm | num. model params: 1,911,816,192
2024-07-12 03:01:45 | INFO | fairseq.data.data_utils | loaded 1,482,831,152 examples from: /work1/amd/hongmfei/raw_data/data-bin/wiki/valid
2024-07-12 03:01:53 | INFO | fairseq_cli.eval_lm | /work1/amd/hongmfei/raw_data/data-bin/wiki/ valid 17,792,645 examples
2024-07-12 03:01:59 | INFO | fairseq_cli.eval_lm | load time: 33.94 seconds
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
/work1/amd/hongmfei/moespace/.moefair/lib64/python3.9/site-packages/torch/nn/functional.py:5504: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:505.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
Warning: The --amdgpu-target option has been deprecated and will be removed in the future.  Use --offload-arch instead.
New cuda time without quantization: 469.2787780761719
torch.Size([524288, 768]) torch.float16
New cuda time: 469.38165283203125
New cuda time without quantization: 111.86270904541016
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.96926879882812
New cuda time without quantization: 257.9580383300781
torch.Size([524288, 768]) torch.float16
New cuda time: 258.08013916015625
New cuda time without quantization: 124.3906021118164
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.50467681884766
New cuda time without quantization: 100.0177001953125
torch.Size([524288, 768]) torch.float16
New cuda time: 100.32362365722656
New cuda time without quantization: 108.94189453125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.01933288574219
New cuda time without quantization: 98.21817779541016
torch.Size([524288, 768]) torch.float16
New cuda time: 98.30121612548828
New cuda time without quantization: 113.9820785522461
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.07599639892578
New cuda time without quantization: 103.29914855957031
torch.Size([524288, 768]) torch.float16
New cuda time: 103.35626983642578
New cuda time without quantization: 124.1712417602539
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.3984375
New cuda time without quantization: 88.57764434814453
torch.Size([524288, 768]) torch.float16
New cuda time: 88.63829040527344
New cuda time without quantization: 125.50788879394531
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 125.57252502441406
New cuda time without quantization: 188.70799255371094
torch.Size([524288, 768]) torch.float16
New cuda time: 188.87167358398438
New cuda time without quantization: 115.00991821289062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.07904052734375
New cuda time without quantization: 98.57513427734375
torch.Size([524288, 768]) torch.float16
New cuda time: 98.73817443847656
New cuda time without quantization: 108.00813293457031
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.07565307617188
New cuda time without quantization: 101.05514526367188
torch.Size([524288, 768]) torch.float16
New cuda time: 101.13770294189453
New cuda time without quantization: 111.48703002929688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.72270965576172
New cuda time without quantization: 109.31421661376953
torch.Size([524288, 768]) torch.float16
New cuda time: 109.38878631591797
New cuda time without quantization: 112.36782836914062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.55326843261719
New cuda time without quantization: 95.35896301269531
torch.Size([524288, 768]) torch.float16
New cuda time: 95.41928100585938
New cuda time without quantization: 108.04141235351562
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.10029602050781
New cuda time without quantization: 105.842529296875
torch.Size([524288, 768]) torch.float16
New cuda time: 105.95724487304688
New cuda time without quantization: 4579.55810546875
torch.Size([524288, 768]) torch.float16
New cuda time: 4579.67431640625
New cuda time without quantization: 93.81553649902344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 94.08785247802734
New cuda time without quantization: 184.421142578125
torch.Size([524288, 768]) torch.float16
New cuda time: 184.66561889648438
New cuda time without quantization: 119.65685272216797
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.7979736328125
New cuda time without quantization: 133.98057556152344
torch.Size([524288, 768]) torch.float16
New cuda time: 134.0978546142578
New cuda time without quantization: 109.80291748046875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.90596008300781
New cuda time without quantization: 97.5364990234375
torch.Size([524288, 768]) torch.float16
New cuda time: 97.63265228271484
New cuda time without quantization: 93.32112884521484
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time without quantization: 103.6444320678711
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.76443481445312
New cuda time without quantization: 111.2255859375
torch.Size([524288, 768]) torch.float16
New cuda time: 111.2883071899414
New cuda time without quantization: 111.2467041015625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.51966094970703
New cuda time without quantization: 94.19143676757812
torch.Size([524288, 768]) torch.float16
New cuda time: 94.25415802001953
New cuda time without quantization: 111.4795150756836
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.58271026611328
New cuda time without quantization: 95.65911865234375
torch.Size([524288, 768]) torch.float16
New cuda time: 95.830322265625
New cuda time without quantization: 131.5535125732422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 131.6202392578125
New cuda time without quantization: 620.5773315429688
torch.Size([524288, 768]) torch.float16
New cuda time: 93.42032623291016
New cuda time without quantization: 109.11299896240234
torch.Size([524288, 768]) torch.float16
New cuda time: 109.19908142089844
New cuda time without quantization: 115.66741180419922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.81556701660156
New cuda time without quantization: 101.87730407714844
torch.Size([524288, 768]) torch.float16
New cuda time: 101.977783203125
New cuda time without quantization: 103.0230712890625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.10259246826172
New cuda time without quantization: 212.4549560546875
torch.Size([524288, 768]) torch.float16
New cuda time: 212.5843963623047
New cuda time without quantization: 117.89109802246094
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.01829528808594
New cuda time without quantization: 93.34656524658203
torch.Size([524288, 768]) torch.float16
New cuda time: 93.46480560302734
New cuda time without quantization: 103.9571533203125
New cuda time: 620.7931518554688
New cuda time without quantization: 1410.010009765625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 104.05859375
New cuda time without quantization: 101.77986145019531
torch.Size([524288, 768]) torch.float16
New cuda time: 101.89442443847656
New cuda time without quantization: 99.26802062988281
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.47954559326172
New cuda time without quantization: 107.89540100097656
torch.Size([524288, 768]) torch.float16
New cuda time: 107.9634017944336
New cuda time without quantization: 106.07539367675781
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.21443176269531
New cuda time without quantization: 113.93621063232422
torch.Size([524288, 768]) torch.float16
New cuda time: 114.21749114990234
New cuda time without quantization: 108.00836181640625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.1666030883789
New cuda time without quantization: 96.42033386230469
torch.Size([524288, 768]) torch.float16
New cuda time: 96.49121856689453
New cuda time without quantization: 4967.755859375
torch.Size([524288, 768]) torch.float16
New cuda time: 4967.91748046875
New cuda time without quantization: 113.67794036865234
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.75506591796875
New cuda time without quantization: 180.48751831054688
torch.Size([524288, 768]) torch.float16
New cuda time: 180.58192443847656
New cuda time without quantization: 124.60343170166016
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.66902923583984
New cuda time without quantization: 100.28300476074219
torch.Size([524288, 768]) torch.float16
New cuda time: 100.38572692871094
New cuda time without quantization: 110.30288696289062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.37857055664062
New cuda time without quantization: 98.3125991821289
torch.Size([524288, 768]) torch.float16
New cuda time: 98.38188171386719
New cuda time without quantization: 120.92981719970703
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time without quantization: 119.30741882324219
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.6389389038086
New cuda time without quantization: 94.76641845703125
torch.Size([524288, 768]) torch.float16
New cuda time: 94.83169555664062
New cuda time without quantization: 105.68595123291016
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.79539489746094
New cuda time without quantization: 105.21619415283203
torch.Size([524288, 768]) torch.float16
New cuda time: 105.32675170898438
New cuda time without quantization: 112.58404541015625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.65412902832031
New cuda time without quantization: 95.44705963134766
torch.Size([524288, 768]) torch.float16
New cuda time: 95.55217742919922
New cuda time without quantization: 68.9991683959961
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 69.38460540771484
New cuda time without quantization: 615.0707397460938
torch.Size([524288, 768]) torch.float16
New cuda time: 121.01429748535156
New cuda time without quantization: 103.81902313232422
torch.Size([524288, 768]) torch.float16
New cuda time: 103.88606262207031
New cuda time without quantization: 101.8086166381836
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 101.91357421875
New cuda time without quantization: 111.44257354736328
torch.Size([524288, 768]) torch.float16
New cuda time: 111.50193786621094
New cuda time without quantization: 124.79783630371094
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.88104248046875
New cuda time without quantization: 189.16868591308594
torch.Size([524288, 768]) torch.float16
New cuda time: 189.2462921142578
New cuda time without quantization: 115.90483093261719
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.98419189453125
New cuda time without quantization: 97.0788345336914
torch.Size([524288, 768]) torch.float16
New cuda time: 97.1637954711914
New cuda time without quantization: 109.98096466064453
New cuda time: 615.374267578125
New cuda time without quantization: 365.5878601074219
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.06864929199219
New cuda time without quantization: 101.15564727783203
torch.Size([524288, 768]) torch.float16
New cuda time: 101.22684478759766
New cuda time without quantization: 116.12435913085938
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.21652221679688
New cuda time without quantization: 108.03632354736328
torch.Size([524288, 768]) torch.float16
New cuda time: 108.11119842529297
New cuda time without quantization: 107.99215698242188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.09648132324219
New cuda time without quantization: 100.84044647216797
torch.Size([524288, 768]) torch.float16
New cuda time: 100.93628692626953
New cuda time without quantization: 108.15984344482422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.22064208984375
New cuda time without quantization: 99.90892791748047
torch.Size([524288, 768]) torch.float16
New cuda time: 99.98060607910156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 365.9462585449219
New cuda time without quantization: 98.88402557373047
torch.Size([524288, 768]) torch.float16
New cuda time: 98.95362091064453
New cuda time without quantization: 66.64427947998047
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 66.95819854736328
New cuda time without quantization: 333.531005859375
torch.Size([524288, 768]) torch.float16
New cuda time: 333.76654052734375
New cuda time without quantization: 67.31436920166016
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 67.61404418945312
New cuda time without quantization: 144.76507568359375
torch.Size([524288, 768]) torch.float16
New cuda time: 145.0797882080078
New cuda time without quantization: 231.20826721191406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 231.45211791992188
New cuda time without quantization: 224.07833862304688
torch.Size([524288, 768]) torch.float16
New cuda time: 224.38697814941406
New cuda time without quantization: 124.10487365722656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.30551147460938
New cuda time without quantization: 97.12042999267578
torch.Size([524288, 768]) torch.float16
New cuda time: 97.1881103515625
New cuda time without quantization: 107.844482421875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.90767669677734
New cuda time without quantization: 105.32207489013672
torch.Size([524288, 768]) torch.float16
New cuda time: 105.38911437988281
New cuda time without quantization: 94.16793823242188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 94.32073974609375
New cuda time without quantization: 102.51565551757812
torch.Size([524288, 768]) torch.float16
New cuda time: 102.6086196899414
New cuda time without quantization: 131.13865661621094
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 131.25946044921875
New cuda time without quantization: 620.759521484375
torch.Size([524288, 768]) torch.float16
New cuda time without quantization: 226.11817932128906
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 226.37161254882812
New cuda time without quantization: 203.80917358398438
torch.Size([524288, 768]) torch.float16
New cuda time: 204.17108154296875
New cuda time without quantization: 67.66973114013672
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 67.93116760253906
New cuda time without quantization: 115.880859375
torch.Size([524288, 768]) torch.float16
New cuda time: 116.26117706298828
New cuda time without quantization: 107.24388122558594
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.3313980102539
New cuda time without quantization: 100.30642700195312
torch.Size([524288, 768]) torch.float16
New cuda time: 100.4864273071289
New cuda time without quantization: 115.06501007080078
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.23028564453125
New cuda time without quantization: 93.12976837158203
torch.Size([524288, 768]) torch.float16
New cuda time: 620.913818359375
New cuda time without quantization: 1410.077392578125
New cuda time: 93.19648742675781
New cuda time without quantization: 107.70468139648438
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.7701187133789
New cuda time without quantization: 107.2723617553711
torch.Size([524288, 768]) torch.float16
New cuda time: 107.33811950683594
New cuda time without quantization: 183.6582489013672
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 183.80673217773438
New cuda time without quantization: 101.3942642211914
torch.Size([524288, 768]) torch.float16
New cuda time: 101.46338653564453
New cuda time without quantization: 114.78324890136719
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.8685302734375
New cuda time without quantization: 97.4700927734375
torch.Size([524288, 768]) torch.float16
New cuda time: 97.57441711425781
New cuda time without quantization: 109.8906021118164
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.95443725585938
New cuda time without quantization: 207.50775146484375
New cuda time without quantization: 1159.450439453125
torch.Size([524288, 768]) torch.float16
New cuda time: 1159.5723876953125
New cuda time without quantization: 114.55827331542969
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.6779556274414
New cuda time without quantization: 251.0166778564453
torch.Size([524288, 768]) torch.float16
New cuda time: 251.11891174316406
New cuda time without quantization: 124.70488739013672
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.77256774902344
New cuda time without quantization: 97.47464752197266
torch.Size([524288, 768]) torch.float16
New cuda time: 97.56201171875
New cuda time without quantization: 103.8503646850586
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.92908477783203
New cuda time without quantization: 103.7318115234375
torch.Size([524288, 768]) torch.float16
New cuda time: 103.82077026367188
New cuda time without quantization: 122.80136108398438
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([524288, 768]) torch.float16
New cuda time: 207.57366943359375
New cuda time without quantization: 108.51123809814453
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.58052062988281
New cuda time without quantization: 88.3124771118164
torch.Size([524288, 768]) torch.float16
New cuda time: 88.37439727783203
New cuda time without quantization: 121.23382568359375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.29718780517578
New cuda time without quantization: 96.74065399169922
torch.Size([524288, 768]) torch.float16
New cuda time: 96.80977630615234
New cuda time without quantization: 111.9402084350586
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.01028442382812
New cuda time without quantization: 176.55039978027344
torch.Size([524288, 768]) torch.float16
New cuda time: 176.62191772460938
New cuda time without quantization: 116.64229583740234
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.77989959716797
New cuda time: 122.85991668701172
New cuda time without quantization: 100.49771118164062
torch.Size([524288, 768]) torch.float16
New cuda time: 100.55323028564453
New cuda time without quantization: 104.14012908935547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 104.25981140136719
New cuda time without quantization: 108.52159881591797
torch.Size([524288, 768]) torch.float16
New cuda time: 108.5814437866211
New cuda time without quantization: 129.03370666503906
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 129.1036376953125
New cuda time without quantization: 180.8191375732422
torch.Size([524288, 768]) torch.float16
New cuda time: 180.91177368164062
New cuda time without quantization: 112.61137390136719
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.68385314941406
New cuda time without quantization: 107.31519317626953
torch.Size([524288, 768]) torch.float16
New cuda time: 107.40718841552734
New cuda time without quantization: 110.07537078857422
New cuda time without quantization: 102.12083435058594
torch.Size([524288, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.13920593261719
New cuda time without quantization: 98.15241241455078
torch.Size([524288, 768]) torch.float16
New cuda time: 98.2437744140625
New cuda time without quantization: 122.45976257324219
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 122.53495788574219
New cuda time without quantization: 109.14656066894531
torch.Size([524288, 768]) torch.float16
New cuda time: 109.2161636352539
New cuda time without quantization: 107.75343322753906
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.8615951538086
New cuda time without quantization: 100.31403350830078
torch.Size([524288, 768]) torch.float16
New cuda time: 100.3780288696289
New cuda time without quantization: 106.8929443359375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.95358276367188
New cuda time without quantization: 101.32587432861328
torch.Size([524288, 768]) torch.float16
New cuda time: 101.41722869873047
New cuda time without quantization: 2219.820068359375
torch.Size([524288, 768]) torch.float16
New cuda time: 2220.001953125
New cuda time without quantization: 118.31944274902344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.65367889404297
New cuda time without quantization: 93.54623413085938
torch.Size([524288, 768]) torch.float16
New cuda time: 93.69135284423828
New cuda time without quantization: 124.96825408935547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 125.0610580444336
New cuda time without quantization: 94.28031921386719
torch.Size([524288, 768]) torch.float16
New cuda time: 94.38655853271484
New cuda time without quantization: 76.04649353027344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 76.1119384765625
New cuda time without quantization: 122.77449798583984
torch.Size([524288, 768]) torch.float16
New cuda time: 123.08265686035156
New cuda time without quantization: 97.64976501464844
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time without quantization: 107.29631042480469
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.37775421142578
New cuda time without quantization: 114.22547149658203
torch.Size([524288, 768]) torch.float16
New cuda time: 114.2872314453125
New cuda time without quantization: 109.05248260498047
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.11759948730469
New cuda time without quantization: 104.59229278564453
torch.Size([524288, 768]) torch.float16
New cuda time: 104.65373229980469
New cuda time without quantization: 111.43329620361328
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.50401306152344
New cuda time without quantization: 102.6660385131836
torch.Size([524288, 768]) torch.float16
New cuda time: 102.76364135742188
New cuda time without quantization: 136.8766326904297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 136.99392700195312
New cuda time without quantization: 610.7802124023438
torch.Size([524288, 768]) torch.float16
New cuda time: 97.75728607177734
New cuda time without quantization: 103.55683135986328
torch.Size([524288, 768]) torch.float16
New cuda time: 103.8166732788086
New cuda time without quantization: 79.67626953125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 80.03739166259766
New cuda time without quantization: 78.89146423339844
torch.Size([524288, 768]) torch.float16
New cuda time: 79.03050231933594
New cuda time without quantization: 103.16242218017578
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.2867431640625
New cuda time without quantization: 180.040771484375
torch.Size([524288, 768]) torch.float16
New cuda time: 180.1471710205078
New cuda time without quantization: 112.35237884521484
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.41909790039062
New cuda time without quantization: 103.4678726196289
torch.Size([524288, 768]) torch.float16
New cuda time: 103.56626892089844
New cuda time without quantization: 113.90614318847656
New cuda time: 610.8746337890625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.970947265625
New cuda time without quantization: 99.08849334716797
torch.Size([524288, 768]) torch.float16
New cuda time: 99.1977767944336
New cuda time without quantization: 123.6154556274414
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 123.7957763671875
New cuda time without quantization: 108.64596557617188
torch.Size([524288, 768]) torch.float16
New cuda time: 108.75364685058594
New cuda time without quantization: 112.78741455078125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.95477294921875
New cuda time without quantization: 95.72223663330078
torch.Size([524288, 768]) torch.float16
New cuda time: 95.80000305175781
New cuda time without quantization: 81.19338989257812
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 81.28091430664062
New cuda time without quantization: 91.15934753417969
torch.Size([524288, 768]) torch.float16
New cuda time: 91.30782318115234
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 1410.2879638671875
New cuda time without quantization: 98.61529541015625
torch.Size([524288, 768]) torch.float16
New cuda time: 98.67833709716797
New cuda time without quantization: 369.13372802734375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 369.4330749511719
New cuda time without quantization: 330.031494140625
torch.Size([524288, 768]) torch.float16
New cuda time: 330.1935729980469
New cuda time without quantization: 674.9129638671875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 675.1255493164062
New cuda time without quantization: 145.7953338623047
torch.Size([524288, 768]) torch.float16
New cuda time: 146.0382080078125
New cuda time without quantization: 231.08544921875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 231.16290283203125
New cuda time without quantization: 216.60891723632812
torch.Size([524288, 768]) torch.float16
New cuda time: 216.71163940429688
New cuda time without quantization: 116.63526916503906
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.9631118774414
New cuda time without quantization: 96.45088195800781
torch.Size([524288, 768]) torch.float16
New cuda time: 96.56448364257812
New cuda time without quantization: 115.61383056640625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.78070831298828
New cuda time without quantization: 104.42979431152344
torch.Size([524288, 768]) torch.float16
New cuda time: 104.49427032470703
New cuda time without quantization: 112.73893737792969
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.81013488769531
New cuda time without quantization: 95.52143859863281
torch.Size([524288, 768]) torch.float16
New cuda time: 95.63471984863281
New cuda time without quantization: 140.06207275390625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 140.24111938476562
New cuda time without quantization: 95.70623779296875
torch.Size([524288, 768]) torch.float16
New cuda time without quantization: 226.38800048828125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 226.4832000732422
New cuda time without quantization: 203.9738311767578
torch.Size([524288, 768]) torch.float16
New cuda time: 204.04310607910156
New cuda time without quantization: 201.3680419921875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 201.45188903808594
New cuda time without quantization: 118.67906188964844
torch.Size([524288, 768]) torch.float16
New cuda time: 118.73714447021484
New cuda time without quantization: 113.03887939453125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.13887786865234
New cuda time without quantization: 95.02728271484375
torch.Size([524288, 768]) torch.float16
New cuda time: 95.08296203613281
New cuda time without quantization: 114.44784545898438
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.51680755615234
New cuda time without quantization: 103.51628112792969
torch.Size([524288, 768]) torch.float16
New cuda time: 95.76416015625
New cuda time without quantization: 1887.8883056640625
New cuda time: 103.59915924072266
New cuda time without quantization: 109.70926666259766
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.7761459350586
New cuda time without quantization: 96.33625030517578
torch.Size([524288, 768]) torch.float16
New cuda time: 96.40216827392578
New cuda time without quantization: 64.84587860107422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 64.92091369628906
New cuda time without quantization: 100.41658020019531
torch.Size([524288, 768]) torch.float16
New cuda time: 100.4858627319336
New cuda time without quantization: 115.09217071533203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.15104675292969
New cuda time without quantization: 99.3844223022461
torch.Size([524288, 768]) torch.float16
New cuda time: 99.44890594482422
New cuda time without quantization: 107.21261596679688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.44205474853516
New cuda time without quantization: 91.07366180419922
New cuda time without quantization: 5238.54296875
torch.Size([524288, 768]) torch.float16
New cuda time: 5238.65966796875
New cuda time without quantization: 107.20777893066406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.4512939453125
New cuda time without quantization: 208.9518585205078
torch.Size([524288, 768]) torch.float16
New cuda time: 209.22946166992188
New cuda time without quantization: 131.73939514160156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 131.87107849121094
New cuda time without quantization: 124.45343780517578
torch.Size([524288, 768]) torch.float16
New cuda time: 124.56912231445312
New cuda time without quantization: 106.58089447021484
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.82281494140625
New cuda time without quantization: 99.81318664550781
torch.Size([524288, 768]) torch.float16
New cuda time: 99.93206024169922
New cuda time without quantization: 111.56123352050781
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([524288, 768]) torch.float16
New cuda time: 91.12870025634766
New cuda time without quantization: 220.9027099609375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 221.00782775878906
New cuda time without quantization: 99.89674377441406
torch.Size([524288, 768]) torch.float16
New cuda time: 99.98714447021484
New cuda time without quantization: 106.8831787109375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.94109344482422
New cuda time without quantization: 98.3760986328125
torch.Size([524288, 768]) torch.float16
New cuda time: 98.43993377685547
New cuda time without quantization: 113.20127868652344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.26927947998047
New cuda time without quantization: 183.3172607421875
torch.Size([524288, 768]) torch.float16
New cuda time: 183.7721405029297
New cuda time without quantization: 107.50157928466797
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.57069396972656
New cuda time: 111.6490707397461
New cuda time without quantization: 96.81109619140625
torch.Size([524288, 768]) torch.float16
New cuda time: 96.94581604003906
New cuda time without quantization: 118.77070617675781
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.93694305419922
New cuda time without quantization: 101.91399383544922
torch.Size([524288, 768]) torch.float16
New cuda time: 101.99751281738281
New cuda time without quantization: 99.60566711425781
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.74870300292969
New cuda time without quantization: 205.94479370117188
torch.Size([524288, 768]) torch.float16
New cuda time: 206.1294403076172
New cuda time without quantization: 110.08938598632812
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.1980209350586
New cuda time without quantization: 103.59960174560547
torch.Size([524288, 768]) torch.float16
New cuda time: 103.70455932617188
New cuda time without quantization: 111.0100326538086
New cuda time without quantization: 99.53850555419922
torch.Size([524288, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.14491271972656
New cuda time without quantization: 98.66214752197266
torch.Size([524288, 768]) torch.float16
New cuda time: 98.763427734375
New cuda time without quantization: 100.27447509765625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 100.36967468261719
New cuda time without quantization: 117.73005676269531
torch.Size([524288, 768]) torch.float16
New cuda time: 117.91661834716797
New cuda time without quantization: 110.44731140136719
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.59210968017578
New cuda time without quantization: 107.13033294677734
torch.Size([524288, 768]) torch.float16
New cuda time: 107.19593811035156
New cuda time without quantization: 106.73625946044922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.83177947998047
New cuda time without quantization: 107.38137817382812
torch.Size([524288, 768]) torch.float16
New cuda time: 107.50953674316406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 1410.265380859375
New cuda time without quantization: 99.20555877685547
torch.Size([524288, 768]) torch.float16
New cuda time: 99.2703628540039
New cuda time without quantization: 369.6253356933594
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 369.8314208984375
New cuda time without quantization: 330.1725158691406
torch.Size([524288, 768]) torch.float16
New cuda time: 330.2542724609375
New cuda time without quantization: 664.6015625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 664.794189453125
New cuda time without quantization: 145.64849853515625
torch.Size([524288, 768]) torch.float16
New cuda time: 145.72193908691406
New cuda time without quantization: 231.9571990966797
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 232.09815979003906
New cuda time without quantization: 223.8549346923828
torch.Size([524288, 768]) torch.float16
New cuda time: 223.9344482421875
New cuda time without quantization: 118.37037658691406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.50973510742188
New cuda time without quantization: 96.93861389160156
torch.Size([524288, 768]) torch.float16
New cuda time: 97.02517700195312
New cuda time without quantization: 118.12877655029297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.20829772949219
New cuda time without quantization: 94.74884796142578
torch.Size([524288, 768]) torch.float16
New cuda time: 94.84276580810547
New cuda time without quantization: 96.73845672607422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 96.84341430664062
New cuda time without quantization: 101.01303100585938
torch.Size([524288, 768]) torch.float16
New cuda time: 101.126953125
New cuda time without quantization: 138.45814514160156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 138.5952606201172
New cuda time without quantization: 108.43353271484375
torch.Size([524288, 768]) torch.float16
New cuda time without quantization: 226.47796630859375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 226.56980895996094
New cuda time without quantization: 204.26123046875
torch.Size([524288, 768]) torch.float16
New cuda time: 204.3437957763672
New cuda time without quantization: 204.59771728515625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 204.68731689453125
New cuda time without quantization: 115.49874877929688
torch.Size([524288, 768]) torch.float16
New cuda time: 115.56419372558594
New cuda time without quantization: 106.85711669921875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.94096374511719
New cuda time without quantization: 101.42125701904297
torch.Size([524288, 768]) torch.float16
New cuda time: 101.4831771850586
New cuda time without quantization: 103.2527847290039
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.35406494140625
New cuda time without quantization: 100.12908935546875
torch.Size([524288, 768]) torch.float16
New cuda time: 108.50297546386719
New cuda time without quantization: 1591.8311767578125
New cuda time: 100.18860626220703
New cuda time without quantization: 111.23409271240234
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.29793548583984
New cuda time without quantization: 101.75277709960938
torch.Size([524288, 768]) torch.float16
New cuda time: 101.8343734741211
New cuda time without quantization: 179.23568725585938
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 179.31776428222656
New cuda time without quantization: 101.3207778930664
torch.Size([524288, 768]) torch.float16
New cuda time: 101.39085388183594
New cuda time without quantization: 104.2374267578125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 104.32686614990234
New cuda time without quantization: 99.57196807861328
torch.Size([524288, 768]) torch.float16
New cuda time: 99.63740539550781
New cuda time without quantization: 107.3881607055664
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.45951843261719
New cuda time without quantization: 102.52189636230469
New cuda time without quantization: 5693.2529296875
torch.Size([524288, 768]) torch.float16
New cuda time: 5693.39599609375
New cuda time without quantization: 107.4006576538086
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.53617858886719
New cuda time without quantization: 185.7305145263672
torch.Size([524288, 768]) torch.float16
New cuda time: 185.84539794921875
New cuda time without quantization: 138.38201904296875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 138.57066345214844
New cuda time without quantization: 125.74524688720703
torch.Size([524288, 768]) torch.float16
New cuda time: 126.0145263671875
New cuda time without quantization: 109.06385803222656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.20657348632812
New cuda time without quantization: 104.62482452392578
torch.Size([524288, 768]) torch.float16
New cuda time: 104.72562408447266
New cuda time without quantization: 108.5873794555664
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([524288, 768]) torch.float16
New cuda time: 102.6199722290039
New cuda time without quantization: 212.8916778564453
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 212.95791625976562
New cuda time without quantization: 99.75885009765625
torch.Size([524288, 768]) torch.float16
New cuda time: 99.82109069824219
New cuda time without quantization: 109.49568939208984
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.5875244140625
New cuda time without quantization: 96.3028335571289
torch.Size([524288, 768]) torch.float16
New cuda time: 96.36507415771484
New cuda time without quantization: 113.56803131103516
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.63091278076172
New cuda time without quantization: 183.222900390625
torch.Size([524288, 768]) torch.float16
New cuda time: 183.29266357421875
New cuda time without quantization: 107.46623992919922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.53279876708984
New cuda time: 108.65553283691406
New cuda time without quantization: 94.91189575195312
torch.Size([524288, 768]) torch.float16
New cuda time: 95.00596618652344
New cuda time without quantization: 147.1051788330078
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 147.3013458251953
New cuda time without quantization: 84.2912826538086
torch.Size([524288, 768]) torch.float16
New cuda time: 84.36759948730469
New cuda time without quantization: 108.87105560302734
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.06417846679688
New cuda time without quantization: 206.89141845703125
torch.Size([524288, 768]) torch.float16
New cuda time: 207.0816650390625
New cuda time without quantization: 104.384033203125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 104.45602416992188
New cuda time without quantization: 109.32241821289062
torch.Size([524288, 768]) torch.float16
New cuda time: 109.44145965576172
New cuda time without quantization: 107.79409790039062
New cuda time without quantization: 100.62509155273438
torch.Size([524288, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.86161804199219
New cuda time without quantization: 80.99561309814453
torch.Size([524288, 768]) torch.float16
New cuda time: 81.11417388916016
New cuda time without quantization: 117.78831481933594
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.89151000976562
New cuda time without quantization: 92.63142395019531
torch.Size([524288, 768]) torch.float16
New cuda time: 92.69541931152344
New cuda time without quantization: 132.2801055908203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 132.42010498046875
New cuda time without quantization: 93.7875747680664
torch.Size([524288, 768]) torch.float16
New cuda time: 93.8546142578125
New cuda time without quantization: 110.41345977783203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.54864501953125
New cuda time without quantization: 101.98291015625
torch.Size([524288, 768]) torch.float16
New cuda time: 102.0513916015625
New cuda time without quantization: 1414.8084716796875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 1415.0418701171875
New cuda time without quantization: 98.70873260498047
torch.Size([524288, 768]) torch.float16
New cuda time: 98.7778549194336
New cuda time without quantization: 369.7616882324219
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 369.9224853515625
New cuda time without quantization: 332.42547607421875
torch.Size([524288, 768]) torch.float16
New cuda time: 332.6661071777344
New cuda time without quantization: 672.8834838867188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 673.0142211914062
New cuda time without quantization: 145.91270446777344
torch.Size([524288, 768]) torch.float16
New cuda time: 145.9759063720703
New cuda time without quantization: 217.92031860351562
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 218.03823852539062
New cuda time without quantization: 225.23876953125
torch.Size([524288, 768]) torch.float16
New cuda time without quantization: 118.09822845458984
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.16238403320312
New cuda time without quantization: 94.64741516113281
torch.Size([524288, 768]) torch.float16
New cuda time: 94.72357940673828
New cuda time without quantization: 115.66191864013672
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.7385482788086
New cuda time without quantization: 105.1491470336914
torch.Size([524288, 768]) torch.float16
New cuda time: 105.21186065673828
New cuda time without quantization: 112.40673065185547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.48735809326172
New cuda time without quantization: 102.75987243652344
torch.Size([524288, 768]) torch.float16
New cuda time: 103.02082824707031
New cuda time without quantization: 130.66859436035156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 130.79371643066406
New cuda time without quantization: 96.08548736572266
torch.Size([524288, 768]) torch.float16
New cuda time: 225.39572143554688
New cuda time without quantization: 239.2689208984375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 239.38796997070312
New cuda time without quantization: 203.9525604248047
torch.Size([524288, 768]) torch.float16
New cuda time: 204.04440307617188
New cuda time without quantization: 225.21429443359375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 225.3096466064453
New cuda time without quantization: 95.73863983154297
torch.Size([524288, 768]) torch.float16
New cuda time: 95.7979965209961
New cuda time without quantization: 100.05482482910156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 100.16682434082031
New cuda time without quantization: 107.42591094970703
torch.Size([524288, 768]) torch.float16
New cuda time: 107.490234375
New cuda time without quantization: 115.50643920898438
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.59539794921875
New cuda time without quantization: 100.89115142822266
New cuda time: 96.29796600341797
New cuda time without quantization: 1608.1689453125
torch.Size([524288, 768]) torch.float16
New cuda time: 100.95451354980469
New cuda time without quantization: 107.9310302734375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.9983901977539
New cuda time without quantization: 96.453369140625
torch.Size([524288, 768]) torch.float16
New cuda time: 96.52169036865234
New cuda time without quantization: 189.48080444335938
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 189.5655975341797
New cuda time without quantization: 97.65337371826172
torch.Size([524288, 768]) torch.float16
New cuda time: 97.71977233886719
New cuda time without quantization: 115.35060119628906
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.41268157958984
New cuda time without quantization: 99.0471420288086
torch.Size([524288, 768]) torch.float16
New cuda time: 99.13786315917969
New cuda time without quantization: 107.91886901855469
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.98383331298828
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 1888.1583251953125
New cuda time without quantization: 98.84561920166016
torch.Size([524288, 768]) torch.float16
New cuda time: 98.91729736328125
New cuda time without quantization: 321.62957763671875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 321.91436767578125
New cuda time without quantization: 97.59536743164062
torch.Size([524288, 768]) torch.float16
New cuda time: 97.65776824951172
New cuda time without quantization: 898.9251098632812
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 899.07470703125
New cuda time without quantization: 119.75785064697266
torch.Size([524288, 768]) torch.float16
New cuda time: 119.85688781738281
New cuda time without quantization: 99.4712142944336
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.75361633300781
New cuda time without quantization: 224.22811889648438
torch.Size([524288, 768]) torch.float16
New cuda time: 224.57675170898438
New cuda time without quantization: 208.38409423828125
torch.Size([524288, 768]) torch.float16
New cuda time: 208.45321655273438
New cuda time without quantization: 107.70159149169922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.7651138305664
New cuda time without quantization: 99.93834686279297
torch.Size([524288, 768]) torch.float16
New cuda time: 100.03370666503906
New cuda time without quantization: 107.18671417236328
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.34319305419922
New cuda time without quantization: 104.64893341064453
torch.Size([524288, 768]) torch.float16
New cuda time: 104.70685577392578
New cuda time without quantization: 105.52798461914062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.5911865234375
New cuda time without quantization: 184.5482940673828
torch.Size([524288, 768]) torch.float16
New cuda time: 184.6466827392578
New cuda time without quantization: 109.57344055175781
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time without quantization: 357.7997741699219
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 358.10504150390625
New cuda time without quantization: 204.95172119140625
torch.Size([524288, 768]) torch.float16
New cuda time: 205.06741333007812
New cuda time without quantization: 200.33395385742188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 200.62371826171875
New cuda time without quantization: 94.63744354248047
torch.Size([524288, 768]) torch.float16
New cuda time: 94.70191955566406
New cuda time without quantization: 106.67876434326172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.99748992919922
New cuda time without quantization: 102.14850616455078
torch.Size([524288, 768]) torch.float16
New cuda time: 102.21298217773438
New cuda time without quantization: 91.4217529296875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 91.54175567626953
New cuda time without quantization: 102.15570068359375
torch.Size([524288, 768]) torch.float16
New cuda time: 109.64112091064453
New cuda time without quantization: 99.62186431884766
New cuda time: 102.23666381835938
New cuda time without quantization: 110.25845336914062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.63557434082031
New cuda time without quantization: 94.29248046875
torch.Size([524288, 768]) torch.float16
New cuda time: 94.36351776123047
New cuda time without quantization: 187.9766387939453
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 188.23695373535156
New cuda time without quantization: 97.54048919677734
torch.Size([524288, 768]) torch.float16
New cuda time: 97.65312957763672
New cuda time without quantization: 116.33222961425781
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.55654907226562
New cuda time without quantization: 97.02976989746094
torch.Size([524288, 768]) torch.float16
New cuda time: 97.14016723632812
New cuda time without quantization: 110.10133361816406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.16629791259766
New cuda time without quantization: 208.49574279785156
torch.Size([524288, 768]) torch.float16
torch.Size([524288, 768]) torch.float16
New cuda time: 208.5813446044922
New cuda time without quantization: 107.98004913330078
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.05540466308594
New cuda time without quantization: 88.63614654541016
torch.Size([524288, 768]) torch.float16
New cuda time: 88.70494079589844
New cuda time without quantization: 119.36408996582031
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.52008819580078
New cuda time without quantization: 98.73521423339844
torch.Size([524288, 768]) torch.float16
New cuda time: 98.81121826171875
New cuda time without quantization: 112.31190490722656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.3848648071289
New cuda time without quantization: 175.96539306640625
torch.Size([524288, 768]) torch.float16
New cuda time: 176.02859497070312
New cuda time without quantization: 118.30744171142578
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.38616180419922
New cuda time without quantization: 3961.714111328125
torch.Size([524288, 768]) torch.float16
New cuda time: 3961.844970703125
New cuda time without quantization: 117.75652313232422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.82723999023438
New cuda time without quantization: 168.91290283203125
torch.Size([524288, 768]) torch.float16
New cuda time: 168.99961853027344
New cuda time without quantization: 125.01750946044922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 125.09046936035156
New cuda time without quantization: 85.96453857421875
torch.Size([524288, 768]) torch.float16
New cuda time: 86.06693267822266
New cuda time without quantization: 106.82687377929688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.89855194091797
New cuda time without quantization: 129.2388153076172
torch.Size([524288, 768]) torch.float16
New cuda time: 129.3378448486328
New cuda time without quantization: 97.60651397705078
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time without quantization: 102.97379302978516
torch.Size([524288, 768]) torch.float16
New cuda time: 97.66970825195312
New cuda time without quantization: 100.40876007080078
torch.Size([524288, 768]) torch.float16
New cuda time: 100.4706802368164
New cuda time without quantization: 104.18477630615234
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 104.26861572265625
New cuda time without quantization: 108.66560363769531
torch.Size([524288, 768]) torch.float16
New cuda time: 108.72640228271484
New cuda time without quantization: 129.4296875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 129.50233459472656
New cuda time without quantization: 180.08863830566406
torch.Size([524288, 768]) torch.float16
New cuda time: 180.1702423095703
New cuda time without quantization: 112.89201354980469
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.97025299072266
New cuda time without quantization: 107.30078887939453
torch.Size([524288, 768]) torch.float16
New cuda time: 107.37647247314453
New cuda time without quantization: 110.22624969482422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 1591.9969482421875
New cuda time without quantization: 425.33990478515625
torch.Size([524288, 768]) torch.float16
New cuda time: 425.44757080078125
New cuda time without quantization: 360.5975646972656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 360.7586975097656
New cuda time without quantization: 95.51268768310547
torch.Size([524288, 768]) torch.float16
New cuda time: 95.57844543457031
New cuda time without quantization: 909.1984252929688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 909.487548828125
New cuda time without quantization: 69.85626983642578
torch.Size([524288, 768]) torch.float16
New cuda time: 69.9343490600586
New cuda time without quantization: 175.61317443847656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 175.7130126953125
New cuda time without quantization: 219.2251739501953
torch.Size([524288, 768]) torch.float16
New cuda time: 219.31285095214844
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.28960418701172
New cuda time without quantization: 95.92362213134766
torch.Size([524288, 768]) torch.float16
New cuda time: 95.99962615966797
New cuda time without quantization: 122.81558227539062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 122.8845443725586
New cuda time without quantization: 108.90831756591797
torch.Size([524288, 768]) torch.float16
New cuda time: 109.05343627929688
New cuda time without quantization: 107.83903503417969
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.92607116699219
New cuda time without quantization: 100.25611877441406
torch.Size([524288, 768]) torch.float16
New cuda time: 100.31643676757812
New cuda time without quantization: 107.06446838378906
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.12591552734375
New cuda time without quantization: 101.4471664428711
torch.Size([524288, 768]) torch.float16
New cuda time: 101.5231704711914
New cuda time without quantization: 348.01959228515625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 348.1347961425781
New cuda time without quantization: 212.88595581054688
torch.Size([524288, 768]) torch.float16
New cuda time: 213.0259552001953
New cuda time without quantization: 182.2088623046875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 182.29959106445312
New cuda time without quantization: 99.15382385253906
torch.Size([524288, 768]) torch.float16
New cuda time: 99.36902618408203
New cuda time without quantization: 112.72460174560547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.89916229248047
New cuda time without quantization: 94.63444519042969
torch.Size([524288, 768]) torch.float16
New cuda time: 94.7000503540039
New cuda time without quantization: 114.43981170654297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.53724670410156
New cuda time without quantization: 94.12773132324219
torch.Size([524288, 768]) torch.float16
New cuda time without quantization: 107.62975311279297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.7436752319336
New cuda time without quantization: 111.21553039550781
torch.Size([524288, 768]) torch.float16
New cuda time: 111.28016662597656
New cuda time without quantization: 116.82771301269531
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.9040298461914
New cuda time without quantization: 96.55706024169922
torch.Size([524288, 768]) torch.float16
New cuda time: 96.62138366699219
New cuda time without quantization: 111.4524917602539
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.51937103271484
New cuda time without quantization: 102.77485656738281
torch.Size([524288, 768]) torch.float16
New cuda time: 102.8444595336914
New cuda time without quantization: 136.85372924804688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 136.98268127441406
New cuda time without quantization: 610.10205078125
torch.Size([524288, 768]) torch.float16
New cuda time: 94.19236755371094
New cuda time without quantization: 102.3951187133789
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 102.54232025146484
New cuda time without quantization: 102.36199951171875
torch.Size([524288, 768]) torch.float16
New cuda time: 102.60295867919922
New cuda time without quantization: 180.37814331054688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 180.5435791015625
New cuda time without quantization: 99.34294128417969
torch.Size([524288, 768]) torch.float16
New cuda time: 99.42390441894531
New cuda time without quantization: 115.63037109375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.71644592285156
New cuda time without quantization: 100.2011947631836
torch.Size([524288, 768]) torch.float16
New cuda time: 100.3720703125
New cuda time without quantization: 106.81913757324219
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.89945220947266
New cuda time without quantization: 192.89434814453125
New cuda time: 610.1871948242188
torch.Size([524288, 768]) torch.float16
New cuda time: 193.06362915039062
New cuda time without quantization: 97.3823013305664
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 97.560546875
New cuda time without quantization: 96.9101333618164
torch.Size([524288, 768]) torch.float16
New cuda time: 97.05157470703125
New cuda time without quantization: 112.38027954101562
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.53292083740234
New cuda time without quantization: 86.4128189086914
torch.Size([524288, 768]) torch.float16
New cuda time: 86.5364990234375
New cuda time without quantization: 113.53340911865234
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.6550064086914
New cuda time without quantization: 182.6988067626953
torch.Size([524288, 768]) torch.float16
New cuda time: 182.78631591796875
New cuda time without quantization: 107.45257568359375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.52057647705078
New cuda time without quantization: 1415.7535400390625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 1415.86083984375
New cuda time without quantization: 98.58715057373047
torch.Size([524288, 768]) torch.float16
New cuda time: 98.65451049804688
New cuda time without quantization: 371.7069091796875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 371.78466796875
New cuda time without quantization: 331.40179443359375
torch.Size([524288, 768]) torch.float16
New cuda time: 331.5270690917969
New cuda time without quantization: 672.460205078125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 672.5554809570312
New cuda time without quantization: 145.3884735107422
torch.Size([524288, 768]) torch.float16
New cuda time: 145.4600067138672
New cuda time without quantization: 99.26555633544922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.32891845703125
New cuda time without quantization: 344.1623229980469
torch.Size([524288, 768]) torch.float16
New cuda time without quantization: 96.85941314697266
torch.Size([524288, 768]) torch.float16
New cuda time: 344.2469787597656
New cuda time without quantization: 239.68873596191406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 239.7717742919922
New cuda time without quantization: 204.01210021972656
torch.Size([524288, 768]) torch.float16
New cuda time: 204.0767364501953
New cuda time without quantization: 224.7973175048828
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 224.8745880126953
New cuda time without quantization: 96.04474639892578
torch.Size([524288, 768]) torch.float16
New cuda time: 96.10794067382812
New cuda time without quantization: 100.16188049316406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 100.22924041748047
New cuda time without quantization: 107.36687469482422
torch.Size([524288, 768]) torch.float16
New cuda time: 107.43983459472656
New cuda time without quantization: 113.87666320800781
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.95138549804688
New cuda time without quantization: 102.41165924072266
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 1608.3892822265625
New cuda time without quantization: 426.4039306640625
torch.Size([524288, 768]) torch.float16
New cuda time: 426.52264404296875
New cuda time without quantization: 365.6197814941406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 365.9135437011719
New cuda time without quantization: 97.45476531982422
torch.Size([524288, 768]) torch.float16
New cuda time: 97.52597045898438
New cuda time without quantization: 908.3060913085938
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 908.579833984375
New cuda time without quantization: 70.45692443847656
torch.Size([524288, 768]) torch.float16
New cuda time: 70.52940368652344
New cuda time without quantization: 171.9508819580078
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 172.0240020751953
New cuda time without quantization: 218.9430694580078
torch.Size([524288, 768]) torch.float16
New cuda time: 219.0398712158203
torch.Size([524288, 768]) torch.float16
New cuda time: 102.48621368408203
New cuda time without quantization: 108.23712158203125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.36192321777344
New cuda time without quantization: 98.51099395751953
torch.Size([524288, 768]) torch.float16
New cuda time: 98.58026885986328
New cuda time without quantization: 183.48561096191406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 183.60369873046875
New cuda time without quantization: 101.49756622314453
torch.Size([524288, 768]) torch.float16
New cuda time: 101.5630111694336
New cuda time without quantization: 115.47347259521484
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.53971099853516
New cuda time without quantization: 99.63147735595703
torch.Size([524288, 768]) torch.float16
New cuda time: 99.72348022460938
New cuda time without quantization: 110.02128601074219
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.12256622314453
New cuda time without quantization: 355.0767822265625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 355.2142028808594
New cuda time without quantization: 203.71047973632812
torch.Size([524288, 768]) torch.float16
New cuda time: 203.80213928222656
New cuda time without quantization: 201.28280639648438
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 201.377685546875
New cuda time without quantization: 111.34368896484375
torch.Size([524288, 768]) torch.float16
New cuda time: 111.40784454345703
New cuda time without quantization: 114.76175689697266
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.00495910644531
New cuda time without quantization: 100.5128402709961
torch.Size([524288, 768]) torch.float16
New cuda time: 100.57827758789062
New cuda time without quantization: 114.77152252197266
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.87055969238281
New cuda time without quantization: 92.15958404541016
torch.Size([524288, 768]) torch.float16
New cuda time without quantization: 91.5487289428711
torch.Size([524288, 768]) torch.float16
New cuda time: 91.61304473876953
New cuda time without quantization: 221.6403350830078
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 221.71633911132812
New cuda time without quantization: 99.82795715332031
torch.Size([524288, 768]) torch.float16
New cuda time: 99.90892028808594
New cuda time without quantization: 107.0948715209961
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.15919494628906
New cuda time without quantization: 94.65289306640625
torch.Size([524288, 768]) torch.float16
New cuda time: 94.75305938720703
New cuda time without quantization: 107.01151275634766
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.07759094238281
New cuda time without quantization: 183.3121795654297
torch.Size([524288, 768]) torch.float16
New cuda time: 183.37857055664062
New cuda time without quantization: 108.37120056152344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 92.21990203857422
New cuda time without quantization: 117.60015106201172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.71710968017578
New cuda time without quantization: 98.26197052001953
torch.Size([524288, 768]) torch.float16
New cuda time: 98.32868957519531
New cuda time without quantization: 187.11660766601562
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 187.27723693847656
New cuda time without quantization: 96.85636901855469
torch.Size([524288, 768]) torch.float16
New cuda time: 96.93780517578125
New cuda time without quantization: 99.2942886352539
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.41123962402344
New cuda time without quantization: 97.29412841796875
torch.Size([524288, 768]) torch.float16
New cuda time: 97.38629150390625
New cuda time without quantization: 95.87173461914062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 95.97716522216797
New cuda time without quantization: 204.62806701660156
New cuda time: 108.4375991821289
New cuda time without quantization: 103.192138671875
torch.Size([524288, 768]) torch.float16
New cuda time: 204.7235870361328
New cuda time without quantization: 108.81249237060547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.88673400878906
New cuda time without quantization: 100.81427764892578
torch.Size([524288, 768]) torch.float16
New cuda time: 100.92868041992188
New cuda time without quantization: 108.57809448242188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.71137237548828
New cuda time without quantization: 102.94147491455078
torch.Size([524288, 768]) torch.float16
New cuda time: 103.0230712890625
New cuda time without quantization: 105.54035186767578
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.61970520019531
New cuda time without quantization: 175.0944061279297
torch.Size([524288, 768]) torch.float16
New cuda time: 175.1609649658203
New cuda time without quantization: 116.74336242675781
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.8131103515625
torch.Size([524288, 768]) torch.float16
New cuda time without quantization: 96.95620727539062
torch.Size([524288, 768]) torch.float16
New cuda time: 103.04515075683594
New cuda time without quantization: 106.68035888671875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.86180114746094
New cuda time without quantization: 60.0096435546875
torch.Size([524288, 768]) torch.float16
New cuda time: 60.11700439453125
New cuda time without quantization: 213.54823303222656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 213.6250457763672
New cuda time without quantization: 118.74664306640625
torch.Size([524288, 768]) torch.float16
New cuda time: 118.8277587890625
New cuda time without quantization: 113.00310516357422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.06694030761719
New cuda time without quantization: 98.92593383789062
torch.Size([524288, 768]) torch.float16
New cuda time: 98.986572265625
New cuda time without quantization: 66.5307846069336
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 66.6146240234375
New cuda time without quantization: 190.7937774658203
torch.Size([524288, 768]) torch.float16
New cuda time: 190.8636932373047
New cuda time without quantization: 102.42355346679688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 102.48963165283203
New cuda time without quantization: 102.46099090576172
torch.Size([524288, 768]) torch.float16
New cuda time: 102.5291519165039
New cuda time without quantization: 114.31591033935547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.40486907958984
New cuda time without quantization: 99.0822525024414
torch.Size([524288, 768]) torch.float16
New cuda time: 99.14945220947266
New cuda time without quantization: 108.97876739501953
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.13909149169922
New cuda time without quantization: 177.87484741210938
torch.Size([524288, 768]) torch.float16
New cuda time: 178.10989379882812
New cuda time without quantization: 121.52617645263672
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.69417572021484
New cuda time without quantization: 98.43473815917969
torch.Size([524288, 768]) torch.float16
New cuda time: 98.50433349609375
New cuda time without quantization: 123.66218566894531
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 123.84490203857422
New cuda time without quantization: 99.0489730834961
torch.Size([524288, 768]) torch.float16
New cuda time: 99.1131362915039
New cuda time without quantization: 231.1363067626953
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 231.21054077148438
New cuda time without quantization: 51.81073760986328
torch.Size([524288, 768]) torch.float16
New cuda time: 52.129615783691406
New cuda time without quantization: 144.31072998046875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 144.3878631591797
New cuda time without quantization: 82.21179962158203
torch.Size([524288, 768]) torch.float16
New cuda time: 82.27404022216797
New cuda time without quantization: 83.0231704711914
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 83.19932556152344
New cuda time without quantization: 196.96435546875
torch.Size([524288, 768]) torch.float16
New cuda time: 197.0773162841797
New cuda time without quantization: 117.4543228149414
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.52680206298828
New cuda time without quantization: 108.89557647705078
torch.Size([524288, 768]) torch.float16
New cuda time: 109.02373504638672
New cuda time without quantization: 119.50009155273438
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.66520690917969
New cuda time without quantization: 103.4051513671875
torch.Size([524288, 768]) torch.float16
New cuda time: 103.47379302978516
New cuda time without quantization: 110.28709411621094
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.35301971435547
New cuda time without quantization: 121.09961700439453
torch.Size([524288, 768]) torch.float16
New cuda time: 121.16441345214844
New cuda time without quantization: 106.44132995605469
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.5040512084961
New cuda time without quantization: 104.80148315429688
torch.Size([524288, 768]) torch.float16
New cuda time: 104.86467742919922
New cuda time without quantization: 108.91685485839844
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.9822998046875
New cuda time without quantization: 151.9298095703125
torch.Size([524288, 768]) torch.float16
New cuda time: 152.00421142578125
New cuda time without quantization: 110.84822082519531
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.93062591552734
New cuda time without quantization: 97.60657501220703
torch.Size([524288, 768]) torch.float16
New cuda time: 97.7238540649414
New cuda time without quantization: 172.88970947265625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 172.95819091796875
New cuda time without quantization: 77.95674896240234
torch.Size([524288, 768]) torch.float16
New cuda time: 78.0892333984375
New cuda time without quantization: 107.2939682006836
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.36724853515625
New cuda time without quantization: 97.93153381347656
torch.Size([524288, 768]) torch.float16
New cuda time: 97.99585723876953
New cuda time without quantization: 214.96041870117188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 215.05209350585938
New cuda time without quantization: 97.44193267822266
torch.Size([524288, 768]) torch.float16
New cuda time: 97.5020980834961
New cuda time without quantization: 92.4788818359375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 92.82479858398438
New cuda time without quantization: 99.2286605834961
torch.Size([524288, 768]) torch.float16
New cuda time: 99.36354064941406
New cuda time without quantization: 122.43482208251953
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 122.55882263183594
New cuda time without quantization: 97.72625732421875
torch.Size([524288, 768]) torch.float16
New cuda time: 97.80545806884766
New cuda time without quantization: 110.77430725097656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.92166137695312
New cuda time without quantization: 106.4627685546875
torch.Size([524288, 768]) torch.float16
New cuda time: 106.77365112304688
New cuda time without quantization: 107.59156799316406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.66372680664062
New cuda time without quantization: 106.49269104003906
torch.Size([524288, 768]) torch.float16
New cuda time: 106.61956787109375
New cuda time without quantization: 80.30892181396484
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 80.4917984008789
New cuda time without quantization: 99.04258728027344
torch.Size([524288, 768]) torch.float16
New cuda time: 99.10978698730469
New cuda time without quantization: 112.77287292480469
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.84791564941406
New cuda time without quantization: 59.23956298828125
torch.Size([524288, 768]) torch.float16
New cuda time: 59.39444351196289
New cuda time without quantization: 110.70182037353516
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.77318572998047
New cuda time without quantization: 98.2497787475586
torch.Size([524288, 768]) torch.float16
New cuda time: 98.33345794677734
New cuda time without quantization: 150.0123748779297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 150.07861328125
New cuda time without quantization: 102.02098846435547
torch.Size([524288, 768]) torch.float16
New cuda time: 102.08419036865234
New cuda time without quantization: 97.56001281738281
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 97.64961242675781
New cuda time without quantization: 100.04291534423828
torch.Size([524288, 768]) torch.float16
New cuda time: 100.10099029541016
New cuda time without quantization: 118.72793579101562
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.89513397216797
New cuda time without quantization: 96.0848159790039
torch.Size([524288, 768]) torch.float16
New cuda time: 96.19249725341797
New cuda time without quantization: 95.9572982788086
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 96.95045471191406
New cuda time without quantization: 107.59994506835938
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.73562622070312
New cuda time without quantization: 106.47513580322266
torch.Size([524288, 768]) torch.float16
New cuda time: 106.56233978271484
New cuda time without quantization: 211.3384246826172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 211.49618530273438
New cuda time without quantization: 89.24371337890625
torch.Size([524288, 768]) torch.float16
New cuda time: 89.3097915649414
New cuda time without quantization: 136.19972229003906
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 136.3821258544922
New cuda time without quantization: 98.68150329589844
torch.Size([524288, 768]) torch.float16
New cuda time: 98.74774169921875
New cuda time without quantization: 217.38308715820312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 217.5587615966797
New cuda time without quantization: 189.17642211914062
torch.Size([524288, 768]) torch.float16
New cuda time: 189.3501739501953
New cuda time without quantization: 104.69416809082031
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 104.7999267578125
New cuda time without quantization: 99.5856704711914
torch.Size([524288, 768]) torch.float16
New cuda time: 99.64598846435547
New cuda time without quantization: 110.61515045166016
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.737548828125
New cuda time without quantization: 102.65576171875
torch.Size([524288, 768]) torch.float16
New cuda time: 102.71800231933594
New cuda time without quantization: 106.71785736083984
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.86329650878906
New cuda time without quantization: 176.6938018798828
torch.Size([524288, 768]) torch.float16
New cuda time: 176.8115692138672
New cuda time without quantization: 121.60320281982422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.67263793945312
New cuda time without quantization: 100.94904327392578
torch.Size([524288, 768]) torch.float16
New cuda time: 101.03975677490234
New cuda time without quantization: 78.99407196044922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 79.1044692993164
New cuda time without quantization: 140.20230102539062
torch.Size([524288, 768]) torch.float16
New cuda time: 140.2981414794922
New cuda time without quantization: 230.93531799316406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 231.00970458984375
New cuda time without quantization: 98.47350311279297
torch.Size([524288, 768]) torch.float16
New cuda time: 98.53046417236328
New cuda time without quantization: 145.7348175048828
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 145.81689453125
New cuda time without quantization: 76.16893768310547
torch.Size([524288, 768]) torch.float16
New cuda time: 76.24429321289062
New cuda time without quantization: 133.45877075195312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 133.70724487304688
New cuda time without quantization: 182.87208557128906
torch.Size([524288, 768]) torch.float16
New cuda time: 182.96888732910156
New cuda time without quantization: 99.45510864257812
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.65351104736328
New cuda time without quantization: 113.41900634765625
torch.Size([524288, 768]) torch.float16
New cuda time: 113.55516815185547
New cuda time without quantization: 99.34583282470703
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.43383026123047
New cuda time without quantization: 106.75018310546875
torch.Size([524288, 768]) torch.float16
New cuda time: 106.84970092773438
New cuda time without quantization: 100.03414916992188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 100.19126892089844
New cuda time without quantization: 95.46357727050781
torch.Size([524288, 768]) torch.float16
New cuda time: 95.71829223632812
New cuda time without quantization: 120.43487548828125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 120.62559509277344
New cuda time without quantization: 104.93209838867188
torch.Size([524288, 768]) torch.float16
New cuda time: 105.15113830566406
New cuda time without quantization: 101.33048248291016
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 101.43112182617188
New cuda time without quantization: 142.40647888183594
torch.Size([524288, 768]) torch.float16
New cuda time: 142.57144165039062
New cuda time without quantization: 83.16992950439453
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 83.32321166992188
New cuda time without quantization: 106.67050170898438
torch.Size([524288, 768]) torch.float16
New cuda time: 106.73994445800781
New cuda time without quantization: 172.32676696777344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 172.55252075195312
New cuda time without quantization: 99.801513671875
torch.Size([524288, 768]) torch.float16
New cuda time: 99.90023040771484
New cuda time without quantization: 106.9202651977539
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.07930755615234
New cuda time without quantization: 99.80663299560547
torch.Size([524288, 768]) torch.float16
New cuda time: 99.90839385986328
New cuda time without quantization: 222.2800750732422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 222.37176513671875
New cuda time without quantization: 96.52454376220703
torch.Size([524288, 768]) torch.float16
New cuda time: 96.6239013671875
New cuda time without quantization: 118.24079132080078
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.34767150878906
New cuda time without quantization: 83.02064514160156
torch.Size([524288, 768]) torch.float16
New cuda time: 83.0889663696289
New cuda time without quantization: 101.61367797851562
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 101.68071746826172
New cuda time without quantization: 116.29598236083984
torch.Size([524288, 768]) torch.float16
New cuda time: 116.36046600341797
New cuda time without quantization: 112.8884506225586
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.95372772216797
New cuda time without quantization: 97.7952651977539
torch.Size([524288, 768]) torch.float16
New cuda time: 97.88214111328125
New cuda time without quantization: 95.30597686767578
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 95.3912582397461
New cuda time without quantization: 107.06938171386719
torch.Size([524288, 768]) torch.float16
New cuda time: 107.17994689941406
New cuda time without quantization: 100.26888275146484
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 100.37095642089844
New cuda time without quantization: 84.90289306640625
torch.Size([524288, 768]) torch.float16
New cuda time: 85.0020980834961
New cuda time without quantization: 98.91638946533203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.01863098144531
New cuda time without quantization: 164.8854522705078
torch.Size([524288, 768]) torch.float16
New cuda time: 165.08786010742188
New cuda time without quantization: 104.81977844238281
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.02681732177734
New cuda time without quantization: 91.53253173828125
torch.Size([524288, 768]) torch.float16
New cuda time: 91.61557006835938
New cuda time without quantization: 153.5100555419922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 153.71388244628906
New cuda time without quantization: 99.02806854248047
torch.Size([524288, 768]) torch.float16
New cuda time: 99.10343170166016
New cuda time without quantization: 118.24207305908203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.31119537353516
New cuda time without quantization: 99.04871368408203
torch.Size([524288, 768]) torch.float16
New cuda time: 99.11798858642578
New cuda time without quantization: 96.9637451171875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 97.03142547607422
New cuda time without quantization: 118.20943450927734
torch.Size([524288, 768]) torch.float16
New cuda time: 118.30799102783203
New cuda time without quantization: 99.2184829711914
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 97.07428741455078
New cuda time without quantization: 112.84529113769531
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.01953125
New cuda time without quantization: 101.37364196777344
torch.Size([524288, 768]) torch.float16
New cuda time: 101.48116302490234
New cuda time without quantization: 215.19732666015625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 215.32196044921875
New cuda time without quantization: 92.94438171386719
torch.Size([524288, 768]) torch.float16
New cuda time: 93.00886535644531
New cuda time without quantization: 124.25373840332031
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.35149383544922
New cuda time without quantization: 100.16069030761719
torch.Size([524288, 768]) torch.float16
New cuda time: 100.22355651855469
New cuda time without quantization: 213.42196655273438
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 213.69940185546875
New cuda time without quantization: 190.15130615234375
torch.Size([524288, 768]) torch.float16
New cuda time: 190.2727508544922
New cuda time without quantization: 93.26294708251953
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 93.36630249023438
New cuda time without quantization: 99.06804656982422
torch.Size([524288, 768]) torch.float16
New cuda time: 99.16260528564453
New cuda time without quantization: 98.17524719238281
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 98.31108856201172
New cuda time without quantization: 103.99043273925781
torch.Size([524288, 768]) torch.float16
New cuda time: 104.1785888671875
New cuda time without quantization: 108.58802032470703
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.72897338867188
New cuda time without quantization: 177.3369598388672
torch.Size([524288, 768]) torch.float16
New cuda time: 177.48365783691406
New cuda time without quantization: 128.17149353027344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 128.30557250976562
New cuda time: 103.27373504638672
New cuda time without quantization: 112.38129425048828
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.44833374023438
New cuda time without quantization: 101.05884552001953
torch.Size([524288, 768]) torch.float16
New cuda time: 101.1246109008789
New cuda time without quantization: 109.59920501708984
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.66816711425781
New cuda time without quantization: 222.56483459472656
torch.Size([524288, 768]) torch.float16
New cuda time: 222.75634765625
New cuda time without quantization: 111.96977233886719
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.06977844238281
New cuda time without quantization: 99.28379821777344
torch.Size([524288, 768]) torch.float16
New cuda time: 99.35436248779297
New cuda time without quantization: 221.8667449951172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 221.9456329345703
New cuda time without quantization: 98.27706909179688
New cuda time without quantization: 98.74436950683594
torch.Size([524288, 768]) torch.float16
New cuda time: 98.8341293334961
New cuda time without quantization: 86.06887817382812
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 86.160400390625
New cuda time without quantization: 120.48287200927734
torch.Size([524288, 768]) torch.float16
New cuda time: 120.57310485839844
New cuda time without quantization: 234.17152404785156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 234.26800537109375
New cuda time without quantization: 98.3763656616211
torch.Size([524288, 768]) torch.float16
New cuda time: 98.50100708007812
New cuda time without quantization: 144.30392456054688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 144.373046875
New cuda time without quantization: 80.71561431884766
torch.Size([524288, 768]) torch.float16
New cuda time: 80.78409576416016
New cuda time without quantization: 140.51528930664062
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([524288, 768]) torch.float16
New cuda time: 98.5196304321289
New cuda time without quantization: 200.5215301513672
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 200.65625
New cuda time without quantization: 99.67372131347656
torch.Size([524288, 768]) torch.float16
New cuda time: 99.74620056152344
New cuda time without quantization: 110.06945037841797
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.2022476196289
New cuda time without quantization: 98.64747619628906
torch.Size([524288, 768]) torch.float16
New cuda time: 98.75196075439453
New cuda time without quantization: 97.67483520507812
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 97.90971374511719
New cuda time without quantization: 173.94253540039062
torch.Size([524288, 768]) torch.float16
New cuda time: 174.08444213867188
New cuda time without quantization: 130.0122528076172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 130.09417724609375
New cuda time: 140.68666076660156
New cuda time without quantization: 197.52281188964844
torch.Size([524288, 768]) torch.float16
New cuda time: 197.75369262695312
New cuda time without quantization: 107.6699447631836
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.85394287109375
New cuda time without quantization: 110.0798568725586
torch.Size([524288, 768]) torch.float16
New cuda time: 110.21985626220703
New cuda time without quantization: 105.58866882324219
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.68611145019531
New cuda time without quantization: 99.79045104980469
torch.Size([524288, 768]) torch.float16
New cuda time: 99.88724517822266
New cuda time without quantization: 112.77969360351562
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.00576782226562
New cuda time without quantization: 94.0013427734375
torch.Size([524288, 768]) torch.float16
New cuda time: 94.15878295898438
New cuda time without quantization: 123.23454284667969
New cuda time without quantization: 98.78795623779297
torch.Size([524288, 768]) torch.float16
New cuda time: 98.8585205078125
New cuda time without quantization: 105.6260757446289
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.80223083496094
New cuda time without quantization: 99.0223617553711
torch.Size([524288, 768]) torch.float16
New cuda time: 99.09275817871094
New cuda time without quantization: 104.71326446533203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 104.80206298828125
New cuda time without quantization: 224.1392364501953
torch.Size([524288, 768]) torch.float16
New cuda time: 224.2565155029297
New cuda time without quantization: 145.51904296875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 145.61920166015625
New cuda time without quantization: 112.8800277709961
torch.Size([524288, 768]) torch.float16
New cuda time: 112.94498443603516
New cuda time without quantization: 103.44446563720703
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 123.32974243164062
New cuda time: 103.51150512695312
New cuda time without quantization: 106.71471405029297
torch.Size([524288, 768]) torch.float16
New cuda time: 106.77822875976562
New cuda time without quantization: 219.4446563720703
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 219.5341033935547
New cuda time without quantization: 113.6558609008789
torch.Size([524288, 768]) torch.float16
New cuda time: 113.76658630371094
New cuda time without quantization: 105.89871215820312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.96910858154297
New cuda time without quantization: 103.47758483886719
torch.Size([524288, 768]) torch.float16
New cuda time: 103.54462432861328
New cuda time without quantization: 108.3569564819336
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.42415618896484
New cuda time without quantization: 108.19840240478516
torch.Size([524288, 768]) torch.float16
New cuda time: 108.43392181396484
New cuda time without quantization: 107.18144226074219
New cuda time without quantization: 93.44454193115234
torch.Size([524288, 768]) torch.float16
New cuda time: 93.53270721435547
New cuda time without quantization: 103.38115692138672
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.48771667480469
New cuda time without quantization: 147.09591674804688
torch.Size([524288, 768]) torch.float16
New cuda time: 147.1607208251953
New cuda time without quantization: 96.13189697265625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 96.31973266601562
New cuda time without quantization: 111.34913635253906
torch.Size([524288, 768]) torch.float16
New cuda time: 111.41841888427734
New cuda time without quantization: 172.6798553466797
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 172.7440185546875
New cuda time without quantization: 100.05268859863281
torch.Size([524288, 768]) torch.float16
New cuda time: 100.12820434570312
New cuda time without quantization: 109.11442565917969
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.25007629394531
New cuda time: 109.18338775634766
New cuda time without quantization: 97.70773315429688
torch.Size([524288, 768]) torch.float16
New cuda time: 97.77045440673828
New cuda time without quantization: 125.04750061035156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 125.11166381835938
New cuda time without quantization: 213.9189453125
torch.Size([524288, 768]) torch.float16
New cuda time: 214.01925659179688
New cuda time without quantization: 116.27424621582031
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.41248321533203
New cuda time without quantization: 99.25973510742188
torch.Size([524288, 768]) torch.float16
New cuda time: 99.4451675415039
New cuda time without quantization: 101.66324615478516
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 101.76213073730469
New cuda time without quantization: 115.48320770263672
torch.Size([524288, 768]) torch.float16
New cuda time: 115.56016540527344
New cuda time without quantization: 107.85699462890625
New cuda time without quantization: 106.05679321289062
torch.Size([524288, 768]) torch.float16
New cuda time: 106.13311004638672
New cuda time without quantization: 110.0817642211914
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.14881134033203
New cuda time without quantization: 97.10987091064453
torch.Size([524288, 768]) torch.float16
New cuda time: 97.24443054199219
New cuda time without quantization: 161.5890350341797
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 161.67880249023438
New cuda time without quantization: 97.7868423461914
torch.Size([524288, 768]) torch.float16
New cuda time: 97.85484313964844
New cuda time without quantization: 171.7266845703125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 171.79708862304688
New cuda time without quantization: 100.73596954345703
torch.Size([524288, 768]) torch.float16
New cuda time: 100.82268524169922
New cuda time without quantization: 98.28588104248047
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.92915344238281
New cuda time without quantization: 91.57334899902344
torch.Size([524288, 768]) torch.float16
New cuda time: 91.68359375
New cuda time without quantization: 111.86001586914062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.1070556640625
New cuda time without quantization: 90.86296081542969
torch.Size([524288, 768]) torch.float16
New cuda time: 91.00935363769531
New cuda time without quantization: 103.29779815673828
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.38147735595703
New cuda time without quantization: 98.3557357788086
torch.Size([524288, 768]) torch.float16
New cuda time: 98.44037628173828
New cuda time without quantization: 106.6398696899414
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.74018859863281
New cuda time without quantization: 153.6194305419922
torch.Size([524288, 768]) torch.float16
New cuda time: 153.81765747070312
New cuda time: 98.38700103759766
New cuda time without quantization: 99.6457290649414
torch.Size([524288, 768]) torch.float16
New cuda time: 99.70796966552734
New cuda time without quantization: 123.04935455322266
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 123.11751556396484
New cuda time without quantization: 213.5054473876953
torch.Size([524288, 768]) torch.float16
New cuda time: 213.57504272460938
New cuda time without quantization: 106.59744262695312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.70735931396484
New cuda time without quantization: 99.53900909423828
torch.Size([524288, 768]) torch.float16
New cuda time: 99.65980529785156
New cuda time without quantization: 121.16454315185547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.29510498046875
New cuda time without quantization: 99.795166015625
torch.Size([524288, 768]) torch.float16
New cuda time: 99.86428833007812
New cuda time without quantization: 110.41681671142578
New cuda time without quantization: 105.46147918701172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.62850952148438
New cuda time without quantization: 97.29878234863281
torch.Size([524288, 768]) torch.float16
New cuda time: 97.38997650146484
New cuda time without quantization: 147.49496459960938
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 147.59751892089844
New cuda time without quantization: 98.88053894042969
torch.Size([524288, 768]) torch.float16
New cuda time: 98.9678955078125
New cuda time without quantization: 112.80753326416016
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.8948974609375
New cuda time without quantization: 99.91333770751953
torch.Size([524288, 768]) torch.float16
New cuda time: 99.98628997802734
New cuda time without quantization: 95.98518371582031
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 96.11510467529297
New cuda time without quantization: 115.359375
torch.Size([524288, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.51713562011719
New cuda time without quantization: 99.93484497070312
torch.Size([524288, 768]) torch.float16
New cuda time: 100.0321273803711
New cuda time without quantization: 111.90530395507812
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.97522735595703
New cuda time without quantization: 107.07071685791016
torch.Size([524288, 768]) torch.float16
New cuda time: 107.18447875976562
New cuda time without quantization: 118.28772735595703
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.35684967041016
New cuda time without quantization: 102.97598266601562
torch.Size([524288, 768]) torch.float16
New cuda time: 103.06814575195312
New cuda time without quantization: 112.31346130371094
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.38018035888672
New cuda time without quantization: 164.8856964111328
torch.Size([524288, 768]) torch.float16
New cuda time: 164.9490509033203
New cuda time: 115.43248748779297
New cuda time without quantization: 93.8355941772461
New cuda time without quantization: 113.4947509765625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.55811309814453
New cuda time without quantization: 139.55262756347656
torch.Size([524288, 768]) torch.float16
New cuda time: 139.6588592529297
New cuda time without quantization: 105.95823669433594
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.03231811523438
New cuda time without quantization: 98.93436431884766
torch.Size([524288, 768]) torch.float16
New cuda time: 99.00701141357422
New cuda time without quantization: 128.0463409423828
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 128.11865234375
New cuda time without quantization: 97.36219787597656
torch.Size([524288, 768]) torch.float16
New cuda time: 97.46156311035156
New cuda time without quantization: 120.53014373779297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 120.73014068603516
New cuda time without quantization: 100.5711669921875
torch.Size([524288, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 100.6694107055664
New cuda time without quantization: 134.9503631591797
New cuda time: 102.19379425048828
New cuda time without quantization: 107.83699798583984
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.91075897216797
New cuda time without quantization: 111.48693084716797
torch.Size([524288, 768]) torch.float16
New cuda time: 111.6043701171875
New cuda time without quantization: 209.433349609375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 209.50965881347656
New cuda time without quantization: 96.28001403808594
torch.Size([524288, 768]) torch.float16
New cuda time: 96.34257507324219
New cuda time without quantization: 133.8028106689453
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 133.86984252929688
New cuda time without quantization: 100.26514434814453
torch.Size([524288, 768]) torch.float16
New cuda time: 100.32594299316406
New cuda time without quantization: 169.34591674804688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 169.42063903808594
New cuda time without quantization: 189.30307006835938
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([524288, 768]) torch.float16
New cuda time: 189.4053192138672
New cuda time without quantization: 103.223388671875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.28659057617188
New cuda time without quantization: 102.9606704711914
torch.Size([524288, 768]) torch.float16
New cuda time: 103.0241928100586
New cuda time without quantization: 75.5015869140625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 75.6865463256836
New cuda time without quantization: 99.01426696777344
torch.Size([524288, 768]) torch.float16
New cuda time: 99.07522583007812
New cuda time without quantization: 111.21125030517578
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.3766860961914
New cuda time without quantization: 175.30528259277344
torch.Size([524288, 768]) torch.float16
New cuda time: 175.41632080078125
New cuda time without quantization: 64.77755737304688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 65.19403839111328
New cuda time: 99.71290588378906
New cuda time without quantization: 116.072998046875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.1322021484375
New cuda time without quantization: 100.86347198486328
torch.Size([524288, 768]) torch.float16
New cuda time: 100.95275115966797
New cuda time without quantization: 219.81777954101562
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 219.8897705078125
New cuda time without quantization: 112.08833312988281
torch.Size([524288, 768]) torch.float16
New cuda time: 112.14705657958984
New cuda time without quantization: 112.86018371582031
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.92082214355469
New cuda time without quantization: 99.31722259521484
torch.Size([524288, 768]) torch.float16
New cuda time: 99.38026428222656
New cuda time without quantization: 221.5478515625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 221.61473083496094
New cuda time without quantization: 190.89984130859375
New cuda time without quantization: 97.53890228271484
torch.Size([524288, 768]) torch.float16
New cuda time: 97.69122314453125
New cuda time without quantization: 82.2532730102539
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 82.64191436767578
New cuda time without quantization: 99.0710678100586
torch.Size([524288, 768]) torch.float16
New cuda time: 99.14066314697266
New cuda time without quantization: 189.5227508544922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 189.75363159179688
New cuda time without quantization: 141.3810577392578
torch.Size([524288, 768]) torch.float16
New cuda time: 141.5240936279297
New cuda time without quantization: 102.45875549316406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 102.53187561035156
New cuda time without quantization: 113.17701721191406
torch.Size([524288, 768]) torch.float16
New cuda time: 113.27349853515625
New cuda time without quantization: 102.5947494506836
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([524288, 768]) torch.float16
New cuda time: 190.97103881835938
New cuda time without quantization: 108.45152282714844
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.51344299316406
New cuda time without quantization: 100.49883270263672
torch.Size([524288, 768]) torch.float16
New cuda time: 100.56394958496094
New cuda time without quantization: 110.071044921875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.194091796875
New cuda time without quantization: 98.8066635131836
torch.Size([524288, 768]) torch.float16
New cuda time: 98.86442565917969
New cuda time without quantization: 109.64480590820312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.75328826904297
New cuda time without quantization: 61.907562255859375
torch.Size([524288, 768]) torch.float16
New cuda time: 61.99140548706055
New cuda time without quantization: 127.94731140136719
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 128.0706787109375
New cuda time: 102.75667572021484
New cuda time without quantization: 208.39158630371094
torch.Size([524288, 768]) torch.float16
New cuda time: 208.5389404296875
New cuda time without quantization: 102.96099090576172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.03539276123047
New cuda time without quantization: 80.58847045898438
torch.Size([524288, 768]) torch.float16
New cuda time: 80.71327209472656
New cuda time without quantization: 112.52581024169922
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.6029281616211
New cuda time without quantization: 63.25963592529297
torch.Size([524288, 768]) torch.float16
New cuda time: 63.346195220947266
New cuda time without quantization: 106.82611846923828
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.89572143554688
New cuda time without quantization: 97.17121887207031
torch.Size([524288, 768]) torch.float16
New cuda time: 97.31777954101562
New cuda time without quantization: 129.16871643066406
New cuda time without quantization: 98.38473510742188
torch.Size([524288, 768]) torch.float16
New cuda time: 98.44585418701172
New cuda time without quantization: 115.6897964477539
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.81220245361328
New cuda time without quantization: 99.38810729980469
torch.Size([524288, 768]) torch.float16
New cuda time: 99.45770263671875
New cuda time without quantization: 230.84840393066406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 230.92599487304688
New cuda time without quantization: 97.74217224121094
torch.Size([524288, 768]) torch.float16
New cuda time: 97.8076171875
New cuda time without quantization: 145.68374633789062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 145.7464599609375
New cuda time without quantization: 114.06130981445312
torch.Size([524288, 768]) torch.float16
New cuda time: 114.12051391601562
New cuda time without quantization: 102.8966064453125
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 129.23495483398438
New cuda time: 103.02349090576172
New cuda time without quantization: 208.48187255859375
torch.Size([524288, 768]) torch.float16
New cuda time: 208.5821990966797
New cuda time without quantization: 117.5008544921875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.58309936523438
New cuda time without quantization: 114.01091003417969
torch.Size([524288, 768]) torch.float16
New cuda time: 114.09747314453125
New cuda time without quantization: 105.81966400146484
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.93214416503906
New cuda time without quantization: 103.37932586669922
torch.Size([524288, 768]) torch.float16
New cuda time: 103.44316864013672
New cuda time without quantization: 116.9757308959961
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.16468811035156
New cuda time without quantization: 109.95408630371094
torch.Size([524288, 768]) torch.float16
New cuda time: 110.02465057373047
New cuda time without quantization: 107.17391204833984
New cuda time without quantization: 89.37024688720703
torch.Size([524288, 768]) torch.float16
New cuda time: 89.45360565185547
New cuda time without quantization: 108.86387634277344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.04084014892578
New cuda time without quantization: 128.4413604736328
torch.Size([524288, 768]) torch.float16
New cuda time: 128.5170440673828
New cuda time without quantization: 108.38179779052734
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.47283935546875
New cuda time without quantization: 97.37954711914062
torch.Size([524288, 768]) torch.float16
New cuda time: 97.49170684814453
New cuda time without quantization: 172.23855590820312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 172.32736206054688
New cuda time without quantization: 100.15890502929688
torch.Size([524288, 768]) torch.float16
New cuda time: 100.2670669555664
New cuda time without quantization: 82.32159423828125
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.23711395263672
New cuda time: 82.4156723022461
New cuda time without quantization: 97.68770599365234
torch.Size([524288, 768]) torch.float16
New cuda time: 97.75506591796875
New cuda time without quantization: 214.4077606201172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 214.50120544433594
New cuda time without quantization: 84.75599670410156
torch.Size([524288, 768]) torch.float16
New cuda time: 84.88912200927734
New cuda time without quantization: 117.15765380859375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.22533416748047
New cuda time without quantization: 99.52098083496094
torch.Size([524288, 768]) torch.float16
New cuda time: 99.7219467163086
New cuda time without quantization: 101.21250915527344
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 101.27779388427734
New cuda time without quantization: 117.48406219482422
torch.Size([524288, 768]) torch.float16
New cuda time: 117.6013412475586
New cuda time without quantization: 110.52468872070312
New cuda time without quantization: 104.5161361694336
torch.Size([524288, 768]) torch.float16
New cuda time: 104.57693481445312
New cuda time without quantization: 111.70049285888672
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.76433563232422
New cuda time without quantization: 84.92498779296875
torch.Size([524288, 768]) torch.float16
New cuda time: 85.08354187011719
New cuda time without quantization: 173.3648681640625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 173.43399047851562
New cuda time without quantization: 98.22217559814453
torch.Size([524288, 768]) torch.float16
New cuda time: 98.3154525756836
New cuda time without quantization: 171.4275665283203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 171.49525451660156
New cuda time without quantization: 102.78044891357422
torch.Size([524288, 768]) torch.float16
New cuda time: 103.05900573730469
New cuda time without quantization: 106.9371109008789
torch.Size([8, 64, 1024, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.58708953857422
New cuda time without quantization: 100.5808334350586
torch.Size([524288, 768]) torch.float16
New cuda time: 100.6517105102539
New cuda time without quantization: 113.36548614501953
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.42916870117188
New cuda time without quantization: 106.52052307128906
torch.Size([524288, 768]) torch.float16
New cuda time: 106.63043975830078
New cuda time without quantization: 119.065185546875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.12678527832031
New cuda time without quantization: 101.11923217773438
torch.Size([524288, 768]) torch.float16
New cuda time: 101.18370819091797
New cuda time without quantization: 113.09716796875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.1619644165039
New cuda time without quantization: 164.7047882080078
torch.Size([524288, 768]) torch.float16
New cuda time: 164.78622436523438
New cuda time: 107.00623321533203
New cuda time without quantization: 97.97545623779297
torch.Size([524288, 768]) torch.float16
New cuda time: 98.03641510009766
New cuda time without quantization: 124.58617401123047
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.65081787109375
New cuda time without quantization: 214.38189697265625
torch.Size([524288, 768]) torch.float16
New cuda time: 214.46702575683594
New cuda time without quantization: 115.88884735107422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.95556640625
New cuda time without quantization: 99.62651062011719
torch.Size([524288, 768]) torch.float16
New cuda time: 99.7250747680664
New cuda time without quantization: 121.09031677246094
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.15512084960938
New cuda time without quantization: 100.1221923828125
torch.Size([524288, 768]) torch.float16
New cuda time: 100.18714904785156
New cuda time without quantization: 101.7986831665039
New cuda time without quantization: 110.856689453125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.91957092285156
New cuda time without quantization: 143.13050842285156
torch.Size([524288, 768]) torch.float16
New cuda time: 143.23899841308594
New cuda time without quantization: 105.67843627929688
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.75988006591797
New cuda time without quantization: 100.55379486083984
torch.Size([524288, 768]) torch.float16
New cuda time: 100.61443328857422
New cuda time without quantization: 86.50736236572266
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 86.59600067138672
New cuda time without quantization: 99.81619262695312
torch.Size([524288, 768]) torch.float16
New cuda time: 99.90579223632812
New cuda time without quantization: 69.33516693115234
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 69.44588470458984
New cuda time without quantization: 96.52626037597656
torch.Size([524288, 768]) torch.float16
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 101.96299743652344
New cuda time without quantization: 101.76715850830078
torch.Size([524288, 768]) torch.float16
New cuda time: 101.85468292236328
New cuda time without quantization: 112.19506072998047
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.26034545898438
New cuda time without quantization: 107.0633544921875
torch.Size([524288, 768]) torch.float16
New cuda time: 107.1683120727539
New cuda time without quantization: 121.10791778564453
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.19367980957031
New cuda time without quantization: 96.62665557861328
torch.Size([524288, 768]) torch.float16
New cuda time: 96.68873596191406
New cuda time without quantization: 114.4669189453125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.52803802490234
New cuda time without quantization: 166.22483825683594
torch.Size([524288, 768]) torch.float16
New cuda time: 166.2875518798828
New cuda time: 96.61602020263672
New cuda time without quantization: 140.8644256591797
New cuda time without quantization: 113.39891052246094
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.46371459960938
New cuda time without quantization: 130.8663787841797
torch.Size([524288, 768]) torch.float16
New cuda time: 131.09005737304688
New cuda time without quantization: 114.3923568725586
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.46643829345703
New cuda time without quantization: 99.17691040039062
torch.Size([524288, 768]) torch.float16
New cuda time: 99.24635314941406
New cuda time without quantization: 127.84748077392578
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 127.91132354736328
New cuda time without quantization: 99.79035186767578
torch.Size([524288, 768]) torch.float16
New cuda time: 100.00682830810547
New cuda time without quantization: 117.89509582519531
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.96565246582031
New cuda time without quantization: 100.69339752197266
torch.Size([524288, 768]) torch.float16
New cuda time: 100.80988311767578
New cuda time without quantization: 135.20640563964844
New cuda time: 100.68685150146484
New cuda time without quantization: 115.87316131591797
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.93636322021484
New cuda time without quantization: 104.13662719726562
torch.Size([524288, 768]) torch.float16
New cuda time: 104.20030212402344
New cuda time without quantization: 104.80927276611328
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 104.87358856201172
New cuda time without quantization: 220.84915161132812
torch.Size([524288, 768]) torch.float16
New cuda time: 220.92147827148438
New cuda time without quantization: 115.8010025024414
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.88020324707031
New cuda time without quantization: 99.42892456054688
torch.Size([524288, 768]) torch.float16
New cuda time: 99.53788757324219
New cuda time without quantization: 221.61666870117188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 221.84947204589844
New cuda time without quantization: 88.1856689453125
torch.Size([524288, 768]) torch.float16
New cuda time: 88.28375244140625
New cuda time without quantization: 209.81246948242188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 209.8951873779297
New cuda time without quantization: 100.97933959960938
torch.Size([524288, 768]) torch.float16
New cuda time: 101.04573822021484
New cuda time without quantization: 109.8902587890625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.01345825195312
New cuda time without quantization: 98.82267761230469
torch.Size([524288, 768]) torch.float16
New cuda time: 98.88700103759766
New cuda time without quantization: 108.87265014648438
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.99745178222656
New cuda time without quantization: 177.14735412597656
torch.Size([524288, 768]) torch.float16
New cuda time: 177.3654327392578
New cuda time without quantization: 121.08966064453125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.1562271118164
New cuda time without quantization: 105.28063201904297
torch.Size([524288, 768]) torch.float16
New cuda time: 105.34495544433594
New cuda time without quantization: 114.94723510742188
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.07411193847656
New cuda time without quantization: 99.66860961914062
torch.Size([524288, 768]) torch.float16
New cuda time: 99.73804473876953
New cuda time without quantization: 85.87702178955078
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 86.23334503173828
New cuda time without quantization: 284.94158935546875
torch.Size([524288, 768]) torch.float16
New cuda time: 285.1822509765625
New cuda time without quantization: 100.81629943847656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 100.8841323852539
New cuda time without quantization: 112.17586517333984
torch.Size([524288, 768]) torch.float16
New cuda time: 112.24018096923828
New cuda time without quantization: 120.8504638671875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 120.91270446777344
New cuda time without quantization: 91.84185791015625
torch.Size([524288, 768]) torch.float16
New cuda time: 91.93465423583984
New cuda time without quantization: 222.5806884765625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 222.64852905273438
New cuda time without quantization: 92.84265899658203
torch.Size([524288, 768]) torch.float16
New cuda time: 92.94873809814453
New cuda time without quantization: 117.32389068603516
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 117.52852630615234
New cuda time without quantization: 100.43309020996094
torch.Size([524288, 768]) torch.float16
New cuda time: 100.50204467773438
New cuda time without quantization: 111.80242156982422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.87186431884766
New cuda time without quantization: 116.93172454833984
torch.Size([524288, 768]) torch.float16
New cuda time: 117.03717041015625
New cuda time without quantization: 108.92288970947266
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.05472564697266
New cuda time: 99.6005859375
New cuda time without quantization: 110.42430877685547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.49166870117188
New cuda time without quantization: 109.43534088134766
torch.Size([524288, 768]) torch.float16
New cuda time: 109.52110290527344
New cuda time without quantization: 103.8362808227539
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 103.898681640625
New cuda time without quantization: 221.89341735839844
torch.Size([524288, 768]) torch.float16
New cuda time: 221.95726013183594
New cuda time without quantization: 114.6316909790039
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 114.78305053710938
New cuda time without quantization: 99.2665023803711
torch.Size([524288, 768]) torch.float16
New cuda time: 99.32730102539062
New cuda time without quantization: 221.475341796875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 221.5910186767578
New cuda time without quantization: 85.69652557373047
torch.Size([524288, 768]) torch.float16
New cuda time: 85.7821273803711
New cuda time without quantization: 207.80984497070312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 207.97720336914062
New cuda time without quantization: 99.72970581054688
torch.Size([524288, 768]) torch.float16
New cuda time: 99.8101806640625
New cuda time without quantization: 111.64864349365234
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.76512145996094
New cuda time without quantization: 98.727783203125
torch.Size([524288, 768]) torch.float16
New cuda time: 98.7879409790039
New cuda time without quantization: 110.41663360595703
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.55839538574219
New cuda time without quantization: 171.9639434814453
torch.Size([524288, 768]) torch.float16
New cuda time: 172.04762268066406
New cuda time without quantization: 124.27700805664062
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 124.40100860595703
New cuda time without quantization: 104.25740814208984
torch.Size([524288, 768]) torch.float16
New cuda time: 104.32157135009766
New cuda time without quantization: 116.0139389038086
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.128173828125
New cuda time without quantization: 99.36714172363281
torch.Size([524288, 768]) torch.float16
New cuda time: 99.42826080322266
New cuda time without quantization: 85.77397155761719
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 85.88692474365234
New cuda time without quantization: 286.2047424316406
torch.Size([524288, 768]) torch.float16
New cuda time: 286.3236083984375
New cuda time without quantization: 100.46218872070312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 100.5233154296875
New cuda time without quantization: 112.68879699707031
torch.Size([524288, 768]) torch.float16
New cuda time: 112.75968170166016
New cuda time without quantization: 120.71204376220703
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 120.83251953125
New cuda time without quantization: 91.76151275634766
torch.Size([524288, 768]) torch.float16
New cuda time: 91.84647369384766
New cuda time without quantization: 220.16542053222656
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 220.2484588623047
New cuda time without quantization: 94.77928924560547
torch.Size([524288, 768]) torch.float16
New cuda time: 94.84040832519531
New cuda time without quantization: 118.99890899658203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.0574722290039
New cuda time without quantization: 100.38011169433594
torch.Size([524288, 768]) torch.float16
New cuda time: 100.46202850341797
New cuda time without quantization: 111.18608093261719
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.25552368164062
New cuda time without quantization: 117.66626739501953
torch.Size([524288, 768]) torch.float16
New cuda time: 117.72578430175781
New cuda time without quantization: 102.06220245361328
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 102.14827728271484
New cuda time without quantization: 103.86958312988281
torch.Size([524288, 768]) torch.float16
New cuda time: 103.94542694091797
New cuda time without quantization: 112.01970672607422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 112.10338592529297
New cuda time without quantization: 82.9302978515625
torch.Size([524288, 768]) torch.float16
New cuda time: 83.00773620605469
New cuda time without quantization: 171.47100830078125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 171.53981018066406
New cuda time without quantization: 101.78717803955078
torch.Size([524288, 768]) torch.float16
New cuda time: 101.88941955566406
New cuda time without quantization: 171.67852783203125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 171.757568359375
New cuda time without quantization: 100.58685302734375
torch.Size([524288, 768]) torch.float16
New cuda time: 100.66797637939453
New cuda time without quantization: 109.07249450683594
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.13713836669922
New cuda time without quantization: 99.71485137939453
torch.Size([524288, 768]) torch.float16
New cuda time: 99.77740478515625
New cuda time without quantization: 123.4503173828125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 123.660400390625
New cuda time without quantization: 210.0623779296875
torch.Size([524288, 768]) torch.float16
New cuda time: 210.13246154785156
New cuda time without quantization: 119.24901580810547
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.32469940185547
New cuda time without quantization: 99.51020812988281
torch.Size([524288, 768]) torch.float16
New cuda time: 99.57532501220703
New cuda time without quantization: 111.40258026123047
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.50674438476562
New cuda time without quantization: 100.84845733642578
torch.Size([524288, 768]) torch.float16
New cuda time: 100.92285919189453
New cuda time without quantization: 107.62577056884766
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.69937133789062
New cuda time without quantization: 105.63775634765625
torch.Size([524288, 768]) torch.float16
New cuda time: 105.7441635131836
New cuda time without quantization: 108.40065002441406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.46528625488281
New cuda time without quantization: 107.22256469726562
torch.Size([524288, 768]) torch.float16
New cuda time: 107.29600524902344
New cuda time without quantization: 118.34837341308594
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.4098129272461
New cuda time without quantization: 99.44493103027344
torch.Size([524288, 768]) torch.float16
New cuda time: 99.50556945800781
New cuda time without quantization: 115.85540771484375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 115.95317077636719
New cuda time without quantization: 173.3222198486328
torch.Size([524288, 768]) torch.float16
New cuda time: 173.38478088378906
New cuda time without quantization: 106.00800323486328
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 106.07279968261719
New cuda time without quantization: 130.86715698242188
torch.Size([524288, 768]) torch.float16
New cuda time: 130.93307495117188
New cuda time without quantization: 93.63610076904297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 93.72858428955078
New cuda time without quantization: 105.88368225097656
torch.Size([524288, 768]) torch.float16
New cuda time: 105.94560241699219
New cuda time without quantization: 121.3731918334961
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.44023132324219
New cuda time without quantization: 97.46891784667969
torch.Size([524288, 768]) torch.float16
New cuda time: 97.53147888183594
New cuda time without quantization: 102.1345443725586
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 102.33806610107422
New cuda time without quantization: 100.9505386352539
torch.Size([524288, 768]) torch.float16
New cuda time: 101.04829406738281
New cuda time without quantization: 103.08316040039062
torch.Size([524288, 768]) torch.float16
New cuda time: 103.14299774169922
New cuda time without quantization: 111.76207733154297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 111.82736206054688
New cuda time without quantization: 151.40834045410156
torch.Size([524288, 768]) torch.float16
New cuda time: 151.70928955078125
New cuda time without quantization: 102.92748260498047
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 102.98876190185547
New cuda time without quantization: 101.3487548828125
torch.Size([524288, 768]) torch.float16
New cuda time: 101.44459533691406
New cuda time without quantization: 171.54249572753906
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 171.65866088867188
New cuda time without quantization: 100.5716323852539
torch.Size([524288, 768]) torch.float16
New cuda time: 100.6612319946289
New cuda time without quantization: 108.7529525756836
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.815673828125
New cuda time without quantization: 99.54443359375
torch.Size([524288, 768]) torch.float16
New cuda time: 99.6031494140625
New cuda time without quantization: 238.99095153808594
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 239.07142639160156
New cuda time without quantization: 94.71192932128906
torch.Size([524288, 768]) torch.float16
New cuda time: 94.77481079101562
New cuda time without quantization: 119.20706939697266
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.2742691040039
New cuda time without quantization: 99.47418975830078
torch.Size([524288, 768]) torch.float16
New cuda time: 99.56619262695312
New cuda time without quantization: 121.04308319091797
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 121.1053237915039
New cuda time without quantization: 90.4391098022461
torch.Size([524288, 768]) torch.float16
New cuda time: 90.59046936035156
New cuda time without quantization: 108.1750259399414
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.24606323242188
New cuda time without quantization: 97.51626586914062
torch.Size([524288, 768]) torch.float16
New cuda time: 97.57514190673828
New cuda time without quantization: 116.0885009765625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.38194274902344
New cuda time without quantization: 106.7811050415039
torch.Size([524288, 768]) torch.float16
New cuda time: 106.871826171875
New cuda time without quantization: 117.97523498535156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.04691314697266
New cuda time without quantization: 101.66876220703125
torch.Size([524288, 768]) torch.float16
New cuda time: 101.82427978515625
New cuda time without quantization: 113.0488052368164
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.12128448486328
New cuda time without quantization: 172.4756317138672
torch.Size([524288, 768]) torch.float16
New cuda time: 172.53466796875
New cuda time without quantization: 105.22301483154297
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 105.35453796386719
New cuda time without quantization: 131.6236114501953
torch.Size([524288, 768]) torch.float16
New cuda time: 131.6912841796875
New cuda time without quantization: 113.35633087158203
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 113.41712951660156
New cuda time without quantization: 108.5772705078125
torch.Size([524288, 768]) torch.float16
New cuda time: 108.66094970703125
New cuda time without quantization: 118.2129898071289
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 118.27490997314453
New cuda time without quantization: 97.46986389160156
torch.Size([524288, 768]) torch.float16
New cuda time: 97.5332260131836
New cuda time without quantization: 119.99092102050781
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 120.26100158691406
New cuda time without quantization: 100.35931396484375
torch.Size([524288, 768]) torch.float16
New cuda time: 100.43978881835938
New cuda time without quantization: 135.84315490722656
New cuda time without quantization: 135.39613342285156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.4080810546875
New cuda time without quantization: 102.990966796875
torch.Size([524288, 768]) torch.float16
New cuda time: 103.05561828613281
New cuda time without quantization: 208.18914794921875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 208.25970458984375
New cuda time without quantization: 114.83485412597656
torch.Size([524288, 768]) torch.float16
New cuda time: 114.89453887939453
New cuda time without quantization: 110.2359619140625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.31420135498047
New cuda time without quantization: 102.23160552978516
torch.Size([524288, 768]) torch.float16
New cuda time: 102.3013687133789
New cuda time without quantization: 110.9012451171875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.97068786621094
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 141.09402465820312
New cuda time without quantization: 187.57522583007812
torch.Size([524288, 768]) torch.float16
New cuda time: 187.64627075195312
New cuda time without quantization: 99.83123016357422
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.9134750366211
New cuda time without quantization: 96.4957046508789
torch.Size([524288, 768]) torch.float16
New cuda time: 96.55602264404297
New cuda time without quantization: 110.25204467773438
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.31588745117188
New cuda time without quantization: 59.8044319152832
torch.Size([524288, 768]) torch.float16
New cuda time: 59.8879508972168
New cuda time without quantization: 110.7000503540039
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.7706069946289
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 135.9097137451172
New cuda time without quantization: 166.04808044433594
torch.Size([524288, 768]) torch.float16
New cuda time: 166.17703247070312
New cuda time without quantization: 119.69940185546875
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 119.76963806152344
New cuda time without quantization: 99.70410919189453
torch.Size([524288, 768]) torch.float16
New cuda time: 99.76459503173828
New cuda time without quantization: 108.37263488769531
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.5009536743164
New cuda time without quantization: 100.27195739746094
torch.Size([524288, 768]) torch.float16
New cuda time: 100.33148193359375
New cuda time without quantization: 110.4072036743164
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 110.46880340576172
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 93.9298324584961
New cuda time without quantization: 110.11011505126953
torch.Size([524288, 768]) torch.float16
New cuda time: 110.19202423095703
New cuda time without quantization: 206.90264892578125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 206.99562072753906
New cuda time without quantization: 110.97842407226562
torch.Size([524288, 768]) torch.float16
New cuda time: 111.05074310302734
New cuda time without quantization: 108.61891174316406
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 108.85826873779297
New cuda time without quantization: 102.90132904052734
torch.Size([524288, 768]) torch.float16
New cuda time: 103.14212799072266
New cuda time without quantization: 106.96147918701172
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.14466857910156
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 135.02012634277344
New cuda time without quantization: 170.28125
torch.Size([524288, 768]) torch.float16
New cuda time: 170.3492431640625
New cuda time without quantization: 116.80276489257812
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 116.91572570800781
New cuda time without quantization: 99.5006103515625
torch.Size([524288, 768]) torch.float16
New cuda time: 99.56716918945312
New cuda time without quantization: 107.32672119140625
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.39167785644531
New cuda time without quantization: 105.24271392822266
torch.Size([524288, 768]) torch.float16
New cuda time: 105.3073501586914
New cuda time without quantization: 107.35040283203125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.43231964111328
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
New cuda time: 96.02401733398438
New cuda time without quantization: 221.96908569335938
torch.Size([524288, 768]) torch.float16
New cuda time: 222.0543670654297
New cuda time without quantization: 95.71361541748047
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 95.77937316894531
New cuda time without quantization: 111.87271118164062
torch.Size([524288, 768]) torch.float16
New cuda time: 111.93719482421875
New cuda time without quantization: 109.32582092285156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.39494323730469
New cuda time without quantization: 102.978759765625
torch.Size([524288, 768]) torch.float16
New cuda time: 103.0411605834961
New cuda time without quantization: 87.64974212646484
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 87.73406219482422
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 135.5830078125
New cuda time without quantization: 187.56869506835938
torch.Size([524288, 768]) torch.float16
New cuda time: 187.73284912109375
New cuda time without quantization: 99.03068542480469
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 99.15213012695312
New cuda time without quantization: 98.9486083984375
torch.Size([524288, 768]) torch.float16
New cuda time: 99.01292419433594
New cuda time without quantization: 107.57696533203125
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.63872528076172
New cuda time without quantization: 102.1582260131836
torch.Size([524288, 768]) torch.float16
New cuda time: 102.2230224609375
New cuda time without quantization: 92.58474731445312
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 92.73402404785156
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 135.38143920898438
New cuda time without quantization: 169.95941162109375
torch.Size([524288, 768]) torch.float16
New cuda time: 170.0222930908203
New cuda time without quantization: 109.79457092285156
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.93632507324219
New cuda time without quantization: 99.60651397705078
torch.Size([524288, 768]) torch.float16
New cuda time: 99.67131042480469
New cuda time without quantization: 107.34175872802734
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 107.4043197631836
New cuda time without quantization: 105.4079818725586
torch.Size([524288, 768]) torch.float16
New cuda time: 105.4742202758789
New cuda time without quantization: 109.34368896484375
torch.Size([8, 64, 1024, 768]) torch.float16
New cuda time: 109.53840637207031
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating scores across the distributed world
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:02:38 | INFO | fairseq_cli.eval_lm | Evaluated 1,800,489 tokens in 39.7s (45339.91 tokens/s)
2024-07-12 03:02:38 | WARNING | fairseq_cli.eval_lm | Aggregating timer stats across the distributed world
2024-07-12 03:02:38 | INFO | fairseq_cli.eval_lm | valid Loss (base 2): 2.9149, Perplexity: 7.54
